{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AHMerrill/unstructured-project/blob/main/anti_echo_chamber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test cell"
      ],
      "metadata": {
        "id": "EcSTm50mDW8Y"
      },
      "id": "EcSTm50mDW8Y",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ================================================================\n",
        "# Anti Echo Chamber â€” Full Analysis and Retrieval Pipeline\n",
        "# ================================================================\n",
        "\n",
        "This notebook performs a complete, production-grade anti-echo workflow:\n",
        "\n",
        "1. Secure OpenAI login  \n",
        "2. Rebuild ChromaDB from Hugging Face  \n",
        "3. Upload and parse PDF / TXT / HTML  \n",
        "4. Summarize with OpenAI (`gpt-4o-mini`)  \n",
        "5. Create topic + stance embeddings  \n",
        "6. Compare against Chroma to surface ideologically contrasting articles  \n",
        "\n",
        "Repositories  \n",
        "- GitHub: https://github.com/AHMerrill/anti-echo-chamber  \n",
        "- Hugging Face dataset: https://huggingface.co/datasets/zanimal/anti-echo-artifacts\n"
      ],
      "metadata": {
        "id": "BBCWCGQG50vz"
      },
      "id": "BBCWCGQG50vz"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Stage 1 â€” Secure OpenAI API Key Setup\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "print(\"OpenAI API key loaded into environment (hidden)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BfTTprh8Srm",
        "outputId": "193e1b97-28e8-44ad-b93b-bfff55f41ebb"
      },
      "id": "9BfTTprh8Srm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "OpenAI API key loaded into environment (hidden)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ================================================================\n",
        "# Stage 2 â€” Environment Setup and Repository Configuration\n",
        "# ================================================================\n",
        "\n",
        "This stage:\n",
        "- Clones the GitHub repo\n",
        "- Installs dependencies\n",
        "- Loads YAML + JSON configs\n",
        "- Prints the active models and Chroma settings\n"
      ],
      "metadata": {
        "id": "ktl-Qobe8WUM"
      },
      "id": "ktl-Qobe8WUM"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Stage 2 â€” Environment Setup and Repository Configuration (config-driven)\n",
        "# ================================================================\n",
        "\n",
        "import os, json, yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Paths ---\n",
        "PROJECT_ROOT = Path(\"/content/unstructured-project\").resolve()\n",
        "\n",
        "# --- Clone correct repo if missing ---\n",
        "if not PROJECT_ROOT.exists():\n",
        "    print(\"Cloning repo from GitHub...\")\n",
        "    os.system(\"git clone https://github.com/AHMerrill/unstructured-project.git /content/unstructured-project\")\n",
        "else:\n",
        "    print(\"Repository exists. Pulling latest changes...\")\n",
        "    os.system(f\"cd {PROJECT_ROOT} && git pull\")\n",
        "\n",
        "# --- Load config.yaml from correct path ---\n",
        "CONFIG_PATH = PROJECT_ROOT / \"config/config.yaml\"\n",
        "if not CONFIG_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Config file not found at: {CONFIG_PATH}\")\n",
        "\n",
        "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    CONFIG = yaml.safe_load(f)\n",
        "\n",
        "# --- Install dependencies ---\n",
        "!pip install -q pdfplumber beautifulsoup4 chromadb sentence-transformers pyyaml huggingface_hub openai rapidfuzz\n",
        "\n",
        "summary = {\n",
        "    \"repo\": \"AHMerrill/unstructured-project\",\n",
        "    \"hf_dataset_id\": CONFIG.get(\"hf_dataset_id\"),\n",
        "    \"topic_model\": CONFIG.get(\"embeddings\", {}).get(\"topic_model\"),\n",
        "    \"stance_model\": CONFIG.get(\"embeddings\", {}).get(\"stance_model\"),\n",
        "    \"chroma_collections\": CONFIG.get(\"chroma_collections\"),\n",
        "}\n",
        "print(json.dumps(summary, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khFeOzme8dH1",
        "outputId": "5370d211-1b95-45f8-a7b7-38bbcd455d1a"
      },
      "id": "khFeOzme8dH1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repo from GitHub...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.7/20.7 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m{\n",
            "  \"repo\": \"AHMerrill/unstructured-project\",\n",
            "  \"hf_dataset_id\": \"zanimal/unstructured-project\",\n",
            "  \"topic_model\": \"intfloat/e5-base-v2\",\n",
            "  \"stance_model\": \"all-mpnet-base-v2\",\n",
            "  \"chroma_collections\": {\n",
            "    \"topic\": \"unstructured_topic\",\n",
            "    \"stance\": \"unstructured_stance\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ================================================================\n",
        "# Stage 3 â€” Full Chroma Rebuild from Hugging Face Dataset\n",
        "# ================================================================\n",
        "\n",
        "This stage reconstructs the local **ChromaDB** from your Hugging Face dataset  \n",
        "[`zanimal/anti-echo-artifacts`](https://huggingface.co/datasets/zanimal/anti-echo-artifacts).\n",
        "\n",
        "It preserves the full multi-topic and multi-stance structure from your scraper:\n",
        "- Each article can yield **multiple topic vectors** (`::topic::0`, `::topic::1`, â€¦)\n",
        "- Each article can yield **multiple stance vectors** (`::stance::summary`, `::stance::0`, â€¦)\n",
        "\n",
        "Duplicates are filtered **only by exact row_id**, not by base article ID.  \n",
        "This ensures we retain all topical clusters while preventing re-ingestion of the same batch.\n"
      ],
      "metadata": {
        "id": "_n2MIXWK8i5a"
      },
      "id": "_n2MIXWK8i5a"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Stage 3 â€” Full Chroma Rebuild from Hugging Face Dataset (config-driven)\n",
        "# ================================================================\n",
        "\n",
        "import os, json, numpy as np, traceback\n",
        "from pathlib import Path\n",
        "from huggingface_hub import list_repo_files, hf_hub_download\n",
        "import chromadb\n",
        "from collections import defaultdict\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/unstructured-project\").resolve()\n",
        "CHROMA_PATH  = PROJECT_ROOT / \"chroma_db\"\n",
        "CHROMA_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "HF_REPO = CONFIG[\"hf_dataset_id\"]\n",
        "topic_name  = CONFIG[\"chroma_collections\"][\"topic\"]\n",
        "stance_name = CONFIG[\"chroma_collections\"][\"stance\"]\n",
        "\n",
        "client = chromadb.PersistentClient(path=str(CHROMA_PATH))\n",
        "\n",
        "# Drop and recreate clean collections\n",
        "for name in [topic_name, stance_name]:\n",
        "    try:\n",
        "        client.delete_collection(name)\n",
        "    except Exception:\n",
        "        pass\n",
        "topic_coll  = client.create_collection(topic_name,  metadata={\"hnsw:space\": \"cosine\"})\n",
        "stance_coll = client.create_collection(stance_name, metadata={\"hnsw:space\": \"cosine\"})\n",
        "print(f\"Initialized collections '{topic_name}' and '{stance_name}' at {CHROMA_PATH}\")\n",
        "\n",
        "# --- Helpers (unchanged) ---\n",
        "def load_npz_safely(path):\n",
        "    arr = np.load(path, allow_pickle=False)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        for key in arr.files:\n",
        "            if arr[key].ndim == 2:\n",
        "                return arr[key]\n",
        "        raise ValueError(f\"No 2D arrays found in {path}\")\n",
        "    return arr\n",
        "\n",
        "def load_jsonl(fp):\n",
        "    records = []\n",
        "    with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            if not line: continue\n",
        "            try: records.append(json.loads(line))\n",
        "            except: continue\n",
        "    return records\n",
        "\n",
        "# --- Discover batches ---\n",
        "files = list_repo_files(HF_REPO, repo_type=\"dataset\")\n",
        "batches = sorted({\"/\".join(f.split(\"/\")[:2]) for f in files if f.startswith(\"batches/\")})\n",
        "print(f\"Detected {len(batches)} batches in {HF_REPO}\")\n",
        "\n",
        "# --- Rebuild loop (same logic as before) ---\n",
        "seen_topic_ids, seen_stance_ids = set(), set()\n",
        "article_topic_counts, article_stance_counts = defaultdict(int), defaultdict(int)\n",
        "topic_total = stance_total = 0\n",
        "\n",
        "for batch in batches:\n",
        "    try:\n",
        "        print(f\"\\n--- Processing {batch} ---\")\n",
        "        topic_npz  = hf_hub_download(HF_REPO, f\"{batch}/embeddings_topic.npz\",  repo_type=\"dataset\")\n",
        "        stance_npz = hf_hub_download(HF_REPO, f\"{batch}/embeddings_stance.npz\", repo_type=\"dataset\")\n",
        "        meta_topic = hf_hub_download(HF_REPO, f\"{batch}/metadata_topic.jsonl\",  repo_type=\"dataset\")\n",
        "        meta_stance= hf_hub_download(HF_REPO, f\"{batch}/metadata_stance.jsonl\", repo_type=\"dataset\")\n",
        "\n",
        "        t_embs, s_embs = load_npz_safely(topic_npz), load_npz_safely(stance_npz)\n",
        "        t_meta, s_meta = load_jsonl(meta_topic),  load_jsonl(meta_stance)\n",
        "\n",
        "        # topic upsert\n",
        "        t_records=[]\n",
        "        for e,m in zip(t_embs,t_meta):\n",
        "            rid=m.get(\"row_id\") or f\"{m.get('id','unknown')}::topic::0\"\n",
        "            if rid in seen_topic_ids: continue\n",
        "            seen_topic_ids.add(rid); t_records.append((rid,e,m))\n",
        "            article_topic_counts[rid.split('::')[0]]+=1\n",
        "        if t_records:\n",
        "            topic_coll.upsert(\n",
        "                ids=[r[0] for r in t_records],\n",
        "                embeddings=[r[1].tolist() for r in t_records],\n",
        "                metadatas=[r[2] for r in t_records])\n",
        "        topic_total+=len(t_records)\n",
        "\n",
        "        # stance upsert\n",
        "        s_records=[]\n",
        "        for e,m in zip(s_embs,s_meta):\n",
        "            rid=m.get(\"row_id\") or f\"{m.get('id','unknown')}::stance::0\"\n",
        "            if rid in seen_stance_ids: continue\n",
        "            seen_stance_ids.add(rid); s_records.append((rid,e,m))\n",
        "            article_stance_counts[rid.split('::')[0]]+=1\n",
        "        if s_records:\n",
        "            stance_coll.upsert(\n",
        "                ids=[r[0] for r in s_records],\n",
        "                embeddings=[r[1].tolist() for r in s_records],\n",
        "                metadatas=[r[2] for r in s_records])\n",
        "        stance_total+=len(s_records)\n",
        "        print(f\"âœ“ Added {len(t_records)} topic, {len(s_records)} stance vectors\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed {batch}: {type(e).__name__}: {e}\")\n",
        "        traceback.print_exc(limit=1)\n",
        "\n",
        "print(\"\\n=== Rebuild Summary ===\")\n",
        "print(f\"Topic vectors added: {topic_total}\")\n",
        "print(f\"Stance vectors added: {stance_total}\")\n",
        "print(f\"Stored at {CHROMA_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603,
          "referenced_widgets": [
            "b14dfa69efaa475e873a376875bd68cf",
            "38592cf818af46d89e87669343772742",
            "98a9deb1eeb4486fa7917950379a383d",
            "6a818980309840e6a186dfe4a767a509",
            "2af2c586cea64708b84dff72b060f3b6",
            "288a8a829f0744cbb4f42aa8dd827fed",
            "56068a5dc1604b27bf4a75471c349f99",
            "e6a02b065d95409ba937f8985079b480",
            "112b4d297a4e45fbaff79c1a24080957",
            "dbe340b2b0344ca8add4c29c1d58f075",
            "5d67003856ac484eab029db4a0cf9ea1",
            "61c41e3693cf465ca667ed9cc9fcd56b",
            "4905a4616eb8423cb481f5a67ad3506b",
            "51be6a45946948539b826e012a41d071",
            "8dfa1fb975b2446a985315f33598bc98",
            "85839a0b1eee4e759c447c2f28d9b1ad",
            "5843a223c02a4aa7b19e39c1a8e55af4",
            "1a2a325c0f6c41489ea1514586170b32",
            "57c83ccab91f40c8ba102bb116a7bf03",
            "b9dc743f0f504642a1a8b68b55ff2a56",
            "1fce3b13dcd4410e8e6fdaa158ef958a",
            "808727bc2ad2440b839cfa1388dbd400",
            "4f6932e98a1a44629814e0b80b2bc4f8",
            "1a4e0f32ae8848d099a6978655830433",
            "e8aa060eec8b42be85a4fe232232f24b",
            "2a40dadc6e834091bc3fc906e253a1f6",
            "253165468f3d4fb69c277bbbdea2c3a4",
            "1aeccfd98fed4f25973c8e54a7cfaab5",
            "577826cf47474c21a3336117f97c9c7f",
            "8ad1f7aa5ddc44b1a5fddd50bb6502bd",
            "002a94a6e92a4c38bdccdbc3495031db",
            "25a01f9761bf450389915153f1be86b3",
            "8c8563a5e3344d94a526cb850520d9bc",
            "f1832738a5cb4ce3b830598ab2666cde",
            "12b20ed181104483ab7ed69bdc25b5e2",
            "b7d48d3032e1418782f959ab438fc947",
            "2bcd4e4243874051af094a14036c5451",
            "5c97586d5099449599c8fb634e9374b9",
            "066bf0c6e46949e0972b87505e46132b",
            "c5e17a0f6edf4e8d86c209f46134fcab",
            "39a4eb435c8949219caed152a57d9a8e",
            "53c3b0c363b04deb8fdab7860fddf033",
            "2f67321f3af84daca3760d04672690cd",
            "2fc0dc114e394dddb0e373c7f4fe1db7",
            "c40f5c79a17d4af0a76904be708624ad",
            "9310906c20c342ef8b914cb301272163",
            "3290cfd2c4634c8f9e4d50262b0628ee",
            "a46ba425988f42b289da68dfce4f0bfd",
            "ada253e75dd748ea80efa8dbbb2d5d91",
            "892422508f304124b9c59094592a1a65",
            "9460e15c318d4696815c339476804514",
            "bfb84cd7c682439188764c1c4b8b2631",
            "9edf3afd6d404f15812c162166674817",
            "f2eadb921032488083e974da68dc53a3",
            "87cded6e38264caca0b3d7332a1dce44",
            "f2b34d28948248528b540429497665cb",
            "99f8435ce3a842cbae9ba710df93fd66",
            "fa6eeaa786c64e4faf9581899ccfe796",
            "ecd58b7072564756b414ff87e96de280",
            "c310bea32c0a4dfd9a1956b18af79195",
            "3471f2078742458bacf5c330e9833725",
            "d206645b80754505861fd52fee80ed1f",
            "ab73a96e36254be19500b74c49484063",
            "c4d03b2cea974ee6b2169ff7d09d3240",
            "c667fa3511664bedb1369c6804477b4a",
            "96199e60c22d4067bb6c6b5b8deb8ab5",
            "6c8fe719550a4880933cd53c84f86684",
            "7b8e082d1bad47e1955a671250df98ec",
            "2a57d5a395a146f893589d06c33fcc91",
            "504d4c79456b424cb6adc3635d94b101",
            "2702b7dfa9a9474894b0eb3e4ba8eb4d",
            "624fb19c733c4337ba3ad69ad5304ea6",
            "b30ed259c5ce48179b591b951a8f470a",
            "2de93038008040d6804a5ae5957fd5a7",
            "5d7f21d07f1e4e1c8af8071f8b30abbb",
            "762a94d6c7644db3a09f619a0ea4da63",
            "1ac28b4cd118414fb9788702720e6245",
            "cbe034bf8eeb4c7e813bc6954451a669",
            "6c782170462e41c9929c5d0c6e60def3",
            "f67b60809c454b5fad638c005f6b6606",
            "4a56ba373d1c452e9f400bc1ef19ae5c",
            "cac0d6cf736f4e0ca4f0055e717ca4c2",
            "c0ce5cdc77d5490d9866fb0413091ed3",
            "c8492d0207234509a680761130961d14",
            "3453ebedf3e849f98dd692b881f2fe1f",
            "9fdd29e789314b738dcdf83ee2af39c7",
            "43416e6109a941e8a14c4295257587cc",
            "c1bb1bac3108421ebf5a08f706be6d12"
          ]
        },
        "id": "R2NotSan8mGR",
        "outputId": "d4c9c0fa-54d6-43a5-8cc5-cdd82113eb29"
      },
      "id": "R2NotSan8mGR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized collections 'unstructured_topic' and 'unstructured_stance' at /content/unstructured-project/chroma_db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 2 batches in zanimal/unstructured-project\n",
            "\n",
            "--- Processing batches/batch_20251025T173713Z_5dd9b9dd ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batches/batch_20251025T173713Z_5dd9b9dd/(â€¦):   0%|          | 0.00/89.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b14dfa69efaa475e873a376875bd68cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batches/batch_20251025T173713Z_5dd9b9dd/(â€¦):   0%|          | 0.00/18.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61c41e3693cf465ca667ed9cc9fcd56b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "metadata_topic.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f6932e98a1a44629814e0b80b2bc4f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "metadata_stance.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1832738a5cb4ce3b830598ab2666cde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Added 64 topic, 13 stance vectors\n",
            "\n",
            "--- Processing batches/batch_20251025T181241Z_d8804259 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batches/batch_20251025T181241Z_d8804259/(â€¦):   0%|          | 0.00/3.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c40f5c79a17d4af0a76904be708624ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batches/batch_20251025T181241Z_d8804259/(â€¦):   0%|          | 0.00/614k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2b34d28948248528b540429497665cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "metadata_topic.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c8fe719550a4880933cd53c84f86684"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "metadata_stance.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbe034bf8eeb4c7e813bc6954451a669"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Added 2104 topic, 419 stance vectors\n",
            "\n",
            "=== Rebuild Summary ===\n",
            "Topic vectors added: 2168\n",
            "Stance vectors added: 432\n",
            "Stored at /content/unstructured-project/chroma_db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ================================================================\n",
        "# Stage 4 â€” User Upload + Source Bias Detection\n",
        "# ================================================================\n",
        "\n",
        "This stage handles ingestion of a user-supplied article (TXT / PDF / HTML).  \n",
        "It performs four key steps:\n",
        "\n",
        "1. **Upload** the file and extract plain text.  \n",
        "2. **Infer or confirm** the publication source.  \n",
        "3. **Match** against existing entries in `source_bias.json` (fuzzy).  \n",
        "4. **If new**, infer ideological metadata (bias family + score) using `gpt-4o-mini`.\n",
        "\n",
        "All extracted and inferred data will be cached for later topic + stance analysis.\n"
      ],
      "metadata": {
        "id": "2NxjvGuBBt1Y"
      },
      "id": "2NxjvGuBBt1Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Stage 4 â€” User Upload + Source Bias Detection\n",
        "# ================================================================\n",
        "\n",
        "import os, re, json, pdfplumber, requests\n",
        "from bs4 import BeautifulSoup\n",
        "from rapidfuzz import process, fuzz\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "# --- Environment setup ---\n",
        "PROJECT_ROOT = Path(\"/content/unstructured-project\").resolve()\n",
        "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
        "\n",
        "# Load your bias map\n",
        "SOURCE_BIAS_PATH = CONFIG_DIR / \"source_bias.json\"\n",
        "SOURCE_BIAS = json.load(open(SOURCE_BIAS_PATH, encoding=\"utf-8\"))\n",
        "\n",
        "# Ensure OpenAI key\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"].strip():\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 1. File Upload + Text Extraction\n",
        "# --------------------------------------------------------------------\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "file_ext = Path(filename).suffix.lower()\n",
        "\n",
        "def extract_text(path):\n",
        "    if path.endswith(\".txt\"):\n",
        "        return Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    if path.endswith(\".pdf\"):\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() or \"\"\n",
        "        return text\n",
        "    if path.endswith(\".html\") or path.endswith(\".htm\"):\n",
        "        soup = BeautifulSoup(Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\"), \"html.parser\")\n",
        "        for s in soup([\"script\", \"style\"]):\n",
        "            s.decompose()\n",
        "        return soup.get_text(separator=\" \")\n",
        "    raise ValueError(\"Unsupported file type\")\n",
        "\n",
        "article_text = extract_text(filename).strip()\n",
        "print(f\"Extracted {len(article_text)} characters from {filename}\")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 2. Attempt Source Inference\n",
        "# --------------------------------------------------------------------\n",
        "def infer_source_name(text):\n",
        "    # Quick domain sniff\n",
        "    m = re.search(r\"https?://([^/\\s]+)\", text)\n",
        "    if m:\n",
        "        domain = m.group(1).lower()\n",
        "        domain = domain.replace(\"www.\", \"\")\n",
        "        return domain.split(\".\")[0]\n",
        "    # GPT fallback\n",
        "    prompt = (\n",
        "        \"You are a media analyst. Based on the article text below, \"\n",
        "        \"infer the most likely publication or outlet name. \"\n",
        "        \"Return only the outlet name, e.g., 'The Guardian', 'Fox News', etc.\\n\\n\"\n",
        "        f\"Article excerpt:\\n{text[:2000]}\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=20,\n",
        "        temperature=0.2\n",
        "    )\n",
        "    guess = resp.choices[0].message.content.strip()\n",
        "    return re.sub(r\"[^A-Za-z0-9\\s\\-]\", \"\", guess)\n",
        "\n",
        "inferred_source = infer_source_name(article_text)\n",
        "print(f\"ğŸ•µï¸ Inferred possible source: {inferred_source}\")\n",
        "\n",
        "# Ask user to confirm or override\n",
        "user_resp = input(f\"Is this article from '{inferred_source}'? [y/n]: \").strip().lower()\n",
        "if user_resp != \"y\":\n",
        "    user_source = input(\"Enter the source name (may contain typos): \").strip()\n",
        "    confirmed_source = user_source\n",
        "else:\n",
        "    confirmed_source = inferred_source\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 3. Fuzzy Match Against Known Sources\n",
        "# --------------------------------------------------------------------\n",
        "known_sources = list(SOURCE_BIAS.keys())\n",
        "match, score, _ = process.extractOne(confirmed_source, known_sources, scorer=fuzz.ratio)\n",
        "print(f\"Closest match: {match} (score {score})\")\n",
        "\n",
        "if score >= 85:\n",
        "    bias_info = SOURCE_BIAS[match]\n",
        "    print(f\"Matched existing bias entry for {match}\")\n",
        "else:\n",
        "    # ----------------------------------------------------------------\n",
        "    # 4. GPT Bias Inference Fallback  (FIXED JSON PARSING)\n",
        "    # ----------------------------------------------------------------\n",
        "    prompt = f\"\"\"\n",
        "You are a media bias researcher.\n",
        "Given the outlet name \"{confirmed_source}\", infer its general political bias family\n",
        "(e.g., 'center left', 'center right', 'libertarian right', 'progressive left', 'neutral').\n",
        "Return JSON with:\n",
        "- bias_family\n",
        "- bias_score (float, -1.0 = far left, +1.0 = far right)\n",
        "- short_rationale (brief explanation)\n",
        "\"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=CONFIG[\"stance_processing\"][\"llm\"][\"model\"],\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=128,\n",
        "        temperature=0.4\n",
        "    )\n",
        "\n",
        "    # --- FIXED: safely parse fenced JSON output from GPT ---\n",
        "    raw_reply = resp.choices[0].message.content.strip()\n",
        "    clean_json = re.sub(r\"```json|```\", \"\", raw_reply).strip()\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(clean_json)\n",
        "        bias_info = {\n",
        "            \"bias_family\": parsed.get(\"bias_family\", \"unknown\"),\n",
        "            \"bias_score\": float(parsed.get(\"bias_score\", 0.0)),\n",
        "            \"short_rationale\": parsed.get(\"short_rationale\", \"\")\n",
        "        }\n",
        "    except Exception:\n",
        "        # fallback: store text if parsing fails\n",
        "        bias_info = {\n",
        "            \"bias_family\": \"unknown\",\n",
        "            \"bias_score\": 0.0,\n",
        "            \"short_rationale\": raw_reply\n",
        "        }\n",
        "\n",
        "    print(f\"New outlet inferred:\\n{json.dumps(bias_info, indent=2)}\")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 5. Cache Inferred Metadata\n",
        "# --------------------------------------------------------------------\n",
        "ARTICLE_META = {\n",
        "    \"filename\": filename,\n",
        "    \"source_input\": confirmed_source,\n",
        "    \"matched_source\": match if score >= 85 else None,\n",
        "    \"bias_family\": bias_info.get(\"bias_family\", \"unknown\"),\n",
        "    \"bias_score\": bias_info.get(\"bias_score\", 0.0),\n",
        "    \"rationale\": bias_info.get(\"short_rationale\", \"\"),\n",
        "    \"chars\": len(article_text)\n",
        "}\n",
        "\n",
        "# Save to temporary workspace\n",
        "TEMP_DIR = PROJECT_ROOT / \"tmp\"\n",
        "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "meta_path = TEMP_DIR / f\"{Path(filename).stem}_meta.json\"\n",
        "text_path = TEMP_DIR / f\"{Path(filename).stem}.txt\"\n",
        "Path(text_path).write_text(article_text, encoding=\"utf-8\")\n",
        "Path(meta_path).write_text(json.dumps(ARTICLE_META, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "# --- NEW: Save pointer for Stage 5a ---\n",
        "latest_ref = TEMP_DIR / \"latest_meta.txt\"\n",
        "latest_ref.write_text(str(meta_path))\n",
        "print(f\"\\nSaved reference for next stage: {latest_ref}\")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# Display summary\n",
        "# --------------------------------------------------------------------\n",
        "print(\"\\n--- Source Bias Summary ---\")\n",
        "print(json.dumps(ARTICLE_META, indent=2))\n",
        "print(f\"Cached article + metadata under {TEMP_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "Fqq7T08tBvoO",
        "outputId": "aa70cacf-86af-4622-c714-9c5df01b25c6"
      },
      "id": "Fqq7T08tBvoO",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8fb8307a-d9b0-4f12-8074-ff82120359e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8fb8307a-d9b0-4f12-8074-ff82120359e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion.pdf to Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion.pdf\n",
            "Extracted 5605 characters from Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion.pdf\n",
            "ğŸ•µï¸ Inferred possible source: usatoday\n",
            "Is this article from 'usatoday'? [y/n]: y\n",
            "Closest match: guardian (score 50.0)\n",
            "New outlet inferred:\n",
            "{\n",
            "  \"bias_family\": \"neutral\",\n",
            "  \"bias_score\": 0.0,\n",
            "  \"short_rationale\": \"USA Today aims to provide balanced news coverage and is generally considered neutral, focusing on a wide range of topics without a strong political leaning.\"\n",
            "}\n",
            "\n",
            "Saved reference for next stage: /content/unstructured-project/tmp/latest_meta.txt\n",
            "\n",
            "--- Source Bias Summary ---\n",
            "{\n",
            "  \"filename\": \"Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion.pdf\",\n",
            "  \"source_input\": \"usatoday\",\n",
            "  \"matched_source\": null,\n",
            "  \"bias_family\": \"neutral\",\n",
            "  \"bias_score\": 0.0,\n",
            "  \"rationale\": \"USA Today aims to provide balanced news coverage and is generally considered neutral, focusing on a wide range of topics without a strong political leaning.\",\n",
            "  \"chars\": 5605\n",
            "}\n",
            "Cached article + metadata under /content/unstructured-project/tmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ================================================================\n",
        "# Stage 5a â€” Topic Embedding with Composite Vector (Base + GPT Summary)\n",
        "# ================================================================\n",
        "\n",
        "This step creates a **two-layer topic representation** for precise matching:\n",
        "\n",
        "### What it does:\n",
        "1. **Loads** the extracted text and metadata from Stage 4\n",
        "2. **Generates base topic embeddings** via hierarchical clustering (same as scraper)\n",
        "3. **Assigns canonical topics** from the predefined taxonomy (e.g., \"Politics / Global / Geopolitics & Conflict\")\n",
        "4. **NEW: Generates GPT summary** - A one-sentence description of the article's specific subject (e.g., \"Trump imposes sanctions on Russian oil companies amid Ukraine conflict\")\n",
        "5. **Creates composite embedding** by concatenating:\n",
        "   - Base topic vector (768 dimensions) - captures broad semantic topic\n",
        "   - GPT summary vector (768 dimensions) - captures specific subject details\n",
        "   - Final output: 1536-dimensional composite vector\n",
        "\n",
        "### Output files:\n",
        "- `{article}_topic_composite.npy` - Composite 1536-dim vector (used for retrieval)\n",
        "- `{article}_topic.npy` - Base topic vectors (for backward compatibility)\n",
        "- `{article}_topics_flat.json` - List of canonical topic labels\n",
        "- `{article}_topic_summary.json` - GPT summary + metadata\n"
      ],
      "metadata": {
        "id": "MC7rpNxNEfas"
      },
      "id": "MC7rpNxNEfas"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Stage 5a â€” Topic Embedding + Canonical Topic Assignment + GPT Summary (SCRAPER-STYLE)\n",
        "# ================================================================\n",
        "\n",
        "import json, numpy as np, nltk, torch, os\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/unstructured-project\").resolve()\n",
        "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
        "TMP = PROJECT_ROOT / \"tmp\"\n",
        "EPHEMERAL = TMP / \"ephemeral_embeddings\"\n",
        "EPHEMERAL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- OpenAI setup ---\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"].strip():\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# --- Load text + meta (from Stage 4 pointer) ---\n",
        "latest_meta_ref = TMP / \"latest_meta.txt\"\n",
        "if not latest_meta_ref.exists():\n",
        "    raise FileNotFoundError(\"Missing latest_meta.txt â€” run Stage 4 first to upload an article.\")\n",
        "\n",
        "latest_meta = Path(latest_meta_ref.read_text().strip())\n",
        "if not latest_meta.exists():\n",
        "    raise FileNotFoundError(f\"Referenced meta file not found: {latest_meta}\")\n",
        "\n",
        "meta = json.load(open(latest_meta))\n",
        "text_path = TMP / f\"{Path(latest_meta).stem.replace('_meta','')}.txt\"\n",
        "if not text_path.exists():\n",
        "    raise FileNotFoundError(f\"Text file not found for: {text_path}\")\n",
        "\n",
        "article_text = text_path.read_text(encoding=\"utf-8\")\n",
        "print(f\"Embedding topics for: {meta['filename']} ({len(article_text)} chars)\")\n",
        "\n",
        "# --- Config parameters ---\n",
        "topic_model_name = CONFIG[\"embeddings\"][\"topic_model\"]\n",
        "chunk_tokens = CONFIG[\"embeddings\"][\"chunk_tokens\"]\n",
        "normalize = CONFIG[\"embeddings\"][\"normalize\"]\n",
        "threshold = CONFIG[\"topics\"][\"similarity_threshold\"]\n",
        "max_topics_per_vec = CONFIG[\"topics\"][\"max_topics_per_article\"]\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using topic model: {topic_model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(topic_model_name, use_fast=True)\n",
        "embedder = SentenceTransformer(topic_model_name, device=device)\n",
        "\n",
        "# --- Load canonical topic anchors + labels ---\n",
        "anchors_path = CONFIG_DIR / \"topic_anchors.npz\"\n",
        "topics_path = CONFIG_DIR / \"topics.json\"\n",
        "anchors_npz = np.load(anchors_path, allow_pickle=True)\n",
        "topic_anchors = {k: anchors_npz[k] for k in anchors_npz.files}\n",
        "topic_labels = list(topic_anchors.keys())\n",
        "print(f\"Loaded {len(topic_anchors)} topic anchors\")\n",
        "\n",
        "# --- NLTK setup ---\n",
        "for pkg in [\"punkt\", \"punkt_tab\"]:\n",
        "    try:\n",
        "        nltk.data.find(f\"tokenizers/{pkg}\")\n",
        "    except LookupError:\n",
        "        nltk.download(pkg)\n",
        "\n",
        "def sent_split(text):\n",
        "    return [s.strip() for s in nltk.sent_tokenize(text) if s.strip()]\n",
        "\n",
        "def encode(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    vecs = embedder.encode(\n",
        "        texts,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=normalize,\n",
        "        show_progress_bar=False,\n",
        "    )\n",
        "    return np.array(vecs)\n",
        "\n",
        "def topic_vecs(text):\n",
        "    sents = sent_split(text)\n",
        "    if not sents:\n",
        "        return []\n",
        "    if len(sents) < 2:\n",
        "        return [encode(\" \".join(sents)).mean(axis=0)]\n",
        "    emb = encode(sents)\n",
        "    k = min(max(1, len(sents)//8), 8)\n",
        "    labels = AgglomerativeClustering(n_clusters=k).fit_predict(emb)\n",
        "    segs = [\" \".join([s for s, l in zip(sents, labels) if l == lab]) for lab in sorted(set(labels))]\n",
        "    out = []\n",
        "    for seg in segs:\n",
        "        out.append(encode(seg).mean(axis=0))\n",
        "    return out\n",
        "\n",
        "def match_topics(vec, anchors_dict, max_topics=5, threshold=0.4):\n",
        "    scores = {\n",
        "        label: float(cosine_similarity([vec], [anchor])[0][0])\n",
        "        for label, anchor in anchors_dict.items()\n",
        "    }\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    selected = []\n",
        "    for i, (label, sim) in enumerate(ranked[:max_topics]):\n",
        "        if i == 0 or sim >= threshold:\n",
        "            selected.append({\"topic_label\": label, \"similarity\": sim})\n",
        "    if not selected:\n",
        "        selected = [{\"topic_label\": \"General / Miscellaneous\", \"similarity\": 0.0}]\n",
        "    return selected\n",
        "\n",
        "# --- Generate base topic embeddings + topic matches ---\n",
        "topic_vec_list = topic_vecs(article_text)\n",
        "topic_vecs_array = np.vstack(topic_vec_list)\n",
        "print(f\"Generated {len(topic_vecs_array)} base topic embeddings with shape {topic_vecs_array.shape}\")\n",
        "\n",
        "# --- Match to anchors ---\n",
        "all_labels = []\n",
        "topic_matches = []\n",
        "for i, vec in enumerate(topic_vecs_array):\n",
        "    matches = match_topics(vec, topic_anchors, max_topics=max_topics_per_vec, threshold=threshold)\n",
        "    topic_matches.append(matches)\n",
        "    top_labels = [m[\"topic_label\"] for m in matches]\n",
        "    all_labels.extend(top_labels)\n",
        "    print(f\"\\n[Topic vector {i}] matches:\")\n",
        "    for m in matches:\n",
        "        print(f\"  - {m['topic_label']:<40} (similarity {m['similarity']:.3f})\")\n",
        "\n",
        "# --- Deduplicate + limit to top 8 overall topics ---\n",
        "flat_topics = list(dict.fromkeys(all_labels))[:8]\n",
        "print(\"\\n--- Canonical Topics Assigned ---\")\n",
        "for t in flat_topics:\n",
        "    print(f\" - {t}\")\n",
        "\n",
        "# ================================================================\n",
        "# Generate GPT Summary (stored as text only)\n",
        "# ================================================================\n",
        "print(\"\\n--- Generating GPT Topic Summary ---\")\n",
        "\n",
        "summary_prompt = f\"\"\"\n",
        "Summarize this article's specific subject in ONE sentence (max 20 words).\n",
        "Be concrete and specific about what event, person, location, or issue is discussed.\n",
        "Focus on the WHO/WHAT/WHERE, not opinion or analysis.\n",
        "\n",
        "Article title: {meta.get('filename', 'Unknown')}\n",
        "Text excerpt: {article_text[:2500]}\n",
        "\n",
        "Example good summaries:\n",
        "- \"Discusses Israel's military operations in Gaza and humanitarian impact\"\n",
        "- \"Analyzes Federal Reserve's interest rate decision and inflation outlook\"\n",
        "- \"Covers Elon Musk's acquisition of Twitter and content moderation changes\"\n",
        "- \"Reports on Supreme Court ruling on affirmative action in college admissions\"\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
        "        max_tokens=40,\n",
        "        temperature=0.3\n",
        "    )\n",
        "    topic_summary = response.choices[0].message.content.strip()\n",
        "    topic_summary = topic_summary.strip('\"').strip(\"'\").strip()\n",
        "    print(f\"Topic summary: {topic_summary}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: GPT summary failed ({e}), using title as fallback\")\n",
        "    topic_summary = meta.get('filename', 'Unknown article')\n",
        "\n",
        "# ================================================================\n",
        "# Save base topic embedding + summary text (SCRAPER-STYLE)\n",
        "# ================================================================\n",
        "base = Path(meta[\"filename\"]).stem\n",
        "primary_topic_vec = topic_vecs_array[0]\n",
        "if primary_topic_vec.ndim == 2:\n",
        "    primary_topic_vec = primary_topic_vec.flatten()\n",
        "\n",
        "topic_path = EPHEMERAL / f\"{base}_topic.npy\"\n",
        "np.save(topic_path, primary_topic_vec)\n",
        "\n",
        "match_path   = EPHEMERAL / f\"{base}_topic_matches.json\"\n",
        "flat_path    = EPHEMERAL / f\"{base}_topics_flat.json\"\n",
        "summary_path = EPHEMERAL / f\"{base}_topic_summary.json\"\n",
        "\n",
        "json.dump(topic_matches, open(match_path, \"w\"), indent=2)\n",
        "json.dump(flat_topics, open(flat_path, \"w\"), indent=2)\n",
        "json.dump(\n",
        "    {\n",
        "        \"summary\": topic_summary,\n",
        "        \"embedding_version\": \"v1_scraper_style\",\n",
        "        \"base_shape\": list(primary_topic_vec.shape),\n",
        "        \"note\": \"Summary stored as text only; matches scraper output.\"\n",
        "    },\n",
        "    open(summary_path, \"w\"),\n",
        "    indent=2,\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Saved Artifacts (Scraper-Style) ---\")\n",
        "print(f\"Base topic vector â†’ {topic_path}\")\n",
        "print(f\"Canonical topics â†’ {flat_path}\")\n",
        "print(f\"Topic summary metadata â†’ {summary_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qwaCAhrEjsE",
        "outputId": "ef6aafac-0f0c-4e4b-c8f7-5b4b8c211138"
      },
      "id": "-qwaCAhrEjsE",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding topics for: Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion.pdf (5605 chars)\n",
            "Using topic model: intfloat/e5-base-v2\n",
            "Loaded 22 topic anchors\n",
            "Generated 5 base topic embeddings with shape (5, 768)\n",
            "\n",
            "[Topic vector 0] matches:\n",
            "  - Politics / US / Federal / Elections and Campaigns (similarity 0.783)\n",
            "  - Society / Culture & Identity / Social Issues (similarity 0.777)\n",
            "  - Ethics / Governance & Accountability / Integrity (similarity 0.777)\n",
            "  - Society / Media / Communication          (similarity 0.770)\n",
            "  - Law / Legal Systems / Justice            (similarity 0.764)\n",
            "\n",
            "[Topic vector 1] matches:\n",
            "  - Law / Legal Systems / Justice            (similarity 0.775)\n",
            "  - Society / Culture & Identity / Social Issues (similarity 0.775)\n",
            "  - Politics / Global / Geopolitics & Conflict (similarity 0.769)\n",
            "  - Politics / US / Federal / Judicial Branch (similarity 0.765)\n",
            "  - Technology / Social Media & Platforms    (similarity 0.764)\n",
            "\n",
            "[Topic vector 2] matches:\n",
            "  - Politics / US / Federal / Elections and Campaigns (similarity 0.811)\n",
            "  - Society / Culture & Identity / Social Issues (similarity 0.800)\n",
            "  - Society / Media / Communication          (similarity 0.799)\n",
            "  - Technology / Social Media & Platforms    (similarity 0.797)\n",
            "  - Politics / US / Federal / Executive Policy (similarity 0.793)\n",
            "\n",
            "[Topic vector 3] matches:\n",
            "  - Politics / US / Federal / Elections and Campaigns (similarity 0.786)\n",
            "  - Society / Culture & Identity / Social Issues (similarity 0.786)\n",
            "  - Ethics / Governance & Accountability / Integrity (similarity 0.783)\n",
            "  - Technology / Social Media & Platforms    (similarity 0.781)\n",
            "  - Society / Media / Communication          (similarity 0.779)\n",
            "\n",
            "[Topic vector 4] matches:\n",
            "  - Society / Culture & Identity / Social Issues (similarity 0.811)\n",
            "  - Society / Media / Communication          (similarity 0.797)\n",
            "  - Politics / US / Federal / Elections and Campaigns (similarity 0.794)\n",
            "  - Technology / Social Media & Platforms    (similarity 0.792)\n",
            "  - Ethics / Governance & Accountability / Integrity (similarity 0.790)\n",
            "\n",
            "--- Canonical Topics Assigned ---\n",
            " - Politics / US / Federal / Elections and Campaigns\n",
            " - Society / Culture & Identity / Social Issues\n",
            " - Ethics / Governance & Accountability / Integrity\n",
            " - Society / Media / Communication\n",
            " - Law / Legal Systems / Justice\n",
            " - Politics / Global / Geopolitics & Conflict\n",
            " - Politics / US / Federal / Judicial Branch\n",
            " - Technology / Social Media & Platforms\n",
            "\n",
            "--- Generating GPT Topic Summary ---\n",
            "Topic summary: Andrew Cuomo's Islamophobic comments toward NYC mayoral candidate Zohran Mamdani highlight racism in the election campaign.\n",
            "\n",
            "--- Saved Artifacts (Scraper-Style) ---\n",
            "Base topic vector â†’ /content/unstructured-project/tmp/ephemeral_embeddings/Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion_topic.npy\n",
            "Canonical topics â†’ /content/unstructured-project/tmp/ephemeral_embeddings/Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion_topics_flat.json\n",
            "Topic summary metadata â†’ /content/unstructured-project/tmp/ephemeral_embeddings/Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion_topic_summary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Stage 5b â€” Stance Classification + Hybrid Embedding (Ephemeral, Scraper-Accurate)\n",
        "# ================================================================\n",
        "\n",
        "import os, json, re, torch, numpy as np\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/unstructured-project\").resolve()\n",
        "CONFIG_DIR   = PROJECT_ROOT / \"config\"\n",
        "TMP          = PROJECT_ROOT / \"tmp\"\n",
        "EPHEMERAL    = TMP / \"ephemeral_embeddings\"\n",
        "EPHEMERAL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Load configs and guides ---\n",
        "with open(CONFIG_DIR / \"political_leanings.json\", encoding=\"utf-8\") as f:\n",
        "    leanings_map = json.load(f)\n",
        "with open(CONFIG_DIR / \"implied_stances.json\", encoding=\"utf-8\") as f:\n",
        "    stances_map = json.load(f)\n",
        "with open(CONFIG_DIR / \"source_bias.json\", encoding=\"utf-8\") as f:\n",
        "    source_bias = json.load(f)\n",
        "\n",
        "# --- Load metadata and article text (FIXED to use explicit reference from Stage 4) ---\n",
        "latest_meta_ref = TMP / \"latest_meta.txt\"\n",
        "if not latest_meta_ref.exists():\n",
        "    raise FileNotFoundError(\"Missing latest_meta.txt â€” run Stage 4 first to upload an article.\")\n",
        "\n",
        "latest_meta = Path(latest_meta_ref.read_text().strip())\n",
        "if not latest_meta.exists():\n",
        "    raise FileNotFoundError(f\"Referenced meta file not found: {latest_meta}\")\n",
        "\n",
        "meta = json.load(open(latest_meta))\n",
        "text_path = TMP / f\"{Path(latest_meta).stem.replace('_meta','')}.txt\"\n",
        "if not text_path.exists():\n",
        "    raise FileNotFoundError(f\"Text file not found for: {text_path}\")\n",
        "\n",
        "article_txt = text_path.read_text(encoding=\"utf-8\")\n",
        "print(f\"Generating stance embedding for: {meta['filename']} ({len(article_txt)} chars)\")\n",
        "\n",
        "# --- Retrieve outlet bias already inferred in Stage 4 ---\n",
        "bias_family = meta.get(\"bias_family\", \"unknown\")\n",
        "bias_score  = float(meta.get(\"bias_score\", 0.0))\n",
        "\n",
        "# --- OpenAI client ---\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"].strip():\n",
        "    from getpass import getpass\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# --- GPT classification identical to scraper ---\n",
        "prompt = f\"\"\"\n",
        "You are a political analyst.\n",
        "Based on the article below, classify its overall political leaning (tone) and implied stance.\n",
        "\n",
        "Leaning options: {', '.join(leanings_map.keys())}\n",
        "Stance examples: {', '.join([s for cat in stances_map.values() for s in cat['families'].keys()])}\n",
        "\n",
        "Return strict JSON with fields:\n",
        "- political_leaning (string)\n",
        "- implied_stance (string)\n",
        "- summary (one-sentence summary of the article's main argument)\n",
        "\n",
        "Article title: {meta.get('filename')}\n",
        "Excerpt: {article_txt[:2000]}\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=CONFIG[\"stance_processing\"][\"llm\"][\"model\"],\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=256,\n",
        "    temperature=0.4\n",
        ")\n",
        "raw = resp.choices[0].message.content.strip()\n",
        "\n",
        "try:\n",
        "    stance_info = json.loads(raw)\n",
        "except Exception:\n",
        "    # fallback regex extraction\n",
        "    leaning = re.search(r\"leaning[:\\-]?\\s*(.+)\", raw, re.I)\n",
        "    stance  = re.search(r\"stance[:\\-]?\\s*(.+)\",  raw, re.I)\n",
        "    summary = re.search(r\"summary[:\\-]?\\s*(.+)\", raw, re.I)\n",
        "    stance_info = {\n",
        "        \"political_leaning\": (leaning.group(1).strip() if leaning else \"unknown\"),\n",
        "        \"implied_stance\":    (stance.group(1).strip()  if stance  else \"unknown\"),\n",
        "        \"summary\":           (summary.group(1).strip() if summary else raw[:200])\n",
        "    }\n",
        "\n",
        "print(\"\\n--- GPT Classification ---\")\n",
        "print(json.dumps(stance_info, indent=2))\n",
        "\n",
        "# --- Compute tone score + match with outlet bias ---\n",
        "def bias_to_score(label):\n",
        "    l = (label or \"\").lower().strip()\n",
        "    if \"progressive\" in l or (\"left\" in l and \"center\" not in l): return -0.8\n",
        "    if \"center left\" in l:  return -0.4\n",
        "    if l == \"center\":       return 0.0\n",
        "    if \"center right\" in l: return 0.4\n",
        "    if \"conservative\" in l or \"right\" in l: return 0.8\n",
        "    if \"libertarian\" in l:  return 0.6\n",
        "    return 0.0\n",
        "\n",
        "tone_score = bias_to_score(stance_info.get(\"political_leaning\"))\n",
        "author_match = abs(bias_score - tone_score) <= 0.3\n",
        "\n",
        "# --- Build enriched stance metadata ---\n",
        "stance_meta = {\n",
        "    \"political_leaning\": stance_info.get(\"political_leaning\", \"unknown\"),\n",
        "    \"implied_stance\":    stance_info.get(\"implied_stance\", \"unknown\"),\n",
        "    \"summary\":           stance_info.get(\"summary\", \"\"),\n",
        "    \"bias_family\":       bias_family,\n",
        "    \"bias_score\":        bias_score,\n",
        "    \"tone_score\":        tone_score,\n",
        "    \"author_tone_match\": author_match\n",
        "}\n",
        "\n",
        "print(\"\\n--- Source / Tone Alignment ---\")\n",
        "print(json.dumps(stance_meta, indent=2))\n",
        "\n",
        "# --- Hybrid text for embedding ---\n",
        "hybrid_text = \"\\n\".join([\n",
        "    stance_meta[\"political_leaning\"],\n",
        "    stance_meta[\"implied_stance\"],\n",
        "    stance_meta[\"summary\"]\n",
        "]).strip()\n",
        "\n",
        "# --- Generate embedding ---\n",
        "stance_model_name = CONFIG[\"embeddings\"][\"stance_model\"]\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "embedder = SentenceTransformer(stance_model_name, device=device)\n",
        "stance_vec = embedder.encode(hybrid_text, normalize_embeddings=True)\n",
        "stance_vec = stance_vec.reshape(1, -1)\n",
        "print(f\"\\nUsing stance model: {stance_model_name}\")\n",
        "print(f\"Generated stance vector with shape {stance_vec.shape}\")\n",
        "\n",
        "# --- Save ephemeral outputs for Stage 6 ---\n",
        "base = Path(meta[\"filename\"]).stem\n",
        "np.save(EPHEMERAL / f\"{base}_stance.npy\", stance_vec)\n",
        "Path(EPHEMERAL / f\"{base}_stance_summary.txt\").write_text(hybrid_text, encoding=\"utf-8\")\n",
        "Path(EPHEMERAL / f\"{base}_stance_info.json\").write_text(json.dumps(stance_meta, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(f\"\\nSaved ephemeral stance artifacts under {EPHEMERAL}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c15hgzKYLH0M",
        "outputId": "322a8b5e-dea5-40cf-c96d-456911ac7017"
      },
      "id": "c15hgzKYLH0M",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating stance embedding for: Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion.pdf (5605 chars)\n",
            "\n",
            "--- GPT Classification ---\n",
            "{\n",
            "  \"political_leaning\": \"\\\": \\\"progressive left\\\",\",\n",
            "  \"implied_stance\": \"\\\": \\\"social justice\\\",\",\n",
            "  \"summary\": \"\\\": \\\"The article criticizes Andrew Cuomo for allowing racism and Islamophobia against Democratic nominee Zohran Mamdani to go unchecked during the New York City mayoral campaign, arguing that NYC deserves better leadership.\\\"\"\n",
            "}\n",
            "\n",
            "--- Source / Tone Alignment ---\n",
            "{\n",
            "  \"political_leaning\": \"\\\": \\\"progressive left\\\",\",\n",
            "  \"implied_stance\": \"\\\": \\\"social justice\\\",\",\n",
            "  \"summary\": \"\\\": \\\"The article criticizes Andrew Cuomo for allowing racism and Islamophobia against Democratic nominee Zohran Mamdani to go unchecked during the New York City mayoral campaign, arguing that NYC deserves better leadership.\\\"\",\n",
            "  \"bias_family\": \"neutral\",\n",
            "  \"bias_score\": 0.0,\n",
            "  \"tone_score\": -0.8,\n",
            "  \"author_tone_match\": false\n",
            "}\n",
            "\n",
            "Using stance model: all-mpnet-base-v2\n",
            "Generated stance vector with shape (1, 768)\n",
            "\n",
            "Saved ephemeral stance artifacts under /content/unstructured-project/tmp/ephemeral_embeddings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 6 â€” Retrieval and Anti-Echo Analysis (Composite Topic + Stance)\n",
        "\n",
        "This stage retrieves conceptually similar articles from the Chroma database and scores them to identify ideologically diverse coverage of the same issue.\n",
        "\n",
        "---\n",
        "\n",
        "### Process Summary\n",
        "\n",
        "* **Load uploaded article metadata and embeddings**\n",
        "  * Canonical topics (list of up to 8 tags)\n",
        "  * Composite topic vector = [topic embedding (768 dims) + summary embedding (768 dims)]\n",
        "  * Stance embedding (512â€“768 dims depending on model)\n",
        "  * Bias and tone scores (from stance classification)\n",
        "* **Retrieve corpus candidates** from the Chroma database\n",
        "  * Each candidate has topic and stance embeddings plus metadata.\n",
        "* **Filter and compare** candidates that:\n",
        "  * Share at least 30% canonical topic overlap (`CANONICAL_TOPIC_THRESHOLD = 0.3`)\n",
        "  * Have â‰¥ 0.8 summary similarity (`SUMMARY_SIMILARITY_THRESHOLD = 0.8`)\n",
        "* **Compute similarity and divergence metrics**\n",
        "  * **canonical_topic_overlap** â€“ Jaccard or semantic overlap of canonical topics  \n",
        "  * **summary_similarity** â€“ cosine similarity of summary embeddings  \n",
        "  * **stance_similarity** â€“ cosine similarity of stance embeddings  \n",
        "  * **bias_diff** â€“ absolute difference in bias scores  \n",
        "  * **tone_diff** â€“ absolute difference in tone scores  \n",
        "\n",
        "---\n",
        "\n",
        "### Scoring Logic\n",
        "\n",
        "Each related article receives a single **anti-echo score**, defined by the following weighted formula:\n",
        "\n",
        "**Anti-Echo Score Formula**\n",
        "\n",
        "**anti_echo_score = (w_T_canonical Ã— canonical_overlap) + (w_T_summary Ã— summary_similarity) âˆ’ (w_S Ã— stance_similarity) âˆ’ (w_B Ã— bias_diff) âˆ’ (w_Tone Ã— tone_diff)**\n",
        "\n",
        "**Current Weights**\n",
        "\n",
        "| Weight | Description | Value |\n",
        "|---------|--------------|-------|\n",
        "| `w_T_canonical` | Canonical topic overlap | 0.5 |\n",
        "| `w_T_summary` | Summary embedding similarity | 10.0 |\n",
        "| `w_S` | Stance similarity penalty | 1.0 |\n",
        "| `w_B` | Bias difference penalty | 0.8 |\n",
        "| `w_Tone` | Tone difference penalty | 0.3 |\n",
        "\n",
        "**Interpretation:**  \n",
        "Higher scores indicate articles that share the same conceptual topics and arguments but are written from different ideological perspectives.  \n",
        "Topic and summary similarity increase the score, while stance similarity and bias/tone alignment decrease it.\n",
        "\n",
        "---\n",
        "\n",
        "### Ranking Outputs\n",
        "\n",
        "Articles are grouped and ranked by:\n",
        "\n",
        "| Category | Filter Criteria | Sort Key |\n",
        "|-----------|-----------------|----------|\n",
        "| **Same Topic â€” Different Source Bias** | High topic similarity; large bias difference | `bias_diff â†“` then `summary_similarity â†“` |\n",
        "| **Same Topic â€” Opposite Stance** | High topic similarity; low stance similarity | `stance_similarity â†‘` then `summary_similarity â†“` |\n",
        "| **Top Anti-Echo Candidates** | Highest overall anti-echo scores | `anti_echo_score â†“` |\n",
        "\n",
        "---\n",
        "\n",
        "### Outputs\n",
        "\n",
        "* **Console Sections**\n",
        "  * Ideological Spread Overview  \n",
        "  * Same Topic â€” Different Source Bias  \n",
        "  * Same Topic â€” Opposite Stance  \n",
        "  * Top Anti-Echo Candidates  \n",
        "* **CSV Export** (`*_anti_echo_analysis.csv`) including:\n",
        "  * `canonical_topic_overlap`\n",
        "  * `summary_similarity`\n",
        "  * `stance_similarity`\n",
        "  * `bias_diff`\n",
        "  * `tone_diff`\n",
        "  * `anti_echo_score`\n",
        "\n",
        "---\n",
        "\n",
        "### Notes\n",
        "\n",
        "* The pipeline now uses `latest_meta.txt` to ensure Stage 6 aligns with the most recent uploaded article.  \n",
        "* The higher `w_T_summary` (10.0) greatly emphasizes semantic similarity of summaries, ensuring topic cohesion.  \n",
        "* Lowering thresholds (e.g., `0.3 â†’ 0.2`, `0.8 â†’ 0.7`) increases recall but may introduce looser or tangential matches.\n"
      ],
      "metadata": {
        "id": "lXd0b52ZGCbr"
      },
      "id": "lXd0b52ZGCbr"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Stage 6 â€” Retrieval and Anti-Echo Analysis (SCRAPER-STYLE, 768-dim)\n",
        "# ================================================================\n",
        "\n",
        "import os, json, numpy as np, pandas as pd, torch\n",
        "from pathlib import Path\n",
        "from itertools import product\n",
        "from openai import OpenAI\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from getpass import getpass\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Tunable weights / thresholds\n",
        "# ---------------------------------------------------------------\n",
        "w_T_canonical = 0.5\n",
        "w_T_summary   = 10.0\n",
        "w_S           = 1.0\n",
        "w_B           = 0.8\n",
        "w_Tone        = 0.3\n",
        "\n",
        "CANONICAL_TOPIC_THRESHOLD = 0.3\n",
        "SUMMARY_SIMILARITY_THRESHOLD = 0.8\n",
        "TOP_N_RESULTS  = 10\n",
        "PRINT_TOP_N    = 3\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Paths / config\n",
        "# ---------------------------------------------------------------\n",
        "PROJECT_ROOT = Path(\"/content/unstructured-project\").resolve()\n",
        "CHROMA_PATH  = PROJECT_ROOT / \"chroma_db\"\n",
        "TMP          = PROJECT_ROOT / \"tmp\"\n",
        "EPHEMERAL    = TMP / \"ephemeral_embeddings\"\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# OpenAI key (for any later GPT calls)\n",
        "# ---------------------------------------------------------------\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"].strip():\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Load metadata + embeddings\n",
        "# ---------------------------------------------------------------\n",
        "latest_meta_ref = TMP / \"latest_meta.txt\"\n",
        "if not latest_meta_ref.exists():\n",
        "    raise FileNotFoundError(\"Missing latest_meta.txt â€” run Stage 4 first.\")\n",
        "\n",
        "latest_meta = Path(latest_meta_ref.read_text().strip())\n",
        "meta = json.load(open(latest_meta))\n",
        "article_id = Path(meta[\"filename\"]).stem\n",
        "bias_score_article = float(meta[\"bias_score\"])\n",
        "tone_score_article = float(meta.get(\"tone_score\", 0.0))\n",
        "print(f\"Running anti-echo retrieval for {meta['filename']} (bias={bias_score_article}, tone={tone_score_article})\")\n",
        "\n",
        "# ---- Load 768-dim topic vector and summary text (scraper-style) ----\n",
        "uploaded_base_topic = np.load(EPHEMERAL / f\"{article_id}_topic.npy\")\n",
        "\n",
        "summary_meta_path = EPHEMERAL / f\"{article_id}_topic_summary.json\"\n",
        "topic_summary = \"\"\n",
        "if summary_meta_path.exists():\n",
        "    topic_summary_meta = json.load(open(summary_meta_path))\n",
        "    topic_summary = topic_summary_meta.get(\"summary\", \"\")\n",
        "\n",
        "topic_model_name = CONFIG[\"embeddings\"][\"topic_model\"]\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "topic_embedder = SentenceTransformer(topic_model_name, device=device)\n",
        "\n",
        "if topic_summary:\n",
        "    uploaded_summary = topic_embedder.encode(\n",
        "        topic_summary, normalize_embeddings=True, show_progress_bar=False\n",
        "    )\n",
        "else:\n",
        "    uploaded_summary = np.zeros_like(uploaded_base_topic)\n",
        "\n",
        "stance_vec  = np.load(EPHEMERAL / f\"{article_id}_stance.npy\")\n",
        "topics_flat = json.load(open(EPHEMERAL / f\"{article_id}_topics_flat.json\"))\n",
        "\n",
        "print(f\"\\nUploaded summary: {topic_summary}\")\n",
        "print(f\"Base topic shape: {uploaded_base_topic.shape}, summary shape: {uploaded_summary.shape}\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Connect to Chroma\n",
        "# ---------------------------------------------------------------\n",
        "client_chroma = chromadb.PersistentClient(path=str(CHROMA_PATH))\n",
        "topic_coll  = client_chroma.get_collection(CONFIG[\"chroma_collections\"][\"topic\"])\n",
        "stance_coll = client_chroma.get_collection(CONFIG[\"chroma_collections\"][\"stance\"])\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Helpers\n",
        "# ---------------------------------------------------------------\n",
        "def parse_topics(obj):\n",
        "    if obj is None:\n",
        "        return []\n",
        "    if isinstance(obj, list):\n",
        "        return [t.strip() for t in obj if t.strip()]\n",
        "    if isinstance(obj, str):\n",
        "        parts = [t.strip() for t in obj.split(\";\") if t.strip()]\n",
        "        if len(parts) == 1 and parts[0].startswith(\"[\"):\n",
        "            try:\n",
        "                parsed = json.loads(parts[0])\n",
        "                if isinstance(parsed, list):\n",
        "                    return [t.strip() for t in parsed if isinstance(t, str)]\n",
        "            except Exception:\n",
        "                pass\n",
        "        return parts\n",
        "    return []\n",
        "\n",
        "def topic_overlap_score_multi(upload_topics, candidate_topics, anchors_dict=None):\n",
        "    A = set(t.lower() for t in parse_topics(upload_topics))\n",
        "    B = set(t.lower() for t in parse_topics(candidate_topics))\n",
        "    if not A or not B:\n",
        "        return 0.0\n",
        "    jaccard = len(A & B) / len(A | B)\n",
        "    if anchors_dict:\n",
        "        sims = []\n",
        "        for a, b in product(A, B):\n",
        "            if a in anchors_dict and b in anchors_dict:\n",
        "                va, vb = anchors_dict[a], anchors_dict[b]\n",
        "                sims.append(float(cosine_similarity([va], [vb])[0][0]))\n",
        "        if sims:\n",
        "            return max(jaccard, max(sims))\n",
        "    return jaccard\n",
        "\n",
        "def interpret_bias(score: float) -> str:\n",
        "    if score <= -0.6: return \"Progressive / Left\"\n",
        "    if -0.6 < score <= -0.2: return \"Center-Left\"\n",
        "    if -0.2 < score < 0.2:  return \"Center / Neutral\"\n",
        "    if 0.2 <= score < 0.6:  return \"Center-Right\"\n",
        "    if score >= 0.6:        return \"Conservative / Right\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Retrieve docs\n",
        "# ---------------------------------------------------------------\n",
        "topic_docs  = topic_coll.get(include=[\"embeddings\",\"metadatas\"])\n",
        "stance_docs = stance_coll.get(include=[\"embeddings\",\"metadatas\"])\n",
        "unique_articles_in_db = len(set(md.get(\"id\",\"\").split(\"::\")[0] for md in topic_docs[\"metadatas\"]))\n",
        "\n",
        "print(f\"\\nRetrieved from Chroma:\")\n",
        "print(f\"  - {len(topic_docs['ids'])} topic vectors\")\n",
        "print(f\"  - {len(stance_docs['ids'])} stance vectors\")\n",
        "print(f\"  - {unique_articles_in_db} unique articles\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Compare uploaded article to corpus\n",
        "# ---------------------------------------------------------------\n",
        "print(\"\\nScanning corpus for matches...\")\n",
        "anchors_path = PROJECT_ROOT / \"config/topic_anchors.npz\"\n",
        "anchors_npz  = np.load(anchors_path, allow_pickle=True)\n",
        "topic_anchors = {k: anchors_npz[k] for k in anchors_npz.files}\n",
        "\n",
        "def encode_text(text):\n",
        "    v = topic_embedder.encode(text, normalize_embeddings=True, show_progress_bar=False)\n",
        "    if v.ndim == 2: v = v.flatten()\n",
        "    return v\n",
        "\n",
        "all_matches = []\n",
        "for emb, md in zip(topic_docs[\"embeddings\"], topic_docs[\"metadatas\"]):\n",
        "    canonical_overlap = topic_overlap_score_multi(topics_flat, md.get(\"topics_flat\", []), anchors_dict=topic_anchors)\n",
        "    if canonical_overlap < CANONICAL_TOPIC_THRESHOLD:\n",
        "        continue\n",
        "\n",
        "    emb_array = np.array(emb)\n",
        "    # --- Handle both 768 (scraper) and 1536 (future) formats ---\n",
        "    if len(emb_array) == 1536:\n",
        "        candidate_summary_vec = emb_array[768:]\n",
        "        summary_similarity = cosine_similarity(uploaded_summary.reshape(1,-1), candidate_summary_vec.reshape(1,-1))[0][0]\n",
        "        old_summary = \"(new format)\"\n",
        "    else:\n",
        "        old_summary = md.get(\"openai_topic_summary\", \"\")\n",
        "        if old_summary:\n",
        "            candidate_summary_vec = encode_text(old_summary)\n",
        "            summary_similarity = cosine_similarity(uploaded_summary.reshape(1,-1), candidate_summary_vec.reshape(1,-1))[0][0]\n",
        "        else:\n",
        "            summary_similarity = cosine_similarity(uploaded_base_topic.reshape(1,-1), emb_array.reshape(1,-1))[0][0]\n",
        "\n",
        "    if summary_similarity < SUMMARY_SIMILARITY_THRESHOLD:\n",
        "        continue\n",
        "\n",
        "    article_id_base = md.get(\"id\",\"\").split(\"::\")[0]\n",
        "    all_matches.append({\n",
        "        \"article_id\": article_id_base,\n",
        "        \"source\": md.get(\"source\",\"\"),\n",
        "        \"title\": md.get(\"title\",\"\"),\n",
        "        \"url\": md.get(\"url\",\"\"),\n",
        "        \"bias_family\": md.get(\"bias_family\",\"\"),\n",
        "        \"topics_flat\": md.get(\"topics_flat\",[]),\n",
        "        \"canonical_overlap\": canonical_overlap,\n",
        "        \"summary_similarity\": summary_similarity,\n",
        "        \"candidate_summary\": old_summary,\n",
        "        \"metadata\": md\n",
        "    })\n",
        "\n",
        "print(f\"Found {len(all_matches)} topic matches from {len(set(m['article_id'] for m in all_matches))} unique articles\")\n",
        "\n",
        "best_matches = {}\n",
        "for m in all_matches:\n",
        "    aid = m[\"article_id\"]\n",
        "    if aid not in best_matches or m[\"summary_similarity\"] > best_matches[aid][\"summary_similarity\"]:\n",
        "        best_matches[aid] = m\n",
        "print(f\"After deduplication: {len(best_matches)} unique articles\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Stance, bias, and final scoring\n",
        "# ---------------------------------------------------------------\n",
        "scores = []\n",
        "for aid, m in best_matches.items():\n",
        "    md = m[\"metadata\"]\n",
        "\n",
        "    bias_db, tone_db = 0.0, 0.0\n",
        "    for s_md in stance_docs[\"metadatas\"]:\n",
        "        s_aid = s_md.get(\"id\",\"\").split(\"::\")[0]\n",
        "        if s_aid == aid:\n",
        "            try:\n",
        "                bias_db = float(s_md.get(\"bias_score\",0.0))\n",
        "            except Exception:\n",
        "                try:\n",
        "                    bias_db = float(json.loads(s_md.get(\"source_bias\",\"{}\")).get(\"bias_score\",0.0))\n",
        "                except Exception:\n",
        "                    bias_db = 0.0\n",
        "            tone_db = float(s_md.get(\"tone_score\",0.0))\n",
        "            break\n",
        "\n",
        "    bias_diff = abs(bias_score_article - bias_db)\n",
        "    tone_diff = abs(tone_score_article - tone_db)\n",
        "\n",
        "    stance_match = None\n",
        "    for s_emb, s_md in zip(stance_docs[\"embeddings\"], stance_docs[\"metadatas\"]):\n",
        "        if s_md.get(\"id\",\"\").split(\"::\")[0] == aid:\n",
        "            stance_match = s_emb\n",
        "            break\n",
        "\n",
        "    stance_sim = 0.0\n",
        "    if stance_match is not None:\n",
        "        stance_sim = cosine_similarity(stance_vec.reshape(1,-1), np.array(stance_match).reshape(1,-1))[0][0]\n",
        "\n",
        "    anti_echo_score = (\n",
        "        (w_T_canonical * m[\"canonical_overlap\"]) +\n",
        "        (w_T_summary   * m[\"summary_similarity\"]) -\n",
        "        (w_S * stance_sim) -\n",
        "        (w_B * bias_diff) -\n",
        "        (w_Tone * tone_diff)\n",
        "    )\n",
        "\n",
        "    scores.append({\n",
        "        \"article_id\": aid,\n",
        "        \"source\": m[\"source\"],\n",
        "        \"title\":  m[\"title\"],\n",
        "        \"url\":    m[\"url\"],\n",
        "        \"bias_family\": m[\"bias_family\"],\n",
        "        \"bias_score\": bias_db,\n",
        "        \"canonical_topic_overlap\": m[\"canonical_overlap\"],\n",
        "        \"summary_similarity\": m[\"summary_similarity\"],\n",
        "        \"stance_similarity\": stance_sim,\n",
        "        \"bias_diff\": bias_diff,\n",
        "        \"tone_diff\": tone_diff,\n",
        "        \"anti_echo_score\": anti_echo_score\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(scores)\n",
        "if df.empty:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"WARNING: No related articles found\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Try lowering thresholds or check your canonical topics:\")\n",
        "    print(f\"Your topics: {topics_flat}\")\n",
        "    raise ValueError(\"No related articles found\")\n",
        "\n",
        "print(f\"\\nFinal result: {len(df)} unique articles matched\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Ranking & display helpers\n",
        "# ---------------------------------------------------------------\n",
        "def print_header(title):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(title.upper().center(80))\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "def format_article_row(row):\n",
        "    title = (row.get(\"title\") or \"Untitled\").strip()\n",
        "    source = row.get(\"source\",\"unknown\")\n",
        "    bias_label = interpret_bias(row[\"bias_score\"])\n",
        "    metrics = (\n",
        "        f\"Canonical overlap: {row['canonical_topic_overlap']:.2f}   \"\n",
        "        f\"Summary sim: {row['summary_similarity']:.2f}   \"\n",
        "        f\"Stance sim: {row['stance_similarity']:.2f}   \"\n",
        "        f\"Bias diff: {row['bias_diff']:.2f}\"\n",
        "    )\n",
        "    lines = [\n",
        "        f\"â€¢ {title}\",\n",
        "        f\"  Source: {source}  ({bias_label})\",\n",
        "        f\"  {metrics}\",\n",
        "        f\"  Anti-echo score: {row['anti_echo_score']:.3f}\",\n",
        "    ]\n",
        "    if row.get(\"url\"): lines.append(f\"  Link: {row['url']}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def show_results(df, title, n=PRINT_TOP_N):\n",
        "    print_header(title)\n",
        "    if df.empty:\n",
        "        print(\"No matches found.\\n\")\n",
        "        return\n",
        "    for _, r in df.head(n).iterrows():\n",
        "        print(format_article_row(r))\n",
        "        print(\"-\"*80)\n",
        "\n",
        "def show_overview(df):\n",
        "    print_header(\"Ideological Spread Overview\")\n",
        "    left  = df[df[\"bias_score\"] < -0.2][\"source\"].unique()\n",
        "    right = df[df[\"bias_score\"] > 0.2][\"source\"].unique()\n",
        "    print(f\"Left / progressive outlets : {', '.join(left) if len(left)>0 else 'none'}\")\n",
        "    print(f\"Right / conservative outlets: {', '.join(right) if len(right)>0 else 'none'}\\n\")\n",
        "    print(f\"Your article summary: {topic_summary}\")\n",
        "    print(f\"Canonical topics: {', '.join(topics_flat[:3])}{'...' if len(topics_flat)>3 else ''}\\n\")\n",
        "    top = df.iloc[0]\n",
        "    print(f\"Top match: {top['source']} ({interpret_bias(top['bias_score'])})\")\n",
        "    print(f\"  Title: {(top['title'] or 'Untitled')[:60]}...\")\n",
        "    print(f\"  Anti-echo score: {top['anti_echo_score']:.3f}\\n\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Ranking & output\n",
        "# ---------------------------------------------------------------\n",
        "same_topic_diff_bias = df.sort_values([\"bias_diff\",\"summary_similarity\"], ascending=[False,False]).head(TOP_N_RESULTS)\n",
        "same_topic_opposite_stance = df[\n",
        "    (df[\"summary_similarity\"]>=SUMMARY_SIMILARITY_THRESHOLD) &\n",
        "    (df[\"canonical_topic_overlap\"]>=CANONICAL_TOPIC_THRESHOLD)\n",
        "].sort_values([\"stance_similarity\",\"summary_similarity\"], ascending=[True,False]).head(TOP_N_RESULTS)\n",
        "anti_echo_best = df.sort_values(\"anti_echo_score\", ascending=False).head(TOP_N_RESULTS)\n",
        "\n",
        "show_overview(anti_echo_best)\n",
        "show_results(same_topic_diff_bias, \"Same Specific Topic â€” Different Source Bias\")\n",
        "show_results(same_topic_opposite_stance, \"Same Specific Topic â€” Opposite Stance\")\n",
        "show_results(anti_echo_best, \"Top Anti-Echo Candidates (Best Overall Matches)\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Save\n",
        "# ---------------------------------------------------------------\n",
        "out_path = TMP / f\"{article_id}_anti_echo_analysis.csv\"\n",
        "df.to_csv(out_path, index=False)\n",
        "print(\"=\"*80)\n",
        "print(f\"Detailed analysis saved to: {out_path}\")\n",
        "print(f\"Total matches found: {len(df)}\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrJab83rIDvk",
        "outputId": "f721cd44-e371-44f6-d5e3-824fd271c1f9"
      },
      "id": "ZrJab83rIDvk",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running anti-echo retrieval for Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion.pdf (bias=0.0, tone=0.0)\n",
            "\n",
            "Uploaded summary: Andrew Cuomo's Islamophobic comments toward NYC mayoral candidate Zohran Mamdani highlight racism in the election campaign.\n",
            "Base topic shape: (768,), summary shape: (768,)\n",
            "\n",
            "Retrieved from Chroma:\n",
            "  - 2168 topic vectors\n",
            "  - 432 stance vectors\n",
            "  - 432 unique articles\n",
            "\n",
            "Scanning corpus for matches...\n",
            "Found 71 topic matches from 16 unique articles\n",
            "After deduplication: 16 unique articles\n",
            "\n",
            "Final result: 16 unique articles matched\n",
            "\n",
            "================================================================================\n",
            "                          IDEOLOGICAL SPREAD OVERVIEW                           \n",
            "================================================================================\n",
            "\n",
            "Left / progressive outlets : none\n",
            "Right / conservative outlets: foxnews, cityjournal, dailycaller\n",
            "\n",
            "Your article summary: Andrew Cuomo's Islamophobic comments toward NYC mayoral candidate Zohran Mamdani highlight racism in the election campaign.\n",
            "Canonical topics: Politics / US / Federal / Elections and Campaigns, Society / Culture & Identity / Social Issues, Ethics / Governance & Accountability / Integrity...\n",
            "\n",
            "Top match: aljazeera (Center-Left)\n",
            "  Title: play...\n",
            "  Anti-echo score: 8.983\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                  SAME SPECIFIC TOPIC â€” DIFFERENT SOURCE BIAS                   \n",
            "================================================================================\n",
            "\n",
            "â€¢ Cuomo slams Mamdani as an &#x27;offender&#x27; against Jews, Blacks and more New Yorkers | Fox News\n",
            "  Source: foxnews  (Conservative / Right)\n",
            "  Canonical overlap: 0.44   Summary sim: 0.94   Stance sim: 0.72   Bias diff: 0.80\n",
            "  Anti-echo score: 8.236\n",
            "  Link: https://www.foxnews.com/politics/cuomo-rips-mamdanis-victim-narrative-says-dem-socialist-offender-against-9-11-families-jews-more\n",
            "--------------------------------------------------------------------------------\n",
            "â€¢ JD Vance criticizes Mamdani over 9/11 comment during campaign event | Fox News\n",
            "  Source: foxnews  (Conservative / Right)\n",
            "  Canonical overlap: 0.44   Summary sim: 0.90   Stance sim: 0.58   Bias diff: 0.80\n",
            "  Anti-echo score: 7.968\n",
            "  Link: https://www.foxnews.com/politics/jd-vance-criticizes-mamdani-claiming-according-him-the-real-victim-9-11-his-auntie\n",
            "--------------------------------------------------------------------------------\n",
            "â€¢ Bill Maher clashes with guest over NYC mayor candidate&#x27;s dual citizenship | Fox News\n",
            "  Source: foxnews  (Conservative / Right)\n",
            "  Canonical overlap: 0.44   Summary sim: 0.87   Stance sim: 0.54   Bias diff: 0.80\n",
            "  Anti-echo score: 7.729\n",
            "  Link: https://www.foxnews.com/media/bill-maher-warns-fellow-democrats-mamdanis-impact-says-whole-party-ballot\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                     SAME SPECIFIC TOPIC â€” OPPOSITE STANCE                      \n",
            "================================================================================\n",
            "\n",
            "â€¢ Gavin Newsom Talks AI With Bill Clinton? | The Daily Caller\n",
            "  Source: dailycaller  (Conservative / Right)\n",
            "  Canonical overlap: 0.30   Summary sim: 0.81   Stance sim: 0.39   Bias diff: 0.70\n",
            "  Anti-echo score: 7.284\n",
            "  Link: https://dailycaller.com/2025/10/25/gavin-newsom-bill-clinton-artificial-intelligence-california-america-china/\n",
            "--------------------------------------------------------------------------------\n",
            "â€¢ â€˜Democrat-Causedâ€™: Stephen Miller Goes Off On Newsom Handing Out CDLs To Illegals, Following Horrific Crash | The Daily Caller\n",
            "  Source: dailycaller  (Conservative / Right)\n",
            "  Canonical overlap: 0.62   Summary sim: 0.81   Stance sim: 0.51   Bias diff: 0.70\n",
            "  Anti-echo score: 7.350\n",
            "  Link: https://dailycaller.com/2025/10/24/stephen-miller-gavin-newsom-handing-cdl/\n",
            "--------------------------------------------------------------------------------\n",
            "â€¢ â€˜Not All Racist, Bigoted Moronsâ€™: Democrat Rep Stuns With His Take On Trump Voters | The Daily Caller\n",
            "  Source: dailycaller  (Conservative / Right)\n",
            "  Canonical overlap: 0.62   Summary sim: 0.81   Stance sim: 0.53   Bias diff: 0.70\n",
            "  Anti-echo score: 7.355\n",
            "  Link: https://dailycaller.com/2025/10/24/democrat-adam-smith-trump-supporters-party-outreach-racist-bigoted-morons/\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                TOP ANTI-ECHO CANDIDATES (BEST OVERALL MATCHES)                 \n",
            "================================================================================\n",
            "\n",
            "â€¢ play\n",
            "  Source: aljazeera  (Center-Left)\n",
            "  Canonical overlap: 0.62   Summary sim: 0.95   Stance sim: 0.69   Bias diff: 0.20\n",
            "  Anti-echo score: 8.983\n",
            "  Link: https://www.aljazeera.com/video/newsfeed/2025/10/25/zohran-mamdani-condemns-islamophobic-attacks-in-nyc-mayoral-race?traffic_source=rss\n",
            "--------------------------------------------------------------------------------\n",
            "â€¢ Cuomo slams Mamdani as an &#x27;offender&#x27; against Jews, Blacks and more New Yorkers | Fox News\n",
            "  Source: foxnews  (Conservative / Right)\n",
            "  Canonical overlap: 0.44   Summary sim: 0.94   Stance sim: 0.72   Bias diff: 0.80\n",
            "  Anti-echo score: 8.236\n",
            "  Link: https://www.foxnews.com/politics/cuomo-rips-mamdanis-victim-narrative-says-dem-socialist-offender-against-9-11-families-jews-more\n",
            "--------------------------------------------------------------------------------\n",
            "â€¢ play\n",
            "  Source: aljazeera  (Center-Left)\n",
            "  Canonical overlap: 0.44   Summary sim: 0.87   Stance sim: 0.63   Bias diff: 0.20\n",
            "  Anti-echo score: 8.129\n",
            "  Link: https://www.aljazeera.com/news/2025/10/25/early-voting-begins-in-nyc-mayors-race-with-mamdani-ahead-in-polls?traffic_source=rss\n",
            "--------------------------------------------------------------------------------\n",
            "================================================================================\n",
            "Detailed analysis saved to: /content/unstructured-project/tmp/Cuomo lets racism against Mamdani slide. NYC deserves better _ Opinion_anti_echo_analysis.csv\n",
            "Total matches found: 16\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b14dfa69efaa475e873a376875bd68cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38592cf818af46d89e87669343772742",
              "IPY_MODEL_98a9deb1eeb4486fa7917950379a383d",
              "IPY_MODEL_6a818980309840e6a186dfe4a767a509"
            ],
            "layout": "IPY_MODEL_2af2c586cea64708b84dff72b060f3b6"
          }
        },
        "38592cf818af46d89e87669343772742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_288a8a829f0744cbb4f42aa8dd827fed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56068a5dc1604b27bf4a75471c349f99",
            "value": "batches/batch_20251025T173713Z_5dd9b9dd/(â€¦):â€‡100%"
          }
        },
        "98a9deb1eeb4486fa7917950379a383d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a02b065d95409ba937f8985079b480",
            "max": 89933,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_112b4d297a4e45fbaff79c1a24080957",
            "value": 89933
          }
        },
        "6a818980309840e6a186dfe4a767a509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbe340b2b0344ca8add4c29c1d58f075",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5d67003856ac484eab029db4a0cf9ea1",
            "value": "â€‡89.9k/89.9kâ€‡[00:01&lt;00:00,â€‡68.2kB/s]"
          }
        },
        "2af2c586cea64708b84dff72b060f3b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288a8a829f0744cbb4f42aa8dd827fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56068a5dc1604b27bf4a75471c349f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a02b065d95409ba937f8985079b480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112b4d297a4e45fbaff79c1a24080957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbe340b2b0344ca8add4c29c1d58f075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d67003856ac484eab029db4a0cf9ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61c41e3693cf465ca667ed9cc9fcd56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4905a4616eb8423cb481f5a67ad3506b",
              "IPY_MODEL_51be6a45946948539b826e012a41d071",
              "IPY_MODEL_8dfa1fb975b2446a985315f33598bc98"
            ],
            "layout": "IPY_MODEL_85839a0b1eee4e759c447c2f28d9b1ad"
          }
        },
        "4905a4616eb8423cb481f5a67ad3506b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5843a223c02a4aa7b19e39c1a8e55af4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a2a325c0f6c41489ea1514586170b32",
            "value": "batches/batch_20251025T173713Z_5dd9b9dd/(â€¦):â€‡100%"
          }
        },
        "51be6a45946948539b826e012a41d071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57c83ccab91f40c8ba102bb116a7bf03",
            "max": 18725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9dc743f0f504642a1a8b68b55ff2a56",
            "value": 18725
          }
        },
        "8dfa1fb975b2446a985315f33598bc98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fce3b13dcd4410e8e6fdaa158ef958a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_808727bc2ad2440b839cfa1388dbd400",
            "value": "â€‡18.7k/18.7kâ€‡[00:00&lt;00:00,â€‡35.4kB/s]"
          }
        },
        "85839a0b1eee4e759c447c2f28d9b1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5843a223c02a4aa7b19e39c1a8e55af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2a325c0f6c41489ea1514586170b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57c83ccab91f40c8ba102bb116a7bf03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9dc743f0f504642a1a8b68b55ff2a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fce3b13dcd4410e8e6fdaa158ef958a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808727bc2ad2440b839cfa1388dbd400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f6932e98a1a44629814e0b80b2bc4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a4e0f32ae8848d099a6978655830433",
              "IPY_MODEL_e8aa060eec8b42be85a4fe232232f24b",
              "IPY_MODEL_2a40dadc6e834091bc3fc906e253a1f6"
            ],
            "layout": "IPY_MODEL_253165468f3d4fb69c277bbbdea2c3a4"
          }
        },
        "1a4e0f32ae8848d099a6978655830433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aeccfd98fed4f25973c8e54a7cfaab5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_577826cf47474c21a3336117f97c9c7f",
            "value": "metadata_topic.jsonl:â€‡"
          }
        },
        "e8aa060eec8b42be85a4fe232232f24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad1f7aa5ddc44b1a5fddd50bb6502bd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_002a94a6e92a4c38bdccdbc3495031db",
            "value": 1
          }
        },
        "2a40dadc6e834091bc3fc906e253a1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a01f9761bf450389915153f1be86b3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8c8563a5e3344d94a526cb850520d9bc",
            "value": "â€‡110k/?â€‡[00:00&lt;00:00,â€‡8.58MB/s]"
          }
        },
        "253165468f3d4fb69c277bbbdea2c3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aeccfd98fed4f25973c8e54a7cfaab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577826cf47474c21a3336117f97c9c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ad1f7aa5ddc44b1a5fddd50bb6502bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "002a94a6e92a4c38bdccdbc3495031db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25a01f9761bf450389915153f1be86b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c8563a5e3344d94a526cb850520d9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1832738a5cb4ce3b830598ab2666cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12b20ed181104483ab7ed69bdc25b5e2",
              "IPY_MODEL_b7d48d3032e1418782f959ab438fc947",
              "IPY_MODEL_2bcd4e4243874051af094a14036c5451"
            ],
            "layout": "IPY_MODEL_5c97586d5099449599c8fb634e9374b9"
          }
        },
        "12b20ed181104483ab7ed69bdc25b5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066bf0c6e46949e0972b87505e46132b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5e17a0f6edf4e8d86c209f46134fcab",
            "value": "metadata_stance.jsonl:â€‡"
          }
        },
        "b7d48d3032e1418782f959ab438fc947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39a4eb435c8949219caed152a57d9a8e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53c3b0c363b04deb8fdab7860fddf033",
            "value": 1
          }
        },
        "2bcd4e4243874051af094a14036c5451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f67321f3af84daca3760d04672690cd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2fc0dc114e394dddb0e373c7f4fe1db7",
            "value": "â€‡12.3k/?â€‡[00:00&lt;00:00,â€‡1.01MB/s]"
          }
        },
        "5c97586d5099449599c8fb634e9374b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066bf0c6e46949e0972b87505e46132b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5e17a0f6edf4e8d86c209f46134fcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a4eb435c8949219caed152a57d9a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "53c3b0c363b04deb8fdab7860fddf033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f67321f3af84daca3760d04672690cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fc0dc114e394dddb0e373c7f4fe1db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c40f5c79a17d4af0a76904be708624ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9310906c20c342ef8b914cb301272163",
              "IPY_MODEL_3290cfd2c4634c8f9e4d50262b0628ee",
              "IPY_MODEL_a46ba425988f42b289da68dfce4f0bfd"
            ],
            "layout": "IPY_MODEL_ada253e75dd748ea80efa8dbbb2d5d91"
          }
        },
        "9310906c20c342ef8b914cb301272163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_892422508f304124b9c59094592a1a65",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9460e15c318d4696815c339476804514",
            "value": "batches/batch_20251025T181241Z_d8804259/(â€¦):â€‡100%"
          }
        },
        "3290cfd2c4634c8f9e4d50262b0628ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb84cd7c682439188764c1c4b8b2631",
            "max": 3039326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9edf3afd6d404f15812c162166674817",
            "value": 3039326
          }
        },
        "a46ba425988f42b289da68dfce4f0bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2eadb921032488083e974da68dc53a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_87cded6e38264caca0b3d7332a1dce44",
            "value": "â€‡3.04M/3.04Mâ€‡[00:00&lt;00:00,â€‡4.73MB/s]"
          }
        },
        "ada253e75dd748ea80efa8dbbb2d5d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892422508f304124b9c59094592a1a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9460e15c318d4696815c339476804514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfb84cd7c682439188764c1c4b8b2631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9edf3afd6d404f15812c162166674817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2eadb921032488083e974da68dc53a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cded6e38264caca0b3d7332a1dce44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2b34d28948248528b540429497665cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99f8435ce3a842cbae9ba710df93fd66",
              "IPY_MODEL_fa6eeaa786c64e4faf9581899ccfe796",
              "IPY_MODEL_ecd58b7072564756b414ff87e96de280"
            ],
            "layout": "IPY_MODEL_c310bea32c0a4dfd9a1956b18af79195"
          }
        },
        "99f8435ce3a842cbae9ba710df93fd66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3471f2078742458bacf5c330e9833725",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d206645b80754505861fd52fee80ed1f",
            "value": "batches/batch_20251025T181241Z_d8804259/(â€¦):â€‡100%"
          }
        },
        "fa6eeaa786c64e4faf9581899ccfe796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab73a96e36254be19500b74c49484063",
            "max": 613911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4d03b2cea974ee6b2169ff7d09d3240",
            "value": 613911
          }
        },
        "ecd58b7072564756b414ff87e96de280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c667fa3511664bedb1369c6804477b4a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_96199e60c22d4067bb6c6b5b8deb8ab5",
            "value": "â€‡614k/614kâ€‡[00:00&lt;00:00,â€‡1.10MB/s]"
          }
        },
        "c310bea32c0a4dfd9a1956b18af79195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3471f2078742458bacf5c330e9833725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d206645b80754505861fd52fee80ed1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab73a96e36254be19500b74c49484063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d03b2cea974ee6b2169ff7d09d3240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c667fa3511664bedb1369c6804477b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96199e60c22d4067bb6c6b5b8deb8ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c8fe719550a4880933cd53c84f86684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b8e082d1bad47e1955a671250df98ec",
              "IPY_MODEL_2a57d5a395a146f893589d06c33fcc91",
              "IPY_MODEL_504d4c79456b424cb6adc3635d94b101"
            ],
            "layout": "IPY_MODEL_2702b7dfa9a9474894b0eb3e4ba8eb4d"
          }
        },
        "7b8e082d1bad47e1955a671250df98ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624fb19c733c4337ba3ad69ad5304ea6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b30ed259c5ce48179b591b951a8f470a",
            "value": "metadata_topic.jsonl:â€‡"
          }
        },
        "2a57d5a395a146f893589d06c33fcc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2de93038008040d6804a5ae5957fd5a7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d7f21d07f1e4e1c8af8071f8b30abbb",
            "value": 1
          }
        },
        "504d4c79456b424cb6adc3635d94b101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_762a94d6c7644db3a09f619a0ea4da63",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ac28b4cd118414fb9788702720e6245",
            "value": "â€‡3.84M/?â€‡[00:00&lt;00:00,â€‡161MB/s]"
          }
        },
        "2702b7dfa9a9474894b0eb3e4ba8eb4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624fb19c733c4337ba3ad69ad5304ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b30ed259c5ce48179b591b951a8f470a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2de93038008040d6804a5ae5957fd5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5d7f21d07f1e4e1c8af8071f8b30abbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "762a94d6c7644db3a09f619a0ea4da63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac28b4cd118414fb9788702720e6245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe034bf8eeb4c7e813bc6954451a669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c782170462e41c9929c5d0c6e60def3",
              "IPY_MODEL_f67b60809c454b5fad638c005f6b6606",
              "IPY_MODEL_4a56ba373d1c452e9f400bc1ef19ae5c"
            ],
            "layout": "IPY_MODEL_cac0d6cf736f4e0ca4f0055e717ca4c2"
          }
        },
        "6c782170462e41c9929c5d0c6e60def3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0ce5cdc77d5490d9866fb0413091ed3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c8492d0207234509a680761130961d14",
            "value": "metadata_stance.jsonl:â€‡"
          }
        },
        "f67b60809c454b5fad638c005f6b6606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3453ebedf3e849f98dd692b881f2fe1f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fdd29e789314b738dcdf83ee2af39c7",
            "value": 1
          }
        },
        "4a56ba373d1c452e9f400bc1ef19ae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43416e6109a941e8a14c4295257587cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c1bb1bac3108421ebf5a08f706be6d12",
            "value": "â€‡432k/?â€‡[00:00&lt;00:00,â€‡37.7MB/s]"
          }
        },
        "cac0d6cf736f4e0ca4f0055e717ca4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ce5cdc77d5490d9866fb0413091ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8492d0207234509a680761130961d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3453ebedf3e849f98dd692b881f2fe1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9fdd29e789314b738dcdf83ee2af39c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43416e6109a941e8a14c4295257587cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bb1bac3108421ebf5a08f706be6d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}