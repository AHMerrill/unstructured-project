{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Note: this was built on colab pro and designed for an A100 GPU / cuda. It will still run on other runtimes, just slower"
      ],
      "metadata": {
        "id": "tq9rkaDkQ_Dn"
      },
      "id": "tq9rkaDkQ_Dn"
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/anti_echo"
      ],
      "metadata": {
        "id": "O1EltHnBVZwC"
      },
      "id": "O1EltHnBVZwC",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/sample_data/"
      ],
      "metadata": {
        "id": "_mG0dF6evfbU"
      },
      "id": "_mG0dF6evfbU",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 1 of N - environment and workspace\n",
        "\n",
        "Purpose\n",
        "Install core dependencies, set up a clean workspace at /content/anti_echo, and print diagnostics so collaborators can debug quickly.\n",
        "\n",
        "Why this matters\n",
        "Pinned installs reduce breakage. A consistent folder layout keeps artifacts predictable. Diagnostics help when the runtime changes.\n",
        "\n",
        "Outputs\n",
        "Directories created under /content/anti_echo, environment flags set, package versions printed."
      ],
      "metadata": {
        "id": "z3lyMabwG0TZ"
      },
      "id": "z3lyMabwG0TZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 1 of N: environment and workspace\n",
        "# Colab safe. No Drive mount. Heavy comments for clarity.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "def pip_install(pkgs):\n",
        "    # Quiet installs but still show what is being installed for reproducibility\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs\n",
        "    print(\"Installing:\", \" \".join(pkgs))\n",
        "    subprocess.check_call(cmd)\n",
        "\n",
        "# Core dependencies with sane pins or upper bounds\n",
        "pip_install([\n",
        "    \"feedparser==6.0.10\",                    # RSS parsing\n",
        "    \"trafilatura>=1.6.2,<2.0\",               # robust article extraction\n",
        "    \"sentence-transformers>=2.6.1,<3.0\",     # embeddings\n",
        "    \"chromadb>=0.5.5,<0.6.0\",                # local vector store\n",
        "    \"huggingface_hub>=0.24.0,<0.28.0\",       # HF dataset and file ops\n",
        "    \"pyyaml>=6.0.1,<7.0\",                    # config parsing\n",
        "    \"numpy>=1.26.4,<3.0\",                    # arrays\n",
        "    \"tqdm>=4.66.0,<5.0\",                     # progress\n",
        "    \"requests>=2.31.0,<3.0\",                 # HTTP\n",
        "    \"rapidfuzz>=3.6.0,<4.0\",                 # dedupe or fuzzy utils\n",
        "    \"scikit-learn>=1.4.0,<2.0\",              # clustering for topics\n",
        "    \"transformers>=4.43.0,<5.0\",             # summarization model\n",
        "    \"nltk>=3.8.1,<4.0\"                       # sentence splitting\n",
        "])\n",
        "\n",
        "# Optional accelerator. If import fails, install a compatible torch\n",
        "try:\n",
        "    import torch\n",
        "except Exception:\n",
        "    pip_install([\"torch>=2.2.0,<3.0\"])\n",
        "    import torch\n",
        "\n",
        "# Define a single project root for all artifacts in this session\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "SUBDIRS = [\n",
        "    \"raw\",        # scraped article text and sidecar metadata\n",
        "    \"batches\",    # packaged embeddings and manifest before HF upload\n",
        "    \"chroma_db\",  # local persistent Chroma store\n",
        "    \"logs\",       # run logs\n",
        "    \"feeds\",      # index and feed state\n",
        "    \"tmp\"         # scratch space\n",
        "]\n",
        "for d in SUBDIRS:\n",
        "    (PROJECT_ROOT / d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Set environment flags to reduce noise and avoid accidental multithreading bugs\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"CHROMA_TELEMETRY_ENABLED\"] = \"false\"\n",
        "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\n",
        "\n",
        "# Print environment diagnostics for reproducibility and easy debugging\n",
        "import platform, json\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "\n",
        "def v(name):\n",
        "    try:\n",
        "        return version(name)\n",
        "    except PackageNotFoundError:\n",
        "        return \"not-installed\"\n",
        "\n",
        "info = {\n",
        "    \"python\": sys.version.split()[0],\n",
        "    \"platform\": platform.platform(),\n",
        "    \"packages\": {\n",
        "        \"feedparser\": v(\"feedparser\"),\n",
        "        \"trafilatura\": v(\"trafilatura\"),\n",
        "        \"sentence-transformers\": v(\"sentence-transformers\"),\n",
        "        \"chromadb\": v(\"chromadb\"),\n",
        "        \"huggingface_hub\": v(\"huggingface-hub\"),\n",
        "        \"PyYAML\": v(\"PyYAML\"),\n",
        "        \"numpy\": v(\"numpy\"),\n",
        "        \"rapidfuzz\": v(\"rapidfuzz\"),\n",
        "        \"torch\": v(\"torch\"),\n",
        "        \"tqdm\": v(\"tqdm\"),\n",
        "        \"requests\": v(\"requests\"),\n",
        "        \"scikit-learn\": v(\"scikit-learn\"),\n",
        "        \"transformers\": v(\"transformers\"),\n",
        "        \"nltk\": v(\"nltk\"),\n",
        "    },\n",
        "    \"paths\": {\n",
        "        \"project_root\": str(PROJECT_ROOT),\n",
        "        \"raw\": str(PROJECT_ROOT / \"raw\"),\n",
        "        \"batches\": str(PROJECT_ROOT / \"batches\"),\n",
        "        \"chroma_db\": str(PROJECT_ROOT / \"chroma_db\"),\n",
        "        \"logs\": str(PROJECT_ROOT / \"logs\"),\n",
        "        \"feeds\": str(PROJECT_ROOT / \"feeds\"),\n",
        "        \"tmp\": str(PROJECT_ROOT / \"tmp\"),\n",
        "    }\n",
        "}\n",
        "\n",
        "# CUDA info is helpful to know if summarization can use GPU\n",
        "info[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
        "if info[\"cuda_available\"]:\n",
        "    info[\"cuda_device_name\"] = torch.cuda.get_device_name(0)\n",
        "\n",
        "print(json.dumps(info, indent=2))\n",
        "\n",
        "# A tiny workspace readme helps collaborators quickly orient\n",
        "workspace_readme = PROJECT_ROOT / \"README_WORKSPACE.txt\"\n",
        "if not workspace_readme.exists():\n",
        "    workspace_readme.write_text(textwrap.dedent(\"\"\"\n",
        "        anti echo chamber - Colab workspace\n",
        "        This directory is ephemeral per session.\n",
        "        Do not commit files from here directly.\n",
        "        Subdirs:\n",
        "          raw        - local scraped texts and meta for this session\n",
        "          batches    - locally packaged batches before HF upload\n",
        "          chroma_db  - local Chroma rebuild target\n",
        "          logs       - run logs\n",
        "          feeds      - runtime feed artifacts\n",
        "          tmp        - scratch space\n",
        "    \"\"\").strip() + \"\\n\", encoding=\"utf-8\")\n",
        "print(f\"Workspace ready at {PROJECT_ROOT}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zffpD2rNG0Ax",
        "outputId": "31aa952b-bd93-4288-8db6-f0627506d064"
      },
      "id": "zffpD2rNG0Ax",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing: feedparser==6.0.10 trafilatura>=1.6.2,<2.0 sentence-transformers>=2.6.1,<3.0 chromadb>=0.5.5,<0.6.0 huggingface_hub>=0.24.0,<0.28.0 pyyaml>=6.0.1,<7.0 numpy>=1.26.4,<3.0 tqdm>=4.66.0,<5.0 requests>=2.31.0,<3.0 rapidfuzz>=3.6.0,<4.0 scikit-learn>=1.4.0,<2.0 transformers>=4.43.0,<5.0 nltk>=3.8.1,<4.0\n",
            "{\n",
            "  \"python\": \"3.12.12\",\n",
            "  \"platform\": \"Linux-6.6.105+-x86_64-with-glibc2.35\",\n",
            "  \"packages\": {\n",
            "    \"feedparser\": \"6.0.10\",\n",
            "    \"trafilatura\": \"1.12.2\",\n",
            "    \"sentence-transformers\": \"2.7.0\",\n",
            "    \"chromadb\": \"0.5.23\",\n",
            "    \"huggingface_hub\": \"0.27.1\",\n",
            "    \"PyYAML\": \"6.0.3\",\n",
            "    \"numpy\": \"2.0.2\",\n",
            "    \"rapidfuzz\": \"3.14.1\",\n",
            "    \"torch\": \"2.8.0+cu126\",\n",
            "    \"tqdm\": \"4.67.1\",\n",
            "    \"requests\": \"2.32.4\",\n",
            "    \"scikit-learn\": \"1.6.1\",\n",
            "    \"transformers\": \"4.46.3\",\n",
            "    \"nltk\": \"3.9.1\"\n",
            "  },\n",
            "  \"paths\": {\n",
            "    \"project_root\": \"/content/anti_echo\",\n",
            "    \"raw\": \"/content/anti_echo/raw\",\n",
            "    \"batches\": \"/content/anti_echo/batches\",\n",
            "    \"chroma_db\": \"/content/anti_echo/chroma_db\",\n",
            "    \"logs\": \"/content/anti_echo/logs\",\n",
            "    \"feeds\": \"/content/anti_echo/feeds\",\n",
            "    \"tmp\": \"/content/anti_echo/tmp\"\n",
            "  },\n",
            "  \"cuda_available\": true,\n",
            "  \"cuda_device_name\": \"NVIDIA A100-SXM4-80GB\"\n",
            "}\n",
            "Workspace ready at /content/anti_echo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 2 of N - config and paths bootstrap\n",
        "\n",
        "Purpose\n",
        "Pull config and label maps from your GitHub repo, cache them locally in the Colab session, validate required keys, and create runtime dirs from config.\n",
        "\n",
        "Why this matters\n",
        "Single source of truth for model names, dims, batch filenames, and collection names. Keeps the notebook aligned with the repo.\n",
        "\n",
        "Outputs\n",
        "CONFIG, STANCE_AXES, TOPIC_LABELS in memory, directories created, and HF_DATASET_ID exported to env.\n"
      ],
      "metadata": {
        "id": "rJEp6xNjHjAz"
      },
      "id": "rJEp6xNjHjAz"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Setup 2 of N: config and paths bootstrap (v5.0, config-driven)\n",
        "# Loads config.yaml (local or GitHub), fetches topics.json and ideological JSONs,\n",
        "# and ensures everything is cached locally for downstream setups.\n",
        "# ==============================\n",
        "\n",
        "import os, json, yaml, requests\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "CONFIG_CACHE = PROJECT_ROOT / \"config_cache\"\n",
        "CONFIG_DIR   = PROJECT_ROOT / \"config\"\n",
        "for d in (CONFIG_CACHE, CONFIG_DIR):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Candidate config files ---\n",
        "CFG_CANDIDATES = [\"config/config.yaml\", \"config/config.yml\", \"config/config.json\"]\n",
        "\n",
        "# --- Try to load local config first ---\n",
        "local_cfg = PROJECT_ROOT / \"config.yaml\"\n",
        "if local_cfg.exists():\n",
        "    cfg_txt = local_cfg.read_text(encoding=\"utf-8\")\n",
        "    cfg_path, cfg_url = str(local_cfg), \"(local)\"\n",
        "else:\n",
        "    # Temporary bootstrap to old defaults just to fetch YAML\n",
        "    TMP_REPO_OWNER = \"AHMerrill\"\n",
        "    TMP_REPO_NAME  = \"unstructured-project\"\n",
        "    TMP_BRANCH     = \"main\"\n",
        "\n",
        "    def raw_url_temp(path):\n",
        "        return f\"https://raw.githubusercontent.com/{TMP_REPO_OWNER}/{TMP_REPO_NAME}/{TMP_BRANCH}/{path.lstrip('/')}\"\n",
        "\n",
        "    # --- Fetch remote YAML ---\n",
        "    def fetch_text_first(paths):\n",
        "        last_err = None\n",
        "        for p in paths:\n",
        "            url = raw_url_temp(p)\n",
        "            try:\n",
        "                r = requests.get(url, timeout=20)\n",
        "                if r.status_code == 200 and r.text.strip():\n",
        "                    return r.text, p, url\n",
        "            except Exception as e:\n",
        "                last_err = e\n",
        "        raise RuntimeError(f\"Could not fetch any of {paths}. Last error: {last_err}\")\n",
        "\n",
        "    cfg_txt, cfg_path, cfg_url = fetch_text_first(CFG_CANDIDATES)\n",
        "    (CONFIG_CACHE / Path(cfg_path).name).write_text(cfg_txt, encoding=\"utf-8\")\n",
        "\n",
        "# --- Parse YAML/JSON into CONFIG ---\n",
        "CONFIG = yaml.safe_load(cfg_txt) if cfg_path.endswith((\".yaml\", \".yml\")) else json.loads(cfg_txt)\n",
        "\n",
        "# --- Use GitHub values from YAML going forward ---\n",
        "REPO_OWNER = CONFIG[\"github\"][\"owner\"]\n",
        "REPO_NAME  = CONFIG[\"github\"][\"repo\"]\n",
        "BRANCH     = CONFIG[\"github\"].get(\"branch\", \"main\")\n",
        "HF_DATASET_ID = CONFIG[\"hf_dataset_id\"]\n",
        "\n",
        "def raw_url(path: str) -> str:\n",
        "    \"\"\"Compose a raw GitHub URL for a given path in the configured repo.\"\"\"\n",
        "    return f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/{path.lstrip('/')}\"\n",
        "\n",
        "# --- Fetch topics.json ---\n",
        "TOPICS_PATH = CONFIG_DIR / \"topics.json\"\n",
        "TOPICS_URL  = raw_url(\"config/topics.json\")\n",
        "\n",
        "if not TOPICS_PATH.exists():\n",
        "    print(f\"Fetching topics.json from {TOPICS_URL} ...\")\n",
        "    r = requests.get(TOPICS_URL, timeout=20)\n",
        "    r.raise_for_status()\n",
        "    TOPICS_PATH.write_text(r.text, encoding=\"utf-8\")\n",
        "\n",
        "try:\n",
        "    TOPIC_LABELS = json.load(open(TOPICS_PATH, encoding=\"utf-8\"))\n",
        "    print(f\"Loaded {len(TOPIC_LABELS)} topic clusters from topics.json\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Failed to load topics.json ({e})\")\n",
        "    TOPIC_LABELS = {}\n",
        "\n",
        "# --- Fetch optional topic_anchors.npz ---\n",
        "ANCHORS_PATH = CONFIG_DIR / \"topic_anchors.npz\"\n",
        "ANCHORS_URL  = raw_url(\"config/topic_anchors.npz\")\n",
        "if not ANCHORS_PATH.exists():\n",
        "    print(f\"Fetching topic_anchors.npz from {ANCHORS_URL} ...\")\n",
        "    r = requests.get(ANCHORS_URL, timeout=30)\n",
        "    if r.status_code == 200:\n",
        "        ANCHORS_PATH.write_bytes(r.content)\n",
        "    else:\n",
        "        print(f\"Warning: topic_anchors.npz not found ({r.status_code})\")\n",
        "\n",
        "# --- Ensure ideological JSONs are cached locally ---\n",
        "def fetch_if_missing(filename):\n",
        "    local_path = CONFIG_DIR / filename\n",
        "    if not local_path.exists():\n",
        "        url = raw_url(f\"config/{filename}\")\n",
        "        print(f\"Fetching {filename} from {url} ...\")\n",
        "        r = requests.get(url, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        local_path.write_text(r.text, encoding=\"utf-8\")\n",
        "    return local_path\n",
        "\n",
        "LEANINGS_PATH = fetch_if_missing(\"political_leanings.json\")\n",
        "STANCES_PATH  = fetch_if_missing(\"implied_stances.json\")\n",
        "BIAS_PATH     = fetch_if_missing(\"source_bias.json\")\n",
        "\n",
        "POLITICAL_LEANINGS = json.load(open(LEANINGS_PATH, encoding=\"utf-8\"))\n",
        "IMPLIED_STANCES    = json.load(open(STANCES_PATH, encoding=\"utf-8\"))\n",
        "SOURCE_BIAS        = json.load(open(BIAS_PATH, encoding=\"utf-8\"))\n",
        "\n",
        "# --- Mirror config.yaml into /config ---\n",
        "CONFIG_PATH = CONFIG_DIR / \"config.yaml\"\n",
        "CONFIG_PATH.write_text(cfg_txt, encoding=\"utf-8\")\n",
        "\n",
        "# --- Validate essentials ---\n",
        "required_cfg_keys = [\"hf_dataset_id\", \"chroma_collections\", \"embeddings\", \"batch\", \"ids\", \"chroma\"]\n",
        "missing = [k for k in required_cfg_keys if k not in CONFIG]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required config keys: {missing}\")\n",
        "\n",
        "# --- Ensure directories exist ---\n",
        "(Path(PROJECT_ROOT / CONFIG[\"batch\"][\"base_dir\"])).mkdir(parents=True, exist_ok=True)\n",
        "(Path(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"])).mkdir(parents=True, exist_ok=True)\n",
        "(Path(PROJECT_ROOT / CONFIG.get(\"logging\", {}).get(\"save_dir\", \"logs\"))).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Runtime summary ---\n",
        "print(json.dumps({\n",
        "    \"github_repo\": f\"{REPO_OWNER}/{REPO_NAME}\",\n",
        "    \"hf_dataset_id\": HF_DATASET_ID,\n",
        "    \"collections\": CONFIG[\"chroma_collections\"],\n",
        "    \"embeddings\": CONFIG[\"embeddings\"],\n",
        "    \"topics\": {\"count\": len(TOPIC_LABELS), \"source\": str(TOPICS_PATH)},\n",
        "    \"ideology_files\": {\n",
        "        \"political_leanings\": str(LEANINGS_PATH),\n",
        "        \"implied_stances\": str(STANCES_PATH),\n",
        "        \"source_bias\": str(BIAS_PATH)\n",
        "    },\n",
        "    \"paths\": {\n",
        "        \"batches\": str(PROJECT_ROOT / CONFIG[\"batch\"][\"base_dir\"]),\n",
        "        \"chroma_db\": str(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]),\n",
        "        \"config_yaml\": str(CONFIG_PATH)\n",
        "    },\n",
        "    \"config_source\": cfg_url\n",
        "}, indent=2))\n",
        "\n",
        "os.environ[\"HF_DATASET_ID\"] = HF_DATASET_ID\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhAwiP7LHjgu",
        "outputId": "c51ba082-bfd7-4e1b-d1bc-07748c420496"
      },
      "id": "vhAwiP7LHjgu",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching topics.json from https://raw.githubusercontent.com/AHMerrill/unstructured-project/main/config/topics.json ...\n",
            "Loaded 22 topic clusters from topics.json\n",
            "Fetching topic_anchors.npz from https://raw.githubusercontent.com/AHMerrill/unstructured-project/main/config/topic_anchors.npz ...\n",
            "Fetching political_leanings.json from https://raw.githubusercontent.com/AHMerrill/unstructured-project/main/config/political_leanings.json ...\n",
            "Fetching implied_stances.json from https://raw.githubusercontent.com/AHMerrill/unstructured-project/main/config/implied_stances.json ...\n",
            "Fetching source_bias.json from https://raw.githubusercontent.com/AHMerrill/unstructured-project/main/config/source_bias.json ...\n",
            "{\n",
            "  \"github_repo\": \"AHMerrill/unstructured-project\",\n",
            "  \"hf_dataset_id\": \"zanimal/unstructured-project\",\n",
            "  \"collections\": {\n",
            "    \"topic\": \"unstructured_topic\",\n",
            "    \"stance\": \"unstructured_stance\"\n",
            "  },\n",
            "  \"embeddings\": {\n",
            "    \"topic_model\": \"intfloat/e5-base-v2\",\n",
            "    \"stance_model\": \"all-mpnet-base-v2\",\n",
            "    \"dim\": 768,\n",
            "    \"dtype\": \"float32\",\n",
            "    \"pooling\": \"mean\",\n",
            "    \"chunk_tokens\": 512,\n",
            "    \"normalize\": true\n",
            "  },\n",
            "  \"topics\": {\n",
            "    \"count\": 22,\n",
            "    \"source\": \"/content/anti_echo/config/topics.json\"\n",
            "  },\n",
            "  \"ideology_files\": {\n",
            "    \"political_leanings\": \"/content/anti_echo/config/political_leanings.json\",\n",
            "    \"implied_stances\": \"/content/anti_echo/config/implied_stances.json\",\n",
            "    \"source_bias\": \"/content/anti_echo/config/source_bias.json\"\n",
            "  },\n",
            "  \"paths\": {\n",
            "    \"batches\": \"/content/anti_echo/batches\",\n",
            "    \"chroma_db\": \"/content/anti_echo/chroma_db\",\n",
            "    \"config_yaml\": \"/content/anti_echo/config/config.yaml\"\n",
            "  },\n",
            "  \"config_source\": \"https://raw.githubusercontent.com/AHMerrill/unstructured-project/main/config/config.yaml\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 3 of N - authentication for Hugging Face and GitHub\n",
        "\n",
        "Purpose\n",
        "Load tokens into environment and verify access. Later cells use these tokens to push to HF and update your GitHub registry.\n",
        "\n",
        "Why this matters\n",
        "Catching auth issues early prevents failing halfway through a run.\n",
        "\n",
        "Outputs\n",
        "Logged in to HF, GitHub token validated."
      ],
      "metadata": {
        "id": "7FuW4A7ELmrx"
      },
      "id": "7FuW4A7ELmrx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 3 of N: auth for Hugging Face and GitHub\n",
        "# Prompts only if tokens are not already in the environment.\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from getpass import getpass\n",
        "from huggingface_hub import login, whoami\n",
        "\n",
        "def need(envvar, prompt):\n",
        "    # Request once per session if missing\n",
        "    if not os.environ.get(envvar, \"\").strip():\n",
        "        os.environ[envvar] = getpass(prompt)\n",
        "    print(f\"{envvar} loaded:\", bool(os.environ.get(envvar)))\n",
        "\n",
        "# Gather tokens\n",
        "need(\"HF_TOKEN\", \"Enter your Hugging Face token: \")\n",
        "need(\"GITHUB_TOKEN\", \"Enter your GitHub Personal Access Token: \")\n",
        "\n",
        "# Sign in to HF so upload_file works later\n",
        "try:\n",
        "    login(token=os.environ[\"HF_TOKEN\"], add_to_git_credential=False)\n",
        "    print(\"HF login OK:\", whoami(token=os.environ[\"HF_TOKEN\"]).get(\"name\",\"(ok)\"))\n",
        "except Exception as e:\n",
        "    print(\"HF login failed:\", e)\n",
        "\n",
        "# Quick GitHub check to confirm token scopes\n",
        "try:\n",
        "    r = requests.get(\n",
        "        \"https://api.github.com/user\",\n",
        "        headers={\"Authorization\": f\"Bearer {os.environ['GITHUB_TOKEN']}\"},\n",
        "        timeout=15\n",
        "    )\n",
        "    print(\"GitHub auth status:\", r.status_code)\n",
        "except Exception as e:\n",
        "    print(\"GitHub auth check failed:\", e)\n"
      ],
      "metadata": {
        "id": "D0Si5GInpuhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22908c20-78b9-45b1-fab2-1b4a3c787491"
      },
      "id": "D0Si5GInpuhV",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Hugging Face token: ··········\n",
            "HF_TOKEN loaded: True\n",
            "Enter your GitHub Personal Access Token: ··········\n",
            "GITHUB_TOKEN loaded: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF login OK: zanimal\n",
            "GitHub auth status: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "tok = os.getenv(\"HF_TOKEN\", \"\")\n",
        "print(\"Length:\", len(tok))\n",
        "print(\"Starts with hf_:\", tok.startswith(\"hf_\"))\n",
        "print(\"Visible prefix:\", tok[:10])\n"
      ],
      "metadata": {
        "id": "zSOBjRBTd2bT",
        "outputId": "4c97b65b-9e52-4443-fd9a-eff5326bdcff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zSOBjRBTd2bT",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length: 37\n",
            "Starts with hf_: True\n",
            "Visible prefix: hf_vvjiawf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API login (hidden input)\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"].strip():\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "print(\"OpenAI API key loaded:\", bool(os.environ.get(\"OPENAI_API_KEY\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kru_M_FnGlZo",
        "outputId": "e5701032-574e-4091-c847-f04506f9f297"
      },
      "id": "kru_M_FnGlZo",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key: ··········\n",
            "OpenAI API key loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 4 of N - restore feed index and feed state\n",
        "\n",
        "Purpose\n",
        "Restore feeds/index.json and feeds/feeds_state.json from HF latest pointers, fallback to GitHub if missing, or reconstruct from HF batch metadata if neither exists.\n",
        "\n",
        "Why this matters\n",
        "Prevents re scraping the same URLs, and keeps numbering and batching consistent across runs.\n",
        "\n",
        "Outputs\n",
        "feeds/index.json and feeds/feeds_state.json present locally with a quick summary."
      ],
      "metadata": {
        "id": "PcIvKe4m4v9r"
      },
      "id": "PcIvKe4m4v9r"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 4 of N: restore feed index and state\n",
        "# Guarantees local index and state exist before scraping.\n",
        "# Refactored to pull GitHub and HF configuration dynamically.\n",
        "\n",
        "import os, json, shutil, requests, datetime as dt, re, hashlib\n",
        "from pathlib import Path\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "FEEDS_DIR = PROJECT_ROOT / \"feeds\"\n",
        "FEEDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "INDEX_PATH = FEEDS_DIR / \"index.json\"\n",
        "STATE_PATH = FEEDS_DIR / \"feeds_state.json\"\n",
        "\n",
        "# --- Config-driven settings (fallback to env vars if not present) ---\n",
        "HF_DATASET_ID = CONFIG.get(\"hf_dataset_id\", os.getenv(\"HF_DATASET_ID\", \"\"))\n",
        "github_cfg = CONFIG.get(\"github\", {})\n",
        "REPO_OWNER = github_cfg.get(\"owner\", os.getenv(\"GITHUB_OWNER\", \"\"))\n",
        "REPO_NAME  = github_cfg.get(\"repo\", os.getenv(\"GITHUB_REPO\", \"\"))\n",
        "BRANCH     = github_cfg.get(\"branch\", os.getenv(\"GITHUB_BRANCH\", \"main\"))\n",
        "\n",
        "def try_hf_restore() -> bool:\n",
        "    # Prefer HF because it is the single source of truth in this design\n",
        "    try:\n",
        "        st = hf_hub_download(HF_DATASET_ID, \"feeds/feeds_state_latest.json\", repo_type=\"dataset\")\n",
        "        ix = hf_hub_download(HF_DATASET_ID, \"feeds/feed_index_latest.json\", repo_type=\"dataset\")\n",
        "        shutil.copy(st, STATE_PATH)\n",
        "        shutil.copy(ix, INDEX_PATH)\n",
        "        print(\"Restored feed state from HF latest\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"HF latest not found:\", e)\n",
        "        return False\n",
        "\n",
        "def try_github_restore() -> bool:\n",
        "    # Fallback if HF latest pointers are not present yet\n",
        "    try:\n",
        "        base = f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/feeds\"\n",
        "        got = False\n",
        "        for src, dst in [(\"feeds_state_latest.json\", STATE_PATH), (\"feed_index_latest.json\", INDEX_PATH)]:\n",
        "            r = requests.get(f\"{base}/{src}\", timeout=20)\n",
        "            if r.status_code == 200 and r.text.strip():\n",
        "                dst.write_text(r.text, encoding=\"utf-8\")\n",
        "                got = True\n",
        "        if got:\n",
        "            print(\"Restored feed state from GitHub latest\")\n",
        "        return got\n",
        "    except Exception as e:\n",
        "        print(\"GitHub restore failed:\", e)\n",
        "        return False\n",
        "\n",
        "restored = try_hf_restore() or try_github_restore()\n",
        "\n",
        "if not restored:\n",
        "    # Reconstruct from HF batch metadata listed in artifacts_registry.json\n",
        "    print(\"No latest feed state found. Attempting reconstruction from HF batches...\")\n",
        "    REGISTRY_URL = f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/artifacts/artifacts_registry.json\"\n",
        "    REGISTRY = requests.get(REGISTRY_URL, timeout=20).json()\n",
        "\n",
        "    # Collect metadata jsonl from each batch\n",
        "    metas = []\n",
        "    for b in REGISTRY.get(\"batches\", []):\n",
        "        meta_rel = (b.get(\"hf_paths\") or b.get(\"paths\") or {}).get(\"metadata\")\n",
        "        if not meta_rel:\n",
        "            continue\n",
        "        try:\n",
        "            metas.append(Path(hf_hub_download(HF_DATASET_ID, meta_rel, repo_type=\"dataset\")))\n",
        "        except Exception as e:\n",
        "            print(\"Skip meta fetch:\", e)\n",
        "\n",
        "    # Build a minimal index of known URLs to prevent re-scraping\n",
        "    items = {}\n",
        "    def norm(txt): return re.sub(r\"\\s+\", \" \", txt.strip().lower())\n",
        "    def sha256_text(txt): return hashlib.sha256(norm(txt).encode()).hexdigest()\n",
        "\n",
        "    for fp in metas:\n",
        "        for line in fp.read_text(encoding=\"utf-8\").splitlines():\n",
        "            if not line.strip():\n",
        "                continue\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "            except Exception:\n",
        "                continue\n",
        "            u = obj.get(\"url\")\n",
        "            if u and u not in items:\n",
        "                items[u] = {\"status\": \"ok\", \"fetched_at\": dt.datetime.now(dt.timezone.utc).isoformat()}\n",
        "\n",
        "    INDEX_PATH.write_text(\n",
        "        json.dumps(\n",
        "            {\"last_updated\": dt.datetime.now(dt.timezone.utc).isoformat(), \"items\": items},\n",
        "            indent=2,\n",
        "        ),\n",
        "        encoding=\"utf-8\",\n",
        "    )\n",
        "\n",
        "    # Create a simple ring buffer structure for each feed\n",
        "    url_hashes = [sha256_text(u)[:12] for u in items.keys()]\n",
        "    feeds_block = {\n",
        "        \"commentisfree\": {\n",
        "            \"feed_url\": None,\n",
        "            \"recent_url_hashes\": url_hashes[-1000:],\n",
        "            \"recent_url_hashes_max\": 1000,\n",
        "        },\n",
        "        \"theguardian\": {\n",
        "            \"feed_url\": None,\n",
        "            \"recent_url_hashes\": url_hashes[-500:],\n",
        "            \"recent_url_hashes_max\": 500,\n",
        "        },\n",
        "    }\n",
        "    STATE_PATH.write_text(\n",
        "        json.dumps(\n",
        "            {\"version\": 1, \"updated_at\": dt.datetime.now(dt.timezone.utc).isoformat(), \"feeds\": feeds_block},\n",
        "            indent=2,\n",
        "        ),\n",
        "        encoding=\"utf-8\",\n",
        "    )\n",
        "    print(\"Reconstruction complete\")\n",
        "\n",
        "# Echo a small summary so you can verify\n",
        "ix = json.loads(INDEX_PATH.read_text(encoding=\"utf-8\"))\n",
        "st = json.loads(STATE_PATH.read_text(encoding=\"utf-8\"))\n",
        "print({\"index_items\": len(ix.get(\"items\", {})), \"feeds\": list(st.get(\"feeds\", {}).keys())})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "4cefcff6fe8141c896582c7729a6f69c",
            "776aea8081ff44998bc5708f6d1c17ad",
            "92bad2f24c2d4dfc9435052b7b4c3599",
            "6c539b044c0e47a28358b916800e58fe",
            "02dd7988561c4b5ca50bbe7deab56747",
            "b1d67c1e3e1d4001a54c9e279484cd20",
            "b2e7377e5b994cce9e8c4d5ba4f68c76",
            "808b7979b6e5482c95ee758aca4aa81c",
            "11e02d1f618c4bab89adce6ca354ede0",
            "d1a39f23809b451e9bd4a023f9f19c03",
            "06e3db41f8b24ca1bdeeee59044da778",
            "96927fcd11474dc4918def91a8887ea7",
            "55d96a9eca6e4319b4facf6261933faa",
            "ab248dde49e849bfaa2212900b0f55d5",
            "83701da7186349bdbb140db4bebde114",
            "cef3a03d71c64c91b7a2599d076c05a5",
            "293bfe57bec0454f9c2a1cc2d6eb5012",
            "560d0c8c560a47b89b4077e291d47d64",
            "43f0672ff0d94765a956b6abfe466a04",
            "86136733a5154f01b301f03fd34b6817",
            "8a792bb5b501477593f83ebaed1acda9",
            "a0570ba74b994f039d394a3676ac98be"
          ]
        },
        "id": "8ZlphFLgMJWk",
        "outputId": "c6ad32fe-fb4c-49de-b818-0ba645e5b09f"
      },
      "id": "8ZlphFLgMJWk",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "feeds_state_latest.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cefcff6fe8141c896582c7729a6f69c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "feed_index_latest.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96927fcd11474dc4918def91a8887ea7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored feed state from HF latest\n",
            "{'index_items': 13, 'feeds': ['commentisfree', 'theguardian', 'vox', 'cnn-opinion', 'guardian', 'bbc', 'cityjournal', 'dailycaller', 'theconversation', 'aljazeera', 'foxnews', 'npr', 'reason', 'thefederalist', 'msnbc', 'nypost']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 5 of N - rebuild Chroma from HF batches\n",
        "\n",
        "Purpose\n",
        "Create or refresh local Chroma collections from the HF dataset using artifacts/artifacts_registry.json as the ledger. HF is the source of truth. Local Chroma is a cache.\n",
        "\n",
        "Why this matters\n",
        "Ensures your retrieval state is consistent before adding new data. No duplicated rows. Clean numbering follows registry order.\n",
        "\n",
        "Outputs\n",
        "Two Chroma collections present with counts: topic and stance."
      ],
      "metadata": {
        "id": "dTRylrXg44OE"
      },
      "id": "dTRylrXg44OE"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Setup 5 of N — Rebuild Chroma (Config-Driven + Idempotent + Schema-Aware + Graceful Empty-State)\n",
        "# ===============================================\n",
        "\n",
        "import os, json, numpy as np, logging, requests, hashlib\n",
        "from pathlib import Path\n",
        "from huggingface_hub import hf_hub_download\n",
        "import chromadb\n",
        "\n",
        "# Silence telemetry\n",
        "os.environ[\"CHROMA_TELEMETRY_ENABLED\"] = \"false\"\n",
        "logging.getLogger(\"chromadb.telemetry\").setLevel(logging.ERROR)\n",
        "\n",
        "# --- Paths and Config ---\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "CHROMA_DIR = PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]\n",
        "CHROMA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "STATE_PATH = CHROMA_DIR / \"ingested_batches.json\"\n",
        "\n",
        "# --- Config-driven variables with safe fallbacks ---\n",
        "HF_DATASET_ID = CONFIG.get(\"hf_dataset_id\", os.getenv(\"HF_DATASET_ID\", \"\"))\n",
        "github_cfg = CONFIG.get(\"github\", {})\n",
        "REPO_OWNER = github_cfg.get(\"owner\", os.getenv(\"GITHUB_OWNER\", \"\"))\n",
        "REPO_NAME  = github_cfg.get(\"repo\", os.getenv(\"GITHUB_REPO\", \"\"))\n",
        "BRANCH     = github_cfg.get(\"branch\", os.getenv(\"GITHUB_BRANCH\", \"main\"))\n",
        "\n",
        "COLL_TOPIC = CONFIG[\"chroma_collections\"][\"topic\"]\n",
        "COLL_STANCE = CONFIG[\"chroma_collections\"][\"stance\"]\n",
        "EMB_DIM = int(CONFIG[\"embeddings\"][\"dim\"])\n",
        "CURRENT_SCHEMA = 1  # expected schema version\n",
        "\n",
        "# --- Registry source (config-driven) ---\n",
        "REGISTRY_URL = f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/artifacts/artifacts_registry.json\"\n",
        "\n",
        "# --- Utilities ---\n",
        "def sha256_file(fp):\n",
        "    h = hashlib.sha256()\n",
        "    with open(fp, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()[:16]\n",
        "\n",
        "def ensure_chroma():\n",
        "    client = chromadb.PersistentClient(path=str(CHROMA_DIR))\n",
        "    t = client.get_or_create_collection(name=COLL_TOPIC, metadata={\"hnsw:space\": \"cosine\"})\n",
        "    s = client.get_or_create_collection(name=COLL_STANCE, metadata={\"hnsw:space\": \"cosine\"})\n",
        "    return client, t, s\n",
        "\n",
        "def load_npz(fp: Path, dim: int):\n",
        "    arr = np.load(fp, allow_pickle=False)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr = arr[list(arr.files)[0]]\n",
        "    vecs = np.asarray(arr)\n",
        "    if vecs.ndim != 2 or vecs.shape[1] != dim:\n",
        "        raise ValueError(f\"{fp.name}: expected [N,{dim}] got {vecs.shape}\")\n",
        "    if not np.isfinite(vecs).all():\n",
        "        raise ValueError(f\"{fp.name}: non-finite values\")\n",
        "    return vecs\n",
        "\n",
        "def read_jsonl(fp: Path):\n",
        "    with fp.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                yield json.loads(line)\n",
        "\n",
        "def upsert_chunks(coll, ids, vecs, metas, chunk=2048):\n",
        "    n = len(ids)\n",
        "    for i in range(0, n, chunk):\n",
        "        j = min(i + chunk, n)\n",
        "        coll.upsert(\n",
        "            ids=ids[i:j],\n",
        "            embeddings=vecs[i:j].tolist(),\n",
        "            metadatas=metas[i:j],\n",
        "        )\n",
        "\n",
        "# --- Fetch registry (from GitHub) ---\n",
        "try:\n",
        "    REGISTRY = requests.get(REGISTRY_URL, timeout=20).json()\n",
        "except Exception as e:\n",
        "    print(f\"Failed to fetch registry ({e}). Creating empty Chroma collections.\")\n",
        "    client, t, s = ensure_chroma()\n",
        "    print(f\"Initialized empty Chroma DB at {CHROMA_DIR}\")\n",
        "    print(\"No remote registry found. You may need to run Setup 9 and Setup 10 to generate your first embeddings.\")\n",
        "    REGISTRY = {\"batches\": []}\n",
        "\n",
        "# --- Empty-registry safeguard ---\n",
        "if not REGISTRY.get(\"batches\"):\n",
        "    client, t, s = ensure_chroma()\n",
        "    print(\"No existing Chroma batches detected.\")\n",
        "    print(f\"Created empty local collections: topic={t.name}, stance={s.name}\")\n",
        "    print(\"Next steps:\")\n",
        "    print(\" - Run Setup 8 to embed and upsert topic vectors.\")\n",
        "    print(\" - Run Setup 9 to embed and upsert stance vectors.\")\n",
        "    print(\" - Run Setup 11 to push your first batch to Hugging Face.\")\n",
        "else:\n",
        "    # --- Continue rebuild ---\n",
        "    if STATE_PATH.exists():\n",
        "        state = json.load(open(STATE_PATH))\n",
        "    else:\n",
        "        state = []\n",
        "\n",
        "    client, topic_coll, stance_coll = ensure_chroma()\n",
        "    added_rows = 0\n",
        "    ingested_batches = 0\n",
        "    skipped_batches = []\n",
        "\n",
        "    for b in REGISTRY.get(\"batches\", []):\n",
        "        batch_id = b.get(\"batch_id\")\n",
        "        sv = int(b.get(\"schema_version\", 1))\n",
        "\n",
        "        if batch_id in state:\n",
        "            print(f\"Skip already ingested {batch_id}\")\n",
        "            continue\n",
        "        if sv < CURRENT_SCHEMA:\n",
        "            print(f\"Skip legacy batch {batch_id} (schema {sv} < {CURRENT_SCHEMA})\")\n",
        "            skipped_batches.append(batch_id)\n",
        "            continue\n",
        "\n",
        "        paths = b.get(\"paths\") or b.get(\"hf_paths\") or {}\n",
        "        need = [\"embeddings_topic\", \"embeddings_stance\", \"metadata_topic\", \"metadata_stance\"]\n",
        "        if not all(k in paths for k in need):\n",
        "            print(f\"Skip batch {batch_id} (missing required paths)\")\n",
        "            skipped_batches.append(batch_id)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            t_vecs = load_npz(Path(hf_hub_download(HF_DATASET_ID, paths[\"embeddings_topic\"], repo_type=\"dataset\")), EMB_DIM)\n",
        "            s_vecs = load_npz(Path(hf_hub_download(HF_DATASET_ID, paths[\"embeddings_stance\"], repo_type=\"dataset\")), EMB_DIM)\n",
        "            t_meta_path = Path(hf_hub_download(HF_DATASET_ID, paths[\"metadata_topic\"], repo_type=\"dataset\"))\n",
        "            s_meta_path = Path(hf_hub_download(HF_DATASET_ID, paths[\"metadata_stance\"], repo_type=\"dataset\"))\n",
        "\n",
        "            topic_ids, topic_metas = [], []\n",
        "            for rec in read_jsonl(t_meta_path):\n",
        "                rid = rec.get(\"row_id\") or f\"{rec.get('id','unknown')}::topic::0\"\n",
        "                topic_ids.append(rid)\n",
        "                topic_metas.append(rec)\n",
        "\n",
        "            stance_ids, stance_metas = [], []\n",
        "            for rec in read_jsonl(s_meta_path):\n",
        "                rid = rec.get(\"row_id\") or f\"{rec.get('id','unknown')}::stance::0\"\n",
        "                stance_ids.append(rid)\n",
        "                stance_metas.append(rec)\n",
        "\n",
        "            if t_vecs.shape[0] != len(topic_ids):\n",
        "                raise ValueError(f\"{batch_id}: topic vec/meta mismatch\")\n",
        "            if s_vecs.shape[0] != len(stance_ids):\n",
        "                raise ValueError(f\"{batch_id}: stance vec/meta mismatch\")\n",
        "\n",
        "            upsert_chunks(topic_coll, topic_ids, t_vecs, topic_metas)\n",
        "            upsert_chunks(stance_coll, stance_ids, s_vecs, stance_metas)\n",
        "\n",
        "            state.append(batch_id)\n",
        "            json.dump(state, open(STATE_PATH, \"w\"), indent=2)\n",
        "            added_rows += len(topic_ids) + len(stance_ids)\n",
        "            ingested_batches += 1\n",
        "            print(f\"Ingested {batch_id}: {len(topic_ids)} topic, {len(stance_ids)} stance\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed batch {batch_id}: {e}\")\n",
        "            skipped_batches.append(batch_id)\n",
        "            continue\n",
        "\n",
        "    summary = {\n",
        "        \"topic_count\": topic_coll.count(),\n",
        "        \"stance_count\": stance_coll.count(),\n",
        "        \"rows_added\": added_rows,\n",
        "        \"ingested_batches\": ingested_batches,\n",
        "        \"skipped_batches\": skipped_batches,\n",
        "        \"state_file\": str(STATE_PATH),\n",
        "    }\n",
        "    print(json.dumps(summary, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "e826337f9e2e4f869ab2a08431e4a986",
            "7812102502b44da28fabcf586e9353c1",
            "0eee7bd41bf6427da9a127d9acb8f9a8",
            "25bab004cfc14be28e0e7af141be0f5d",
            "5ec18f76661f49bd83dde46325dc270d",
            "422205c375e648ac9fe20f83fa9e2324",
            "a8bf9efa515a47009d683569b73f8758",
            "b40c15f084d14b64803be9e59dc8577e",
            "e54a43c203cc4f6bb678a38ffe86dd4a",
            "735694a0e3c6445bbe366cb9234f48b0",
            "f30c09c041d9459492e83fedcddda3f3",
            "a4abcf682e134d3b83e14061b663d7d7",
            "aadf7ceead704466870600fed076f89e",
            "6811b0b814b640c0afb7d7f0a03faecc",
            "0fa896ad0b6b40818f46540c8dce93ff",
            "58f76104372b4f00ac60535a22a50747",
            "d0bb9ffe6dc14910b480105afa244911",
            "d8c31e4dbf944845bb4ac71b4c5e3377",
            "81d29a54c92e45ccb349d79e3f1ffb5f",
            "717ba9f1a7344eb28ee4f994dc0e735e",
            "691d26fb43e24eccbcd86244ae731fe9",
            "654819d5dbdf45d797a9056f88911fb7",
            "fa892e72a0104458942234780b8b3f25",
            "09fde59c7ea948c6a82cab08cd049a15",
            "d873c534f3e24682818d4ba85d3de950",
            "216d12908b2749c58ebe4596b018a657",
            "2c6e48f959e849e493392889afe60fac",
            "e3d4ee0b31264d0395e8ea130eb46054",
            "4789e40b0311460b953e8797aa6bfc82",
            "918f9c3fd194411aa9909c0c74671060",
            "2b8fe85dbaa1415a88439fd95443add4",
            "c5280c1991d04c2fade3576d664e9c85",
            "4ad5535276444ce09bae0ce0783b8c40",
            "191c4366a0b4483ba41047bd1b8e79c3",
            "ca5178d08cb244978a068bf145273caa",
            "608e07f7a59144cea2fd8c9a1eb46d5f",
            "828a918aedac4dc09194e49fa3f0d94a",
            "9583f94abd504c52bf10127cf9c88126",
            "916018bd8fb64199939c94dc2ba4399e",
            "25b7247c7b754fae988bcefb6a280e00",
            "ef8c972042494a2f8496524c52354739",
            "d8e43eb21e7e48b9a7a9bc60c8e3f4e9",
            "fa28984302fa48b0b27f17e579387787",
            "4a7987d23332432e83b079c7d062df0c"
          ]
        },
        "id": "w8hxn43ELo1G",
        "outputId": "13db3c00-d493-4ccf-a111-50eb1e4d0e5e"
      },
      "id": "w8hxn43ELo1G",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "embeddings_topic.npz:   0%|          | 0.00/89.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e826337f9e2e4f869ab2a08431e4a986"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "embeddings_stance.npz:   0%|          | 0.00/18.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4abcf682e134d3b83e14061b663d7d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "metadata_topic.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa892e72a0104458942234780b8b3f25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "metadata_stance.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "191c4366a0b4483ba41047bd1b8e79c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingested batch_20251025T173713Z_5dd9b9dd: 64 topic, 13 stance\n",
            "{\n",
            "  \"topic_count\": 64,\n",
            "  \"stance_count\": 13,\n",
            "  \"rows_added\": 77,\n",
            "  \"ingested_batches\": 1,\n",
            "  \"skipped_batches\": [],\n",
            "  \"state_file\": \"/content/anti_echo/chroma_db/ingested_batches.json\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 6 of N - scraping tunables\n",
        "\n",
        "Purpose:\n",
        "Define scrape quotas, date floor, and feed list. Export to environment so the scraper reads configuration without edits.\n",
        "\n",
        "Scope:\n",
        "Attempted to have an even balance of left, right, center for this experiment.  used allsides.com and chatGPT to help cover a complete spectrum of sites considered biased in particular directions\n",
        "\n",
        "\n",
        "Why this matters\n",
        "Allows you to adjust scrape size and distribution per run from a single cell.\n",
        "\n",
        "Outputs\n",
        "Environment variables set and a printed summary."
      ],
      "metadata": {
        "id": "B8nvAQxhNAcH"
      },
      "id": "B8nvAQxhNAcH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 6 of N: feed configuration\n",
        "# Defines the set of RSS/Atom feeds to pull from for balanced, full-text content scraping.\n",
        "\n",
        "import json, os\n",
        "\n",
        "# Verified full-text feeds (as of latest probe)\n",
        "NEWS_FEEDS = [\n",
        "    (\"vox\", \"https://www.vox.com/rss/index.xml\"),\n",
        "    (\"cnn-opinion\", \"http://rss.cnn.com/rss/cnn_opinion.rss\"),\n",
        "    (\"guardian\", \"https://www.theguardian.com/uk/rss\"),\n",
        "    (\"bbc\", \"https://feeds.bbci.co.uk/news/rss.xml\"),\n",
        "    (\"cityjournal\", \"https://www.city-journal.org/rss.xml\"),\n",
        "    (\"dailycaller\", \"https://dailycaller.com/feed/\"),\n",
        "    (\"theconversation\", \"https://theconversation.com/us/articles.atom\"),\n",
        "    (\"aljazeera\", \"https://www.aljazeera.com/xml/rss/all.xml\"),\n",
        "    (\"foxnews\", \"https://moxie.foxnews.com/google-publisher/latest.xml\"),\n",
        "    (\"npr\", \"https://feeds.npr.org/1001/rss.xml\"),\n",
        "    (\"reason\", \"https://reason.com/feed/\"),\n",
        "    (\"thefederalist\", \"https://thefederalist.com/feed/\"),\n",
        "    (\"msnbc\", \"https://feeds.nbcnews.com/msnbc/public/news\"),\n",
        "    (\"nypost\", \"https://nypost.com/feed/\"),\n",
        "]\n",
        "\n",
        "# Export to environment for scraper\n",
        "os.environ[\"NEWS_FEEDS_JSON\"] = json.dumps(NEWS_FEEDS)\n",
        "\n",
        "# Scraper configuration\n",
        "# Adjust MAX_ARTICLES and MAX_PER_FEED for your target scale\n",
        "os.environ[\"MAX_ARTICLES\"] = \"2800\"       # ≈200 per feed × 14 feeds\n",
        "os.environ[\"MAX_PER_FEED\"] = \"200\"\n",
        "os.environ[\"EVEN_SPLIT\"] = \"true\"\n",
        "os.environ[\"DATE_FROM\"] = \"2019-01-01\"    # scrape articles newer than this date\n",
        "os.environ[\"FORCE_REFETCH\"] = \"false\"\n",
        "os.environ[\"QUOTA_REMAINDER_TO\"] = \"theconversation\"\n",
        "\n",
        "print(\"Configured verified full-text feeds:\")\n",
        "for name, url in NEWS_FEEDS:\n",
        "    print(f\"- {name}: {url}\")\n",
        "\n",
        "print(\"\\nScraper parameters:\")\n",
        "print(json.dumps({\n",
        "    \"MAX_ARTICLES\": os.environ[\"MAX_ARTICLES\"],\n",
        "    \"MAX_PER_FEED\": os.environ[\"MAX_PER_FEED\"],\n",
        "    \"DATE_FROM\": os.environ[\"DATE_FROM\"],\n",
        "    \"EVEN_SPLIT\": os.environ[\"EVEN_SPLIT\"],\n",
        "    \"FORCE_REFETCH\": os.environ[\"FORCE_REFETCH\"],\n",
        "    \"QUOTA_REMAINDER_TO\": os.environ[\"QUOTA_REMAINDER_TO\"]\n",
        "}, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFlG77sFNAzu",
        "outputId": "25db1a86-137c-439c-c46c-596852b43409"
      },
      "id": "cFlG77sFNAzu",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configured verified full-text feeds:\n",
            "- vox: https://www.vox.com/rss/index.xml\n",
            "- cnn-opinion: http://rss.cnn.com/rss/cnn_opinion.rss\n",
            "- guardian: https://www.theguardian.com/uk/rss\n",
            "- bbc: https://feeds.bbci.co.uk/news/rss.xml\n",
            "- cityjournal: https://www.city-journal.org/rss.xml\n",
            "- dailycaller: https://dailycaller.com/feed/\n",
            "- theconversation: https://theconversation.com/us/articles.atom\n",
            "- aljazeera: https://www.aljazeera.com/xml/rss/all.xml\n",
            "- foxnews: https://moxie.foxnews.com/google-publisher/latest.xml\n",
            "- npr: https://feeds.npr.org/1001/rss.xml\n",
            "- reason: https://reason.com/feed/\n",
            "- thefederalist: https://thefederalist.com/feed/\n",
            "- msnbc: https://feeds.nbcnews.com/msnbc/public/news\n",
            "- nypost: https://nypost.com/feed/\n",
            "\n",
            "Scraper parameters:\n",
            "{\n",
            "  \"MAX_ARTICLES\": \"2800\",\n",
            "  \"MAX_PER_FEED\": \"200\",\n",
            "  \"DATE_FROM\": \"2019-01-01\",\n",
            "  \"EVEN_SPLIT\": \"true\",\n",
            "  \"FORCE_REFETCH\": \"false\",\n",
            "  \"QUOTA_REMAINDER_TO\": \"theconversation\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 7 of N - scraper with dedupe\n",
        "\n",
        "Purpose\n",
        "Scrape the feeds, skip URLs already in feeds/index.json, save raw/{id}.txt and {id}.meta.json, and update both feeds/index.json and feeds/feeds_state.json.\n",
        "\n",
        "Why this matters\n",
        "Prevents duplicates, keeps state consistent across runs, and prepares clean inputs for embedding.\n",
        "\n",
        "Outputs\n",
        "New articles saved under raw/, updated feeds/index.json and feeds/feeds_state.json, and a summary."
      ],
      "metadata": {
        "id": "AR-rVGInQqeZ"
      },
      "id": "AR-rVGInQqeZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 7 of N: scraper with dedupe and caching\n",
        "# Uses feed list from Setup 6 (NEWS_FEEDS_JSON)\n",
        "# Fetches full text locally; saves metadata for embeddings downstream.\n",
        "\n",
        "import os, re, json, hashlib, datetime as dt\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "from email.utils import parsedate_to_datetime\n",
        "import feedparser, trafilatura, requests\n",
        "\n",
        "feedparser.USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\"\n",
        "\n",
        "def safe_parse_feed(url):\n",
        "    \"\"\"Fetch RSS/Atom with realistic browser headers to bypass blocks.\"\"\"\n",
        "    try:\n",
        "        headers = {\n",
        "            \"User-Agent\": feedparser.USER_AGENT,\n",
        "            \"Accept\": \"application/rss+xml, application/atom+xml, application/xml;q=0.9,*/*;q=0.8\",\n",
        "            \"Referer\": \"https://www.google.com/\",\n",
        "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "        }\n",
        "        resp = requests.get(url, headers=headers, timeout=15)\n",
        "        if resp.status_code != 200:\n",
        "            print(f\"feed fetch error ({resp.status_code}): {url}\")\n",
        "            return feedparser.FeedParserDict(entries=[])\n",
        "        return feedparser.parse(resp.content)\n",
        "    except Exception as e:\n",
        "        print(f\"feed fetch exception for {url}: {e}\")\n",
        "        return feedparser.FeedParserDict(entries=[])\n",
        "\n",
        "# === Paths ===\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "RAW_DIR = PROJECT_ROOT / \"raw\"\n",
        "FEEDS_DIR = PROJECT_ROOT / \"feeds\"\n",
        "FEEDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "INDEX_PATH = FEEDS_DIR / \"index.json\"\n",
        "STATE_PATH = FEEDS_DIR / \"feeds_state.json\"\n",
        "\n",
        "# === Load config ===\n",
        "FEED_LIST = json.loads(os.environ[\"NEWS_FEEDS_JSON\"])\n",
        "MAX_ARTICLES = int(os.environ.get(\"MAX_ARTICLES\", \"30\"))\n",
        "MAX_PER_FEED = os.environ.get(\"MAX_PER_FEED\", \"\")\n",
        "MAX_PER_FEED = None if MAX_PER_FEED == \"\" else int(MAX_PER_FEED)\n",
        "DATE_FROM = os.environ.get(\"DATE_FROM\", \"\") or None\n",
        "FORCE_REFETCH = os.environ.get(\"FORCE_REFETCH\", \"false\").lower() == \"true\"\n",
        "EVEN_SPLIT = os.environ.get(\"EVEN_SPLIT\", \"true\").lower() == \"true\"\n",
        "QUOTA_REMAINDER_TO = os.environ.get(\"QUOTA_REMAINDER_TO\", \"theconversation\")\n",
        "\n",
        "def now_iso(): return dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "\n",
        "# === State & index handling ===\n",
        "def load_json(path, default):\n",
        "    if path.exists():\n",
        "        try: return json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "        except Exception: pass\n",
        "    return default\n",
        "\n",
        "index = load_json(INDEX_PATH, {\"last_updated\": None, \"items\": {}})\n",
        "feeds_state = load_json(STATE_PATH, {\"version\": 1, \"updated_at\": None, \"feeds\": {}})\n",
        "fs = feeds_state.setdefault(\"feeds\", {})\n",
        "for name, feed_url in FEED_LIST:\n",
        "    fs.setdefault(name, {\"feed_url\": feed_url, \"recent_url_hashes\": [], \"recent_url_hashes_max\": 1000, \"last_run_at\": None})\n",
        "\n",
        "def save_json(path, obj):\n",
        "    obj[\"last_updated\"] = now_iso()\n",
        "    path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "# === Utility ===\n",
        "def parse_date(entry):\n",
        "    for k in [\"published\", \"updated\"]:\n",
        "        val = getattr(entry, k, None) or entry.get(k)\n",
        "        if val:\n",
        "            try: return parsedate_to_datetime(val)\n",
        "            except Exception: pass\n",
        "    return None\n",
        "\n",
        "def in_range(d, lower_iso):\n",
        "    if not lower_iso: return True\n",
        "    try: floor = dt.datetime.fromisoformat(lower_iso).replace(tzinfo=dt.timezone.utc)\n",
        "    except Exception: return True\n",
        "    if d is None: return True\n",
        "    if d.tzinfo is None: d = d.replace(tzinfo=dt.timezone.utc)\n",
        "    return d >= floor\n",
        "\n",
        "def normalize_text(txt): return re.sub(r\"\\s+\", \" \", txt.strip().lower())\n",
        "def sha256_text(txt): return hashlib.sha256(txt.encode()).hexdigest()\n",
        "def slugify(text, maxlen=60):\n",
        "    s = re.sub(r\"[^a-zA-Z0-9]+\", \"-\", text).strip(\"-\").lower()\n",
        "    return s[:maxlen] or \"untitled\"\n",
        "\n",
        "def fetch_article(url):\n",
        "    html = trafilatura.fetch_url(url, no_ssl=False)\n",
        "    if not html:\n",
        "        raise RuntimeError(\"fetch failed\")\n",
        "    text = trafilatura.extract(html, include_comments=False, include_tables=False) or \"\"\n",
        "    title_match = re.search(r\"<title>(.*?)</title>\", html or \"\", flags=re.I | re.S)\n",
        "    title = re.sub(r\"\\s+\", \" \", title_match.group(1)).strip() if title_match else \"Untitled\"\n",
        "    if not text.strip():\n",
        "        raise RuntimeError(\"extraction empty\")\n",
        "    return title, text\n",
        "\n",
        "def already_cached(url):\n",
        "    return url in index[\"items\"] and index[\"items\"][url].get(\"status\") == \"ok\"\n",
        "\n",
        "def mark(url, status):\n",
        "    index[\"items\"][url] = {\"status\": status, \"fetched_at\": now_iso()}\n",
        "    save_json(INDEX_PATH, index)\n",
        "\n",
        "# === Quotas ===\n",
        "feed_names = [n for n, _ in FEED_LIST]\n",
        "if EVEN_SPLIT:\n",
        "    base = MAX_ARTICLES // len(feed_names)\n",
        "    rem = MAX_ARTICLES % len(feed_names)\n",
        "    quotas = {n: base for n in feed_names}\n",
        "    quotas[QUOTA_REMAINDER_TO if QUOTA_REMAINDER_TO in quotas else feed_names[0]] += rem\n",
        "else:\n",
        "    quotas = {n: 0 for n in feed_names}\n",
        "    quotas[QUOTA_REMAINDER_TO if QUOTA_REMAINDER_TO in quotas else feed_names[0]] = MAX_ARTICLES\n",
        "if isinstance(MAX_PER_FEED, int):\n",
        "    quotas = {k: min(v, MAX_PER_FEED) for k, v in quotas.items()}\n",
        "print(\"Quotas:\", quotas)\n",
        "\n",
        "# === Main fetch loop ===\n",
        "saved_global = 0\n",
        "errors_global = 0\n",
        "seen_global = set()\n",
        "\n",
        "for name, feed_url in FEED_LIST:\n",
        "    if saved_global >= MAX_ARTICLES: break\n",
        "    quota = quotas.get(name, 0)\n",
        "    if quota <= 0: continue\n",
        "\n",
        "    fp = safe_parse_feed(feed_url)\n",
        "    if not fp.entries:\n",
        "        print(f\"[{name}] no entries found.\")\n",
        "        continue\n",
        "\n",
        "    items = []\n",
        "    for e in fp.entries:\n",
        "        url = getattr(e, \"link\", None)\n",
        "        if not url: continue\n",
        "        pub = parse_date(e)\n",
        "        if in_range(pub, DATE_FROM):\n",
        "            items.append({\"url\": url, \"published\": pub})\n",
        "\n",
        "    uniq, seen = [], set()\n",
        "    for it in sorted(items, key=lambda x: (x[\"published\"] or dt.datetime.min), reverse=True):\n",
        "        if it[\"url\"] in seen: continue\n",
        "        seen.add(it[\"url\"])\n",
        "        uniq.append(it)\n",
        "\n",
        "    saved_this = 0\n",
        "    for it in uniq:\n",
        "        if saved_global >= MAX_ARTICLES or saved_this >= quota: break\n",
        "        url = it[\"url\"]\n",
        "        if url in seen_global: continue\n",
        "        seen_global.add(url)\n",
        "        if already_cached(url) and not FORCE_REFETCH:\n",
        "            print(f\"skip (cached) [{name}]: {url}\")\n",
        "            continue\n",
        "        try:\n",
        "            title, text = fetch_article(url)\n",
        "            domain = urlparse(url).netloc\n",
        "            slug = slugify(title)\n",
        "            h = sha256_text(normalize_text(text))\n",
        "            art_id = f\"{domain}-{slug}-{h[:12]}\"\n",
        "            RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "            txt_path = RAW_DIR / f\"{art_id}.txt\"\n",
        "            meta_path = RAW_DIR / f\"{art_id}.meta.json\"\n",
        "            txt_path.write_text(text, encoding=\"utf-8\")\n",
        "            meta = {\n",
        "                \"id\": art_id, \"url\": url, \"title\": title, \"source\": name, \"domain\": domain,\n",
        "                \"published\": it[\"published\"].isoformat() if it[\"published\"] else None,\n",
        "                \"sha256\": h, \"chars\": len(text), \"saved_at\": now_iso(),\n",
        "            }\n",
        "            meta_path.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
        "            mark(url, \"ok\")\n",
        "            fs[name][\"last_run_at\"] = now_iso()\n",
        "            saved_this += 1\n",
        "            saved_global += 1\n",
        "            print(f\"saved [{name}]: {txt_path.name} | {title[:90]} | {len(text)} chars\")\n",
        "        except Exception as e:\n",
        "            mark(url, \"error\")\n",
        "            errors_global += 1\n",
        "            print(f\"error [{name}]: {url} | {type(e).__name__}: {str(e)[:120]}\")\n",
        "\n",
        "feeds_state[\"updated_at\"] = now_iso()\n",
        "STATE_PATH.write_text(json.dumps(feeds_state, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(json.dumps({\n",
        "    \"saved_total\": saved_global,\n",
        "    \"errors_total\": errors_global,\n",
        "    \"index_items\": len(index[\"items\"]),\n",
        "    \"feeds_state_path\": str(STATE_PATH)\n",
        "}, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAULiUriQr9n",
        "outputId": "1b172e7e-cd50-4ba6-9891-073d01ddadf9"
      },
      "id": "wAULiUriQr9n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quotas: {'vox': 200, 'cnn-opinion': 200, 'guardian': 200, 'bbc': 200, 'cityjournal': 200, 'dailycaller': 200, 'theconversation': 200, 'aljazeera': 200, 'foxnews': 200, 'npr': 200, 'reason': 200, 'thefederalist': 200, 'msnbc': 200, 'nypost': 200}\n",
            "skip (cached) [vox]: https://www.vox.com/policy/465969/ice-protests-chicago-broadview-pastor-pepper-spray\n",
            "saved [vox]: www.vox.com-caribbean-boat-strikes-is-the-us-killing-innocent-people-vox-ef90a0158dbd.txt | Caribbean boat strikes: Is the US killing innocent people? | Vox | 2668 chars\n",
            "saved [vox]: www.vox.com-the-nba-betting-scandal-exposes-america-s-sports-gambling-pr-c2abef0f7372.txt | The NBA betting scandal exposes America’s sports gambling problem | Vox | 4814 chars\n",
            "saved [vox]: www.vox.com-how-the-rich-avoid-paying-taxes-vox-886e9f0df696.txt | How the rich avoid paying taxes | Vox | 11752 chars\n",
            "saved [vox]: www.vox.com-east-wing-demolition-is-this-legal-and-5-other-questions-ans-b8662a87c9fb.txt | East Wing demolition: Is this legal? And 5 other questions, answered | Vox | 8072 chars\n",
            "saved [vox]: www.vox.com-philip-pullman-s-the-rose-field-finishes-the-story-of-the-go-941e66bbe146.txt | Philip Pullman’s The Rose Field finishes the story of The Golden Compass | Vox | 16200 chars\n",
            "saved [vox]: www.vox.com-endangered-houston-toad-recovery-inside-the-fort-worth-zoo-s-3d719787acf3.txt | Endangered Houston toad recovery: Inside the Fort Worth Zoo’s amphibian IVF program | Vox | 18588 chars\n",
            "saved [vox]: www.vox.com-dubai-chocolate-is-everywhere-and-it-s-giving-tiktok-brain-r-0bd8df948b1b.txt | Dubai chocolate is everywhere — and it’s giving TikTok brain rot | Vox | 8172 chars\n",
            "saved [vox]: www.vox.com-trump-s-tariffs-are-beginning-to-have-a-real-impact-on-poor--fdee5b28033a.txt | Trump’s tariffs are beginning to have a real impact on poor countries | Vox | 17038 chars\n",
            "saved [vox]: www.vox.com-florida-s-coral-reef-has-lost-two-species-that-help-limit-hu-07031fef71e0.txt | Florida’s coral reef has lost two species that help limit hurricane damage | Vox | 6239 chars\n",
            "saved [guardian]: www.theguardian.com-manchester-united-v-brighton-premier-league-live-updates-pre-8f633b59e013.txt | Manchester United v Brighton: Premier League – live updates | Premier League | The Guardia | 16070 chars\n",
            "skip (cached) [guardian]: https://www.theguardian.com/tv-and-radio/live/2025/oct/25/strictly-come-dancing-week-five-live\n",
            "saved [guardian]: www.theguardian.com-england-v-brazil-international-friendly-live-updates-england-a9a77dc3edaa.txt | England v Brazil: international friendly – live updates | England women's football team |  | 12358 chars\n",
            "saved [guardian]: www.theguardian.com-brentford-v-liverpool-premier-league-live-updates-premier-le-010b67314cac.txt | Brentford v Liverpool: Premier League – live updates | Premier League | The Guardian | 553 chars\n",
            "saved [guardian]: www.theguardian.com-cokanasiga-on-song-to-help-bath-past-bristol-in-bruising-wes-5cc7714cb607.txt | Cokanasiga on song to help Bath past Bristol in bruising West Country derby | Prem Rugby | | 3795 chars\n",
            "saved [guardian]: www.theguardian.com-tyne-and-weary-truro-city-s-914-mile-round-trip-makes-englis-aa739dce588b.txt | Tyne and weary: Truro City’s 914-mile round trip makes English football history | Football | 3070 chars\n",
            "saved [guardian]: www.theguardian.com-sunderland-flying-high-after-stunning-chelsea-with-injury-ti-2f0a730bbaea.txt | Sunderland flying high after stunning Chelsea with injury-time Talbi winner | Premier Leag | 4421 chars\n",
            "saved [guardian]: www.theguardian.com-met-police-urge-epping-sex-offender-spotted-in-london-to-han-4818afc48547.txt | Met police urge Epping sex offender spotted in London to hand himself in | Prisons and pro | 7448 chars\n",
            "saved [guardian]: www.theguardian.com-ruthless-australia-sweep-england-aside-in-one-sided-ashes-te-b5ae6821b0d9.txt | Ruthless Australia sweep England aside in one-sided Ashes Test at Wembley | Rugby league | | 3905 chars\n",
            "saved [guardian]: www.theguardian.com-labour-s-new-deputy-leader-says-party-must-pay-more-heed-to--897bb4d0100a.txt | Labour’s new deputy leader says party must pay more heed to its members | Lucy Powell | Th | 4270 chars\n",
            "saved [guardian]: www.theguardian.com-i-am-not-done-kamala-harris-says-she-may-run-for-president-a-b99117ad3998.txt | ‘I am not done’: Kamala Harris says she may run for president again | Kamala Harris | The  | 3086 chars\n",
            "saved [guardian]: www.theguardian.com-the-heist-of-the-decade-full-story-podcast-france-the-guardi-3cbba7482b7f.txt | The heist of the decade – Full Story podcast | France | The Guardian | 1230 chars\n",
            "saved [guardian]: www.theguardian.com-cholera-is-spreading-fast-yet-it-can-be-stopped-why-haven-t--8942cfaba537.txt | Cholera is spreading fast, yet it can be stopped. Why haven’t we consigned it to history?  | 4729 chars\n",
            "saved [guardian]: www.theguardian.com-leftwinger-catherine-connolly-wins-ireland-presidential-elec-4c4f829e0553.txt | Leftwinger Catherine Connolly wins Ireland presidential election by landslide | Ireland |  | 3922 chars\n",
            "saved [guardian]: www.theguardian.com-why-is-trump-demolishing-the-white-house-s-east-wing-because-f3d40b8cd856.txt | Why is Trump demolishing the White House’s East Wing? Because he wants to | Arwa Mahdawi | | 7795 chars\n",
            "saved [guardian]: www.theguardian.com-suicides-linked-to-domestic-abuse-should-be-investigated-as--a77f2085a069.txt | Suicides linked to domestic abuse should be investigated as potential homicides, say UK fa | 5867 chars\n",
            "saved [guardian]: www.theguardian.com-history-is-repeating-itself-fight-against-far-right-in-londo-c6d1c3ed8c35.txt | ‘History is repeating itself’: fight against far-right in London’s East End goes on | Far  | 7528 chars\n",
            "saved [guardian]: www.theguardian.com-rfk-jr-to-urge-americans-to-eat-more-saturated-fats-alarming-9a3221c7fdda.txt | RFK Jr to urge Americans to eat more saturated fats, alarming health experts | Robert F Ke | 5620 chars\n",
            "saved [guardian]: www.theguardian.com-from-apartheid-to-democracy-a-blueprint-for-a-different-futu-1b12742460d4.txt | From Apartheid to Democracy – a ‘blueprint’ for a different future in Israel-Palestine | P | 6941 chars\n",
            "saved [guardian]: www.theguardian.com-crisps-up-perfectly-the-best-and-worst-supermarket-bacon-tas-b1cf73a19a47.txt | ‘Crisps up perfectly’: the best (and worst) supermarket bacon, tasted and rated | Pork | T | 6673 chars\n",
            "saved [guardian]: www.theguardian.com-australia-women-s-cricket-world-cup-players-touched-inapprop-4a82e5d0a994.txt | Australia Women’s Cricket World Cup players ‘touched inappropriately’ in India | Women's C | 2622 chars\n",
            "saved [guardian]: www.theguardian.com-japanese-tourist-dies-in-fall-from-pantheon-in-rome-italy-th-bac01535dd12.txt | Japanese tourist dies in fall from Pantheon in Rome | Italy | The Guardian | 1786 chars\n",
            "saved [guardian]: www.theguardian.com-at-least-four-killed-in-russian-strikes-overnight-on-ukraine-289dbfe2ed23.txt | At least four killed in Russian strikes overnight on Ukraine | Ukraine | The Guardian | 2267 chars\n",
            "saved [guardian]: www.theguardian.com-factionalism-farce-and-chaos-dog-reform-uk-in-the-garden-of--25c242c7efc2.txt | Factionalism, farce and chaos dog Reform UK in the garden of England | Reform UK | The Gua | 5171 chars\n",
            "saved [guardian]: www.theguardian.com-trump-was-planning-to-send-troops-to-san-francisco-now-he-s--2dba6a9d65b0.txt | Trump was planning to send troops to San Francisco. Now he’s not. Here’s why | Joe Eskenaz | 6585 chars\n",
            "saved [guardian]: www.theguardian.com-argentina-goes-to-polls-amid-economic-crisis-and-trump-inter-82349e9fc542.txt | Argentina goes to polls amid economic crisis and Trump ‘interference’ | Javier Milei | The | 5001 chars\n",
            "saved [guardian]: www.theguardian.com-rejuvenated-joe-root-all-revved-up-to-end-ashes-century-drou-0905841c6658.txt | Rejuvenated Joe Root all revved up to end Ashes century drought in Australia | Joe Root |  | 4285 chars\n",
            "saved [guardian]: www.theguardian.com-if-you-use-chocolate-you-re-in-crisis-the-surprise-ingredien-b804541621f8.txt | ‘If you use chocolate, you’re in crisis’: the surprise ingredients being used to beat cost | 9114 chars\n",
            "saved [guardian]: www.theguardian.com-amazon-strategised-about-keeping-its-datacentres-full-water--b1b0011187f7.txt | Amazon strategised about keeping its datacentres’ full water use secret, leaked document s | 9393 chars\n",
            "saved [guardian]: www.theguardian.com-young-country-diary-the-foxes-and-i-have-been-watching-each--cb0c1c133de2.txt | Young country diary: The foxes and I have been watching each other closely | Urban wildlif | 1626 chars\n",
            "saved [guardian]: www.theguardian.com-i-don-t-know-how-anyone-takes-themselves-seriously-in-this-j-a6635bb7ba30.txt | ‘I don’t know how anyone takes themselves seriously in this job’: Hollywood hotshot Glen P | 24183 chars\n",
            "saved [guardian]: www.theguardian.com-sam-lau-on-the-stages-of-adulthood-cartoon-sam-lau-the-guard-71df678f26a1.txt | Sam Lau on the stages of adulthood – cartoon | Sam Lau | The Guardian | 171 chars\n",
            "saved [guardian]: www.theguardian.com-a-cloak-some-monsters-and-a-bicycle-marguerite-o-molloy-s-be-6b1856e93de4.txt | A cloak, some monsters and a bicycle: Marguerite O’Molloy’s best phone picture | Photograp | 1345 chars\n",
            "saved [guardian]: www.theguardian.com-tarling-and-charlton-grab-gb-s-first-golds-at-track-world-ch-9a901b6591fc.txt | Tarling and Charlton grab GB’s first golds at Track World Championships | Cycling | The Gu | 1551 chars\n",
            "saved [guardian]: www.theguardian.com-offer-cancer-patients-exercise-on-nhs-major-charity-urges-ca-c979ccf3aae8.txt | Offer cancer patients exercise on NHS, major charity urges | Cancer | The Guardian | 4379 chars\n",
            "saved [guardian]: www.theguardian.com-shobna-gulati-if-i-could-choose-to-bring-something-extinct-b-3a1a4d1d745a.txt | Shobna Gulati: ‘If I could choose to bring something extinct back to life? A 1970s disco’  | 3216 chars\n",
            "saved [guardian]: www.theguardian.com-trump-s-men-come-to-israel-with-plenty-to-say-but-they-re-si-16497cbb9ad2.txt | Trump’s men come to Israel with plenty to say. But they’re silent on any real future for G | 5216 chars\n",
            "saved [guardian]: www.theguardian.com-you-just-have-to-laugh-five-teachers-on-dealing-with-six-sev-b88fa16f6151.txt | ‘You just have to laugh’: five teachers on dealing with ‘six-seven’ in the classroom | Tea | 6507 chars\n",
            "saved [guardian]: www.theguardian.com-it-s-insanely-sinister-horror-writers-on-the-scariest-storie-99182c42734d.txt | ‘It’s insanely sinister’: horror writers on the scariest stories they’ve ever read | Books | 16253 chars\n",
            "saved [guardian]: www.theguardian.com-ai-models-may-be-developing-their-own-survival-drive-researc-85ed17770a0b.txt | AI models may be developing their own ‘survival drive’, researchers say | Artificial intel | 4118 chars\n",
            "saved [guardian]: www.theguardian.com-my-big-shop-used-to-cost-100-now-it-s-150-readers-recount-th-67e6ce0e97ec.txt | ‘My big shop used to cost £100, now it’s £150’: readers recount their shock at supermarket | 11226 chars\n",
            "saved [guardian]: www.theguardian.com-how-does-he-pay-for-it-all-the-mystery-of-prince-andrew-s-mo-a126c7932690.txt | How does he pay for it all? The mystery of Prince Andrew’s money | Prince Andrew | The Gua | 10381 chars\n",
            "saved [guardian]: www.theguardian.com-it-s-what-s-in-your-heart-that-counts-kenny-dalglish-on-his--d67363c51416.txt | ‘It’s what’s in your heart that counts’: Kenny Dalglish on his love for Liverpool and the  | 10997 chars\n",
            "saved [guardian]: www.theguardian.com-how-did-we-beat-nigel-farage-and-reform-in-caerphilly-we-sto-a858b138f68a.txt | How did we beat Nigel Farage and Reform in Caerphilly? We stood by our convictions | Rhun  | 5158 chars\n",
            "saved [guardian]: www.theguardian.com-buy-now-pay-later-holiday-purchases-leaving-travellers-expos-0a9ecc9b5523.txt | Buy now, pay later holiday purchases leaving travellers exposed to losses | Buy now, pay l | 4282 chars\n",
            "saved [guardian]: www.theguardian.com-daisy-may-and-charlie-cooper-s-nightwatch-their-hilarious-gh-c969dc466d0c.txt | Daisy May and Charlie Cooper’s NightWatch: their hilarious ghost show is a warm-hearted jo | 4119 chars\n",
            "saved [guardian]: www.theguardian.com-enforced-veganism-ofcom-lets-gb-news-flout-accuracy-rules-sa-becffb6b8b5c.txt | ‘Enforced veganism’: Ofcom lets GB News flout accuracy rules, say climate campaigners | Cl | 6611 chars\n",
            "saved [guardian]: www.theguardian.com-my-cultural-awakening-a-jim-carrey-series-made-me-embrace-ba-ea9fa87f74bf.txt | My cultural awakening: A Jim Carrey series made me embrace baldness – and shave my head on | 3725 chars\n",
            "saved [guardian]: www.theguardian.com-short-term-hibernation-in-animals-is-known-as-what-the-satur-367b64526b19.txt | Short-term hibernation in animals is known as what? The Saturday quiz | Quiz and trivia ga | 1749 chars\n",
            "saved [guardian]: www.theguardian.com-30-of-the-best-uk-pubs-for-an-autumn-escape-with-great-food--27797b7f3b81.txt | 30 of the best UK pubs for an autumn escape with great food | United Kingdom holidays | Th | 24532 chars\n",
            "saved [guardian]: www.theguardian.com-blind-date-i-was-sweating-quite-a-lot-for-the-first-five-min-3ca5351511a6.txt | Blind date: ‘I was sweating quite a lot for the first five minutes’ | Dating | The Guardia | 2624 chars\n",
            "saved [guardian]: www.theguardian.com-tv-tonight-a-dazzling-night-of-strictly-stars-taking-on-thei-3cd61f950001.txt | TV tonight: a dazzling night of Strictly stars taking on their favourite icons | Televisio | 3267 chars\n",
            "saved [guardian]: www.theguardian.com-tim-dowling-after-a-year-of-ignoring-each-other-the-cat-and--5cce7ad21a9a.txt | Tim Dowling: after a year of ignoring each other, the cat and the dog have declared war |  | 4364 chars\n",
            "saved [guardian]: www.theguardian.com-we-ll-march-as-many-times-as-necessary-peru-s-youth-proteste-8bb5d0c8dc37.txt | ‘We’ll march as many times as necessary’: Peru’s youth protesters defy state of emergency  | 3002 chars\n",
            "saved [guardian]: www.theguardian.com-co-op-staff-told-to-boost-promotion-of-vapes-after-costly-cy-51f908d3e2cd.txt | Co-op staff told to boost promotion of vapes after costly cyber-attack, document shows | C | 4223 chars\n",
            "saved [guardian]: www.theguardian.com-meera-sodha-s-recipe-for-japanese-curry-rice-with-soy-marina-ac8d20498633.txt | Meera Sodha’s recipe for Japanese curry rice with soy-marinated yolk | Vegetables | The Gu | 2988 chars\n",
            "saved [guardian]: www.theguardian.com-nobody-wants-this-to-lily-allen-the-week-in-rave-reviews-cul-c05466bd499a.txt | Nobody Wants This to Lily Allen: the week in rave reviews | Culture | The Guardian | 9613 chars\n",
            "saved [guardian]: www.theguardian.com-the-supremes-marcus-garvey-tupac-shakur-the-cultural-figures-963153756ac8.txt | The Supremes, Marcus Garvey, Tupac Shakur: the cultural figures who inspired our Black His | 20919 chars\n",
            "saved [guardian]: www.theguardian.com-greece-accuses-british-museum-of-provocative-indifference-ov-07fed2e1be9a.txt | Greece accuses British Museum of ‘provocative indifference’ over pink ball | Parthenon mar | 3016 chars\n",
            "saved [guardian]: www.theguardian.com-moving-house-time-to-think-inside-the-box-the-edith-pritchet-4a3d91c4d732.txt | Moving house – time to think inside the box: the Edith Pritchett cartoon | Life and style  | 311 chars\n",
            "saved [guardian]: www.theguardian.com-looking-forward-to-an-extra-hour-in-bed-on-sunday-time-to-th-65fed13901af.txt | Looking forward to an extra hour in bed on Sunday? Time to thank a farsighted builder from | 2800 chars\n",
            "saved [guardian]: www.theguardian.com-six-great-reads-a-golden-age-of-stupidity-inside-the-manosph-7e2690f7f9bc.txt | Six great reads: a golden age of stupidity, inside the manosphere and Harper Lee’s lost st | 3023 chars\n",
            "saved [guardian]: www.theguardian.com-every-time-i-step-outside-the-first-thing-on-my-mind-is-my-f-963769f2e9d1.txt | ‘Every time I step outside, the first thing on my mind is my forehead’: the women getting  | 24735 chars\n",
            "saved [guardian]: www.theguardian.com-from-springsteen-deliver-me-from-nowhere-to-it-welcome-to-de-0b2f359d9c00.txt | From Springsteen: Deliver Me from Nowhere to IT: Welcome to Derry – your complete entertai | 10018 chars\n",
            "saved [guardian]: www.theguardian.com-the-15-year-scandal-no-government-has-gripped-uk-grooming-ga-b08aca2ea4dc.txt | The 15-year-scandal no government has gripped: UK grooming gangs explained | Grooming gang | 7778 chars\n",
            "saved [guardian]: www.theguardian.com-six-metres-below-ground-inside-the-secret-hospital-treating--c8e7663f4a05.txt | Six metres below ground: inside the secret hospital treating Ukrainian soldiers injured by | 4801 chars\n",
            "saved [guardian]: www.theguardian.com-france-has-survived-revolutions-and-wars-its-crisis-now-is-d-62a25d2dbb11.txt | France has survived revolutions and wars: its crisis now is deep, but not terminal | David | 8772 chars\n",
            "saved [guardian]: www.theguardian.com-long-time-no-sea-more-than-100m-red-crabs-migrate-on-christm-5dc6f418f3b1.txt | Long time, no sea: more than 100m red crabs migrate on Christmas Island, delighting conser | 3462 chars\n",
            "saved [guardian]: www.theguardian.com-us-investigates-tesla-s-mad-max-high-speed-driver-assistance-4b18cba00308.txt | US investigates Tesla’s ‘Mad Max’ high-speed driver assistance mode | Tesla | The Guardian | 3325 chars\n",
            "saved [guardian]: www.theguardian.com-pentagon-deploys-top-aircraft-carrier-as-trump-militarisatio-c22aed5a445e.txt | Pentagon deploys top aircraft carrier as Trump militarisation of Caribbean ratchets up | T | 3999 chars\n",
            "saved [guardian]: www.theguardian.com-the-week-around-the-world-in-20-pictures-photography-the-gua-28928b76c405.txt | The week around the world in 20 pictures | Photography | The Guardian | 363 chars\n",
            "saved [guardian]: www.theguardian.com-prince-andrew-in-advanced-talks-about-moving-out-of-royal-lo-e60ee48053d2.txt | Prince Andrew in advanced talks about moving out of Royal Lodge, reports say | Prince Andr | 3115 chars\n",
            "saved [guardian]: www.theguardian.com-dave-ball-obituary-dave-ball-the-guardian-5dccce990bc6.txt | Dave Ball obituary | Dave Ball | The Guardian | 5657 chars\n",
            "saved [guardian]: www.theguardian.com-the-guardian-view-on-the-caerphilly-byelection-labour-s-coll-10d7118b04ab.txt | The Guardian view on the Caerphilly byelection: Labour’s collapse in its Welsh heartland s | 3500 chars\n",
            "saved [guardian]: www.theguardian.com-the-guardian-view-on-a-bumper-crop-of-horror-scary-times-cal-10a6b17a1b2e.txt | The Guardian view on a bumper crop of horror: scary times call for even scarier films | Ed | 3574 chars\n",
            "saved [guardian]: www.theguardian.com-six-britons-acting-for-wagner-group-jailed-for-arson-attack--2cd80e052b9c.txt | Six Britons acting for Wagner group jailed for arson attack on UK warehouse | UK news | Th | 3209 chars\n",
            "saved [guardian]: www.theguardian.com-dave-the-boy-who-played-the-harp-review-it-s-clearer-than-ev-30aa4176862f.txt | Dave: The Boy Who Played the Harp review – ​it’s clearer than ever what a stunningly skill | 4954 chars\n",
            "saved [guardian]: www.theguardian.com-still-life-that-never-moved-mystery-of-missing-picasso-paint-1415d7b30cd0.txt | Still life that never moved: mystery of missing Picasso painting solved | Pablo Picasso |  | 3485 chars\n",
            "saved [guardian]: www.theguardian.com-literature-offers-insights-into-the-rise-of-extremism-nazism-633b86deac9b.txt | Literature offers insights into the rise of extremism | Nazism | The Guardian | 2772 chars\n",
            "saved [guardian]: www.theguardian.com-don-t-let-the-dugong-follow-the-sea-cow-conservation-the-gua-760c362c9eaa.txt | Don’t let the dugong follow the sea cow | Conservation | The Guardian | 1707 chars\n",
            "saved [guardian]: www.theguardian.com-there-must-be-an-engels-playing-with-my-chart-history-the-gu-b7d94b823fce.txt | There must be an Engels (playing with my chart) | History | The Guardian | 1768 chars\n",
            "saved [guardian]: www.theguardian.com-timely-assurance-from-lear-s-kent-william-shakespeare-the-gu-891ed05bfd3b.txt | Timely assurance from Lear’s Kent | William Shakespeare | The Guardian | 753 chars\n",
            "saved [guardian]: www.theguardian.com-scientists-demand-cancer-warnings-on-bacon-and-ham-sold-in-u-f79dceea04fe.txt | Scientists demand cancer warnings on bacon and ham sold in UK | Cancer | The Guardian | 3707 chars\n",
            "saved [guardian]: www.theguardian.com-his-teeth-flew-out-of-his-mouth-and-landed-in-my-spaghetti-1-0fb4ede78925.txt | ‘His teeth flew out of his mouth and landed in my spaghetti’: 10 first date horror stories | 8757 chars\n",
            "saved [guardian]: www.theguardian.com-your-guardian-sport-weekend-rugby-league-ashes-lionesses-v-b-e264cf44793a.txt | Your Guardian sport weekend: rugby league Ashes, Lionesses v Brazil and F1’s title tussle  | 9426 chars\n",
            "saved [guardian]: www.theguardian.com-unflappable-witty-and-super-smart-the-rise-and-rise-of-claud-57236924810f.txt | ‘Unflappable, witty and super smart’: the rise and rise of Claudia Winkleman | Claudia Win | 5723 chars\n",
            "saved [guardian]: www.theguardian.com-blue-lights-is-more-than-great-tv-it-might-be-the-best-chanc-776b24148058.txt | Blue Lights is more than great TV. It might be the best chance Britons have of reckoning w | 7037 chars\n",
            "saved [guardian]: www.theguardian.com-the-rad-pack-david-beckham-leads-country-menswear-trend-men--44650114b805.txt | The Rad pack: David Beckham leads country menswear trend | Men's fashion | The Guardian | 4811 chars\n",
            "saved [guardian]: www.theguardian.com-tigest-girma-i-was-like-hey-do-you-want-black-vampires-and-t-de503d2c5b0b.txt | Tigest Girma: ‘I was like – Hey, do you want black vampires? And they were like – Yeah, we | 7690 chars\n",
            "saved [guardian]: www.theguardian.com-light-candles-at-breakfast-and-swap-your-alarm-33-easy-tips--187ea6ad7f45.txt | Light candles at breakfast and swap your alarm: 33 easy tips for better mornings | Autumn  | 12286 chars\n",
            "saved [guardian]: www.theguardian.com-she-took-chickens-from-a-slaughterhouse-was-it-a-rescue-or-a-714ff0a84abb.txt | She took chickens from a slaughterhouse. Was it a rescue or a crime? | US news | The Guard | 16203 chars\n",
            "saved [guardian]: www.theguardian.com-am-i-doing-this-right-how-to-master-the-lost-art-of-flirting-05173d162029.txt | ‘Am I doing this right?’: how to master the lost art of flirting | Dating | The Guardian | 8911 chars\n",
            "saved [guardian]: www.theguardian.com-i-don-t-make-it-easy-for-myself-divorce-and-desire-power-lil-f7db33021b3f.txt | ‘I don’t make it easy for myself’: divorce and desire power Lily Allen’s autofictional com | 5533 chars\n",
            "saved [guardian]: www.theguardian.com-nigel-farage-seeks-influence-over-bank-of-england-in-same-ve-08c0b3d50248.txt | Nigel Farage seeks influence over Bank of England in same vein as Trump and US Federal Res | 2592 chars\n",
            "saved [guardian]: www.theguardian.com-what-s-in-a-name-west-end-casting-directors-raise-concerns-a-e48a60cfe394.txt | What’s in a name? West End casting directors raise concerns about trend for big stars | Th | 5585 chars\n",
            "saved [guardian]: www.theguardian.com-the-assembled-parties-review-christmas-comes-early-in-a-crac-bcb63993991b.txt | The Assembled Parties review – Christmas comes early in a crackling family comedy | Theatr | 2364 chars\n",
            "saved [guardian]: www.theguardian.com-i-hate-that-they-show-my-bum-in-the-first-scene-david-duchov-0cd20b18eb19.txt | ‘I hate that they show my bum in the first scene!’ David Duchovny on poems, podcasts – and | 8412 chars\n",
            "saved [guardian]: www.theguardian.com-cocktail-of-the-week-brasserie-max-s-saketini-recipe-cocktai-1a6f5a406815.txt | Cocktail of the week: Brasserie Max’s saketini – recipe | Cocktails | The Guardian | 538 chars\n",
            "saved [guardian]: www.theguardian.com-tell-us-have-you-lived-in-temporary-accommodation-in-the-uk--9f1c840c7192.txt | Tell us: have you lived in temporary accommodation in the UK with children? | Housing | Th | 1147 chars\n",
            "saved [guardian]: www.theguardian.com-add-to-playlist-the-spiky-playful-free-jazz-of-laura-ann-sin-b66b0ef49cb5.txt | Add to playlist: the spiky, playful free jazz of Laura Ann Singh and the week’s best new t | 3451 chars\n",
            "saved [guardian]: www.theguardian.com-children-and-teens-roundup-the-best-new-picture-books-and-no-429e4339039a.txt | Children and teens roundup – the best new picture books and novels | Teen books | The Guar | 5475 chars\n",
            "saved [guardian]: www.theguardian.com-wales-revs-up-turner-casts-his-shadow-gursky-goes-large-and--07fc02d54e15.txt | Wales revs up, Turner casts his shadow, Gursky goes large and Wool keeps it woolly – the w | 2996 chars\n",
            "saved [guardian]: www.theguardian.com-clean-lines-and-a-connection-with-nature-the-modernist-beach-5a2af180c1fa.txt | Clean lines and a connection with nature: the modernist beach house jutting out over a Sco | 4730 chars\n",
            "saved [guardian]: www.theguardian.com-who-s-afraid-of-virginia-woolf-review-carnage-in-new-carthag-ce3486d9229e.txt | Who’s Afraid of Virginia Woolf? review – carnage in New Carthage as couples fight, flirt,  | 3166 chars\n",
            "saved [guardian]: www.theguardian.com-the-best-beard-trimmers-to-groom-in-comfort-and-style-tested-af5d5aaec98b.txt | The best beard trimmers to groom in comfort and style, tested | Men | The Guardian | 18048 chars\n",
            "saved [guardian]: www.theguardian.com-are-digital-board-games-as-fun-as-the-real-thing-turns-out-a-6e9d0bbe375d.txt | Are digital board games as fun as the real thing? Turns out: absolutely not | Games | The  | 4735 chars\n",
            "saved [guardian]: www.theguardian.com-raise-the-questions-don-t-provide-the-answers-composer-jake--23f3e26880ac.txt | ‘Raise the questions. Don’t provide the answers’: composer Jake Heggie on 25 years of Dead | 6529 chars\n",
            "saved [guardian]: www.theguardian.com-lily-allen-west-end-girl-a-gobsmacking-autopsy-of-marital-be-c211a0fe1bf9.txt | Lily Allen: West End Girl – a gobsmacking autopsy of marital betrayal | Lily Allen | The G | 5535 chars\n",
            "saved [guardian]: www.theguardian.com-a-mind-of-my-own-by-kathy-burke-review-a-brilliant-blunt-and-6abbefe39f14.txt | A Mind of My Own by Kathy Burke review – a brilliant, blunt and beautiful memoir | Books | | 4425 chars\n",
            "saved [guardian]: www.theguardian.com-does-the-word-luxury-mean-anything-now-fashion-the-guardian-fb3084984b51.txt | Does the word luxury mean anything now? | Fashion | The Guardian | 4818 chars\n",
            "saved [guardian]: www.theguardian.com-not-many-pub-lunches-require-a-trip-across-the-atlantic-read-b63bee11e0a3.txt | ‘Not many pub lunches require a trip across the Atlantic’: readers’ favourite UK country p | 6492 chars\n",
            "saved [guardian]: www.theguardian.com-helen-goh-s-recipe-for-forest-floor-cake-cake-the-guardian-6ab06df1938c.txt | Helen Goh’s recipe for forest floor cake | Cake | The Guardian | 3724 chars\n",
            "saved [guardian]: www.theguardian.com-sweater-weather-what-to-wear-with-a-chunky-knit-fashion-the--ad9e009ec4e8.txt | Sweater weather: what to wear with a chunky knit | Fashion | The Guardian | 331 chars\n",
            "saved [guardian]: www.theguardian.com-posh-proud-and-impossible-to-ignore-the-incredible-life-of-a-cc08f79ad04e.txt | Posh, proud and impossible to ignore: the incredible life of Annabel Goldsmith | Aristocra | 9143 chars\n",
            "saved [guardian]: www.theguardian.com-herbal-supplements-were-supposed-to-make-them-healthier-inst-7f6cfc539d4f.txt | Herbal supplements were supposed to make them healthier. Instead, they got sick | Well act | 10168 chars\n",
            "saved [guardian]: www.theguardian.com-dictator-for-life-vibes-our-architecture-critic-on-trump-s-b-6de08fd4382e.txt | ‘Dictator-for-life vibes’: our architecture critic on Trump’s bulletproof ballroom bling | | 5454 chars\n",
            "saved [guardian]: www.theguardian.com-fermented-in-the-gut-scientists-uncover-clues-about-kopi-luw-9a7f2c753076.txt | ‘Fermented in the gut’: scientists uncover clues about kopi luwak coffee’s unique taste |  | 3476 chars\n",
            "saved [guardian]: www.theguardian.com-the-10-best-e-readers-in-the-uk-from-kindle-to-kobo-and-beyo-ce8c202b8362.txt | The 10 best e-readers in the UK, from Kindle to Kobo and beyond – tried and tested | E-rea | 25245 chars\n",
            "saved [guardian]: www.theguardian.com-a-rift-that-took-500-years-to-repair-king-charles-prays-with-0057d09e086d.txt | A rift that took 500 years to repair: King Charles prays with the pope | Catholicism | The | 3072 chars\n",
            "saved [guardian]: www.theguardian.com-toe-curling-fashion-how-did-toe-shoes-become-so-popular-fash-cc50026a02b1.txt | Toe-curling fashion: how did toe shoes become so popular? | Fashion | The Guardian | 3442 chars\n",
            "saved [guardian]: www.theguardian.com-i-am-content-being-single-how-do-i-make-people-understand-th-f92d6764c212.txt | I am content being single. How do I make people understand that I’m happy as I am? | Famil | 3892 chars\n",
            "saved [guardian]: www.theguardian.com-give-me-shelter-protecting-trafficked-children-in-the-us-doc-e64755f159a0.txt | Give me shelter: protecting trafficked children in the US - documentary | Documentary film | 1278 chars\n",
            "saved [guardian]: www.theguardian.com-to-wash-or-not-to-wash-how-to-look-after-your-knitwear-exper-dca5e94406c3.txt | To wash or not to wash? How to look after your knitwear: expert tips to stop shrinking, bo | 6702 chars\n",
            "saved [guardian]: www.theguardian.com-get-your-jabs-don-t-oversleep-don-t-be-too-keen-to-go-to-wor-7561515be9d8.txt | Get your jabs, don’t oversleep, don’t be too keen to go to work: GPs’ tips for battling wi | 10902 chars\n",
            "saved [guardian]: www.theguardian.com-i-cannot-stop-playing-this-preposterous-game-about-falling-d-16a8ab61d089.txt | I cannot stop playing this preposterous game about falling down a mountain | Games | The G | 5750 chars\n",
            "saved [guardian]: www.theguardian.com-a-train-tour-of-europe-s-cool-northern-capitals-from-london--c2dc7483ae8e.txt | A train tour of Europe’s cool northern capitals: from London to Vilnius, via Berlin and Wa | 8618 chars\n",
            "saved [guardian]: www.theguardian.com-nothing-ear-3-review-good-looking-earbuds-with-super-mic-par-548c62fd6ffa.txt | Nothing Ear 3 review: good-looking earbuds with ‘Super Mic’ party trick | Headphones | The | 5522 chars\n",
            "saved [guardian]: www.theguardian.com-the-pressure-to-get-your-old-body-back-is-immense-the-new-mo-13ad366c57be.txt | ‘The pressure to get your old body back is immense’: the new mothers driven to weight-loss | 11245 chars\n",
            "saved [guardian]: www.theguardian.com-could-this-brutal-and-restrictive-therapy-cure-my-intense-in-4647f79fe71f.txt | Could this ‘brutal and restrictive’ therapy cure my intense insomnia? | Well actually | Th | 8646 chars\n",
            "saved [guardian]: www.theguardian.com-average-but-arresting-games-used-to-be-the-backbone-of-the-i-348b75a19739.txt | Average-but-arresting games used to be the backbone of the industry. What price perfection | 8979 chars\n",
            "saved [guardian]: www.theguardian.com-nhs-staff-have-you-seen-or-been-affected-by-violence-in-hosp-9418b76148ce.txt | NHS staff: have you seen or been affected by violence in hospital? | NHS | The Guardian | 485 chars\n",
            "saved [guardian]: www.theguardian.com-a-force-of-nature-who-took-no-prisoners-a-tribute-to-ninja-g-5d11337ca450.txt | ‘A force of nature who took no prisoners’: a tribute to Ninja Gaiden creator Tomonobu Itag | 4347 chars\n",
            "saved [guardian]: www.theguardian.com-where-tourists-seldom-tread-part-19-three-uk-towns-with-indu-07fbbe3bfb07.txt | Where tourists seldom tread, part 19: three UK towns with industrial legacies | United Kin | 10586 chars\n",
            "saved [guardian]: www.theguardian.com-rats-how-to-banish-rodents-bedbugs-and-other-pests-from-your-97ee7c678fe5.txt | Rats! How to banish rodents, bedbugs and other pests from your home | Home improvements |  | 7513 chars\n",
            "saved [guardian]: www.theguardian.com-uk-women-in-tech-we-would-like-to-hear-from-you-technology-t-9b8ff29d5ff7.txt | UK women in tech: we would like to hear from you | Technology | The Guardian | 1155 chars\n",
            "saved [guardian]: www.theguardian.com-feel-like-your-mind-and-body-are-separate-here-s-how-life-ch-93680efb82da.txt | Feel like your mind and body are separate? Here’s how life changes when we become whole |  | 5463 chars\n",
            "saved [guardian]: www.theguardian.com-travelodge-guest-suffers-sleepless-night-as-hotel-says-it-is-3d0f28030655.txt | Travelodge guest suffers sleepless night as hotel says it is ‘overbooked’ | Money | The Gu | 4653 chars\n",
            "saved [guardian]: www.theguardian.com-the-kindness-of-strangers-a-gang-of-scary-looking-youths-ste-dd6c9bbebf76.txt | The kindness of strangers: a gang of scary-looking youths stepped in to save me from being | 2292 chars\n",
            "saved [guardian]: www.theguardian.com-tell-us-how-have-price-rises-affected-your-spending-habits-m-bc7f99d07035.txt | Tell us: how have price rises affected your spending habits? | Money | The Guardian | 516 chars\n",
            "saved [guardian]: www.theguardian.com-sign-up-for-the-filter-uk-newsletter-our-free-weekly-buying--9a5a7ac5d623.txt | Sign up for the Filter UK newsletter: our free weekly buying advice | Newsletter sign-up | | 389 chars\n",
            "saved [guardian]: www.theguardian.com-sign-up-for-the-guide-newsletter-our-free-pop-culture-email--26c40d314caf.txt | Sign up for the Guide newsletter: our free pop-culture email | Newsletter sign-up | The Gu | 261 chars\n",
            "saved [guardian]: www.theguardian.com-sign-up-for-the-first-edition-newsletter-our-free-daily-news-f5485e83d7ca.txt | Sign up for the First Edition newsletter: our free daily news email | Newsletter sign-up | | 462 chars\n",
            "saved [guardian]: www.theguardian.com-sign-up-for-the-feast-newsletter-our-free-guardian-food-emai-20009ccd8396.txt | Sign up for the Feast newsletter: our free Guardian food email | Food | The Guardian | 311 chars\n",
            "saved [bbc]: www.bbc.com-man-arrested-after-viral-video-of-alleged-attempted-rape-on--ce0c20271f46.txt | Man arrested after viral video of alleged attempted rape on Paris train | 2011 chars\n",
            "skip (cached) [bbc]: https://www.bbc.com/sport/rugby-league/articles/c74jz23jdp0o?at_medium=RSS&at_campaign=rss\n",
            "saved [bbc]: www.bbc.com-trump-x27-friend-x27-donates-130m-to-help-fund-us-military-d-ce8d50319ea3.txt | Trump &#x27;friend&#x27; donates $130m to help fund US military during shutdown | 3130 chars\n",
            "saved [bbc]: www.bbc.com-met-police-reviewing-9-000-grooming-cases-over-15-years-6b919c8bdcd6.txt | Met Police reviewing 9,000 grooming cases over 15 years | 2562 chars\n",
            "saved [bbc]: www.bbc.com-will-lucy-powell-x27-s-win-turn-things-around-for-labour-92d483a64644.txt | Will Lucy Powell&#x27;s win turn things around for Labour? | 2753 chars\n",
            "saved [bbc]: www.bbc.com-untitled-68dd4b2a694e.txt | Untitled | 400 chars\n",
            "saved [bbc]: www.bbc.com-parents-urged-to-vaccinate-children-as-flu-cases-rise-5fb900fafcde.txt | Parents urged to vaccinate children as flu cases rise | 2550 chars\n",
            "saved [bbc]: www.bbc.com-venezuela-x27-s-maduro-says-us-x27-fabricating-war-x27-after-a55a023ca616.txt | Venezuela&#x27;s Maduro says US &#x27;fabricating war&#x27; after it deployed huge warship | 4851 chars\n",
            "saved [bbc]: www.bbc.com-first-raid-on-uk-illegal-weight-loss-drug-factory-in-northam-9f9d0035bcb9.txt | First raid on UK illegal weight loss drug factory in Northampton | 2224 chars\n",
            "saved [bbc]: www.bbc.com-kamala-harris-tells-bbc-she-may-run-for-president-again-da7f3c164773.txt | Kamala Harris tells BBC she may run for president again | 7342 chars\n",
            "saved [bbc]: www.bbc.com-lucy-powell-elected-labour-x27-s-deputy-leader-ac6a7984fb34.txt | Lucy Powell elected Labour&#x27;s deputy leader | 5897 chars\n",
            "saved [bbc]: www.bbc.com-untitled-e74923f8c62b.txt | Untitled | 449 chars\n",
            "saved [bbc]: www.bbc.com-how-to-cope-with-long-winter-nights-when-the-clocks-go-back-7a2cf6e27565.txt | How to cope with long winter nights when the clocks go back | 5908 chars\n",
            "saved [bbc]: www.bbc.com-gaza-children-dying-as-they-wait-for-israel-to-enable-evacua-7c493885fd32.txt | Gaza children dying as they wait for Israel to enable evacuations | 5392 chars\n",
            "saved [bbc]: www.bbc.com-britney-spears-said-she-was-used-kevin-federline-says-she-ne-0c1637f865f3.txt | Britney Spears said she was used. Kevin Federline says she needs help | 10541 chars\n",
            "saved [bbc]: www.bbc.com-tiktok-awards-spud-sellers-posh-girl-comedy-and-bus-loving-a-3a454f5eef71.txt | TikTok awards: Spud sellers, posh girl comedy and bus loving aunty among nominees | 7423 chars\n",
            "saved [bbc]: www.bbc.com-what-is-driving-the-decision-to-learn-in-a-manual-or-automat-36d9fe9ac039.txt | What is driving the decision to learn in a manual or automatic car? | 5859 chars\n",
            "saved [bbc]: www.bbc.com-magnesium-can-this-quot-miracle-mineral-quot-really-help-us--362852666953.txt | Magnesium: Can this &quot;miracle mineral&quot; really help us sleep? | 7004 chars\n",
            "saved [bbc]: www.bbc.co.uk-the-big-cases-the-bodies-in-the-suitcases-bbc-iplayer-887a0a728a4e.txt | The Big Cases - The Bodies in the Suitcases - BBC iPlayer | 4209 chars\n",
            "saved [bbc]: www.bbc.co.uk-untitled-a0009784c3aa.txt | Untitled | 1308 chars\n",
            "saved [bbc]: www.bbc.co.uk-untitled-8ab4836313b0.txt | Untitled | 940 chars\n",
            "saved [bbc]: www.bbc.com-uckfield-charity-says-bears-x27-enjoy-life-to-the-full-x27-a-0b202d7b1e56.txt | Uckfield charity says bears &#x27;enjoy life to the full&#x27; after rescue | 2155 chars\n",
            "saved [bbc]: www.bbc.com-pen-pals-from-canada-and-singapore-meet-after-43-years-0522b8a15315.txt | Pen pals from Canada and Singapore meet after 43 years | 462 chars\n",
            "saved [bbc]: www.bbc.com-preston-cafe-owner-starts-x27-phone-jail-x27-to-encourage-mo-b316d5644033.txt | Preston cafe owner starts &#x27;phone jail&#x27; to encourage more chatting | 2308 chars\n",
            "saved [bbc]: www.bbc.com-jimmy-fallon-borrows-kilt-from-hotel-manager-for-king-x27-s--6a009b550eb4.txt | Jimmy Fallon borrows kilt from hotel manager for King&#x27;s Guard dinner | 2531 chars\n",
            "saved [bbc]: www.bbc.co.uk-banned-in-the-80s-moments-that-shook-music-bbc-iplayer-a708fa416575.txt | Banned in the 80s: Moments That Shook Music - BBC iPlayer | 2025 chars\n",
            "saved [bbc]: www.bbc.co.uk-untitled-57bafeb95415.txt | Untitled | 1266 chars\n",
            "skip (cached) [cityjournal]: https://www.city-journal.org/article/max-h-bazerman-inside-an-academic-scandal-fraudulent-data-study\n",
            "saved [cityjournal]: www.city-journal.org-why-mamdani-struggled-with-working-class-voters-4d3c9dc2ea36.txt | Why Mamdani Struggled With Working-Class Voters | 6583 chars\n",
            "saved [cityjournal]: www.city-journal.org-why-schools-of-civic-thought-matter-2ffbcc4dc006.txt | Why Schools of Civic Thought Matter | 6017 chars\n",
            "saved [cityjournal]: www.city-journal.org-city-journal-urban-affairs-magazine-conservative-magazine-on-928974a09071.txt | City Journal | Urban Affairs Magazine | Conservative Magazine Online | 1833 chars\n",
            "saved [cityjournal]: www.city-journal.org-new-york-rsquo-s-latino-electorate-will-play-decisive-role-i-e270b8862590.txt | New York&rsquo;s Latino Electorate Will Play Decisive Role in Mayoral Race | 4693 chars\n",
            "saved [cityjournal]: www.city-journal.org-mayoral-debate-highlights-who-stood-out-city-journal-podcast-451d7fe71d00.txt | Mayoral Debate Highlights: Who Stood Out? City Journal Podcast | 49149 chars\n",
            "saved [cityjournal]: www.city-journal.org-mamdani-cuomo-spar-in-second-debate-30dfbfc6694b.txt | Mamdani, Cuomo Spar in Second Debate | 7050 chars\n",
            "saved [cityjournal]: www.city-journal.org-the-group-chat-trap-1a6780e1c64b.txt | The Group Chat Trap | 928 chars\n",
            "saved [cityjournal]: www.city-journal.org-a-long-overdue-shakeup-in-higher-education-de15e6fb254b.txt | A Long-Overdue Shakeup in Higher Education | 8470 chars\n",
            "saved [cityjournal]: www.city-journal.org-the-city-journal-college-rankings-0aab4e103c9c.txt | The City Journal College Rankings | 4950 chars\n",
            "saved [dailycaller]: dailycaller.com-d-c-del-norton-reportedly-in-early-stages-of-dementia-scamme-850bc31d67e9.txt | D.C. Del. Norton, Reportedly In ‘Early Stages Of Dementia,’ Scammed By Suspects Masqueradi | 4603 chars\n",
            "skip (cached) [dailycaller]: https://dailycaller.com/2025/10/25/4-dead-russian-attacks-ukraine-missiles-drones/\n",
            "saved [dailycaller]: dailycaller.com-ro-khanna-defends-populism-despite-representing-tech-oligarc-85b70158843c.txt | Ro Khanna Defends Populism Despite Representing Tech Oligarchs | The Daily Caller | 757 chars\n",
            "saved [dailycaller]: dailycaller.com-trump-nominates-new-person-to-lead-commodity-futures-trading-546569ef5dd3.txt | Trump Nominates New Person To Lead Commodity Futures Trading Commission | The Daily Caller | 2067 chars\n",
            "saved [dailycaller]: dailycaller.com-venezuela-in-the-trump-administration-s-crosshairs-will-war--c70e3efee4f9.txt | Venezuela In The Trump Administration’s Crosshairs: Will War Follow? | The Daily Caller | 5149 chars\n",
            "saved [dailycaller]: dailycaller.com-tulsi-gabbard-reveals-how-trump-showed-his-seriousness-again-b0ac6d692b96.txt | Tulsi Gabbard Reveals How Trump Showed ‘His Seriousness’ Against The Cartels Who Ran Borde | 3074 chars\n",
            "saved [dailycaller]: dailycaller.com-gavin-newsom-talks-ai-with-bill-clinton-the-daily-caller-dd4301cb4bc2.txt | Gavin Newsom Talks AI With Bill Clinton? | The Daily Caller | 599 chars\n",
            "saved [dailycaller]: dailycaller.com-independent-journalist-shocks-jesse-watters-with-antifa-memb-fd21b378e48c.txt | Independent Journalist Shocks Jesse Watters With Antifa Members’ Alleged Day Jobs | The Da | 2722 chars\n",
            "saved [dailycaller]: dailycaller.com-msnbc-guest-pushes-bizarre-claim-trump-plans-to-use-military-66d24d9e8775.txt | MSNBC Guest Pushes Bizarre Claim Trump Plans To Use Military To Kill Any Person He Wants | | 4023 chars\n",
            "saved [dailycaller]: dailycaller.com-not-all-racist-bigoted-morons-democrat-rep-stuns-with-his-ta-b85dc1e63071.txt | ‘Not All Racist, Bigoted Morons’: Democrat Rep Stuns With His Take On Trump Voters | The D | 4674 chars\n",
            "saved [dailycaller]: dailycaller.com-kellyanne-conway-says-left-is-zealous-because-they-re-jealou-5d4bec6ba534.txt | Kellyanne Conway Says Left ‘Is Zealous Because They’re Jealous’ About Trump’s Ballroom | T | 3555 chars\n",
            "saved [dailycaller]: dailycaller.com-northeast-mid-atlantic-could-see-halloween-plans-ruined-than-9746264c78d7.txt | Northeast, Mid-Atlantic Could See Halloween Plans Ruined Thanks To Potential Spooky Nor’ea | 1892 chars\n",
            "saved [dailycaller]: dailycaller.com-democrat-caused-stephen-miller-goes-off-on-newsom-handing-ou-63d445a1067f.txt | ‘Democrat-Caused’: Stephen Miller Goes Off On Newsom Handing Out CDLs To Illegals, Followi | 3424 chars\n",
            "saved [dailycaller]: dailycaller.com-mehek-cooke-democrats-shutdown-misplay-gives-trump-rare-oppo-20e9f2e4fbb2.txt | MEHEK COOKE: Democrats’ Shutdown Misplay Gives Trump Rare Opportunity | The Daily Caller | 6928 chars\n",
            "saved [dailycaller]: dailycaller.com-cnn-contributor-says-with-straight-face-trump-third-term-tal-2d9b1ac51489.txt | CNN Contributor Says With Straight Face Trump Third Term Talk Has Been ‘Incredibly Trigger | 3299 chars\n",
            "saved [dailycaller]: dailycaller.com-kid-rock-shocks-jesse-watters-into-fit-of-laughter-when-he-r-6eb897e5a98b.txt | Kid Rock Shocks Jesse Watters Into Fit Of Laughter When He Reveals Halloween Costume | The | 1496 chars\n",
            "saved [dailycaller]: dailycaller.com-abigail-spanberger-fundraises-with-aoc-in-final-stretch-of-g-623c46fee840.txt | Abigail Spanberger Fundraises With AOC In Final Stretch Of Governor’s Race | The Daily Cal | 3789 chars\n",
            "saved [dailycaller]: dailycaller.com-report-third-person-allegedly-dies-at-florida-s-walt-disney--b8add2bde637.txt | REPORT: Third Person Allegedly Dies At Florida’s Walt Disney World Theme Park In 10 Days | | 1948 chars\n",
            "saved [dailycaller]: dailycaller.com-quiet-as-a-whisper-german-firm-who-built-lift-allegedly-used-3efe39a3da9d.txt | ‘Quiet As A Whisper’: German Firm Who Built Lift Allegedly Used In Brazen Louvre Heist Pos | 2360 chars\n",
            "saved [dailycaller]: dailycaller.com-dems-probably-won-t-be-able-to-govern-if-they-win-big-in-202-073681318e00.txt | Dems Probably Won’t Be Able To Govern If They Win Big In 2026, House Dem Says | The Daily  | 3672 chars\n",
            "skip (cached) [theconversation]: https://theconversation.com/pumpkins-journey-from-ancient-food-staple-to-spicy-fall-obsession-spans-thousands-of-years-268260\n",
            "saved [theconversation]: theconversation.com-dinosaur-mummies-help-scientists-visualize-the-fleshy-detail-96b2a09dfc19.txt | Dinosaur ‘mummies’ help scientists visualize the fleshy details of these ancient animals | 7085 chars\n",
            "saved [theconversation]: theconversation.com-the-lost-history-of-latin-america-s-role-in-averting-catastr-ec63fdb5b220.txt | The lost history of Latin America’s role in averting catastrophe during the Cuban missile  | 7768 chars\n",
            "saved [theconversation]: theconversation.com-relying-heavily-on-contractors-can-cut-attendance-by-27-for--aafd4dad78a7.txt | Relying heavily on contractors can cut attendance by 27% for museums, theaters and other a | 4337 chars\n",
            "saved [theconversation]: theconversation.com-influencers-could-learn-a-thing-or-two-from-traditional-jour-e8445745f57d.txt | Influencers could learn a thing or two from traditional journalism about disclosing who’s  | 7374 chars\n",
            "saved [theconversation]: theconversation.com-navigating-mental-illness-in-the-workplace-can-be-tricky-but-5322687dc783.txt | Navigating mental illness in the workplace can be tricky, but employees are entitled to ac | 6847 chars\n",
            "saved [theconversation]: theconversation.com-you-ve-just-stolen-a-priceless-artifact-what-happens-next-40ac999ed613.txt | You’ve just stolen a priceless artifact – what happens next? | 6321 chars\n",
            "saved [theconversation]: theconversation.com-demolishing-the-white-house-east-wing-to-build-a-ballroom-em-a79bad8b4213.txt | Demolishing the White House East Wing to build a ballroom embodies Trump’s heritage politi | 8500 chars\n",
            "saved [theconversation]: theconversation.com-2-iconic-coral-species-are-now-functionally-extinct-off-flor-0484ce9ed257.txt | 2 iconic coral species are now functionally extinct off Florida, study finds – we witnesse | 6404 chars\n",
            "saved [theconversation]: theconversation.com-japan-s-sumo-association-turns-100-but-the-sport-s-rituals-h-fa61502c7169.txt | Japan’s sumo association turns 100 – but the sport’s rituals have a much older role shapin | 7642 chars\n",
            "saved [theconversation]: theconversation.com-building-a-stable-abode-of-thought-kant-s-rules-for-virtuous-cbb65342ecb9.txt | Building a stable ‘abode of thought’: Kant’s rules for virtuous thinking | 7320 chars\n",
            "saved [theconversation]: theconversation.com-surrealism-is-better-known-for-its-strangeness-than-the-radi-544012c31d49.txt | Surrealism is better known for its strangeness than the radical politics and revolutionary | 5873 chars\n",
            "saved [theconversation]: theconversation.com-coal-plants-emitted-more-pollution-during-the-last-governmen-b02514ab864e.txt | Coal plants emitted more pollution during the last government shutdown, while regulators w | 6821 chars\n",
            "saved [theconversation]: theconversation.com-why-your-late-teens-and-early-20s-are-crucial-times-for-life-215e1f5ccb29.txt | Why your late teens and early 20s are crucial times for lifelong heart health | 7249 chars\n",
            "saved [theconversation]: theconversation.com-james-comey-s-lawyers-face-an-uphill-battle-to-prove-selecti-45eea2be0fff.txt | James Comey’s lawyers face an uphill battle to prove selective or vindictive prosecution i | 3789 chars\n",
            "saved [theconversation]: theconversation.com-1-in-3-us-nonprofits-that-serve-communities-lost-government--d09aeac165de.txt | 1 in 3 US nonprofits that serve communities lost government funding in early 2025 | 4212 chars\n",
            "saved [theconversation]: theconversation.com-a-flexible-lens-controlled-by-light-activated-artificial-mus-a9ce0739660d.txt | A flexible lens controlled by light-activated artificial muscles promises to let soft mach | 3719 chars\n",
            "saved [theconversation]: theconversation.com-covid-19-mrna-vaccines-could-unlock-the-next-revolution-in-c-eaa7b1d1c4c0.txt | COVID-19 mRNA vaccines could unlock the next revolution in cancer treatment – new research | 4667 chars\n",
            "saved [theconversation]: theconversation.com-is-it-wrong-to-have-too-much-money-your-answer-may-depend-on-eb24ccb8d307.txt | Is it wrong to have too much money? Your answer may depend on deep-seated values – and you | 4668 chars\n",
            "saved [theconversation]: theconversation.com-office-of-space-commerce-faces-an-uncertain-future-amid-budg-d13192ec24bd.txt | Office of Space Commerce faces an uncertain future amid budget cuts and new oversight | 6800 chars\n",
            "saved [theconversation]: theconversation.com-the-disgraceful-history-of-erasing-black-cemeteries-in-the-u-fb1278e5759c.txt | The disgraceful history of erasing Black cemeteries in the United States | 6384 chars\n",
            "saved [theconversation]: theconversation.com-can-ai-keep-students-motivated-or-does-it-do-the-opposite-80bad71f8a23.txt | Can AI keep students motivated, or does it do the opposite? | 7584 chars\n",
            "saved [theconversation]: theconversation.com-college-faculty-are-under-pressure-to-say-and-do-the-right-t-7f7e8738b398.txt | College faculty are under pressure to say and do the right thing – the stress also trickle | 6468 chars\n",
            "saved [theconversation]: theconversation.com-giant-ground-sloths-fossilized-teeth-reveal-their-unique-rol-4d8dca72f177.txt | Giant ground sloths’ fossilized teeth reveal their unique roles in the prehistoric ecosyst | 5867 chars\n",
            "saved [theconversation]: theconversation.com-king-pope-jedi-superman-trump-s-social-media-images-exclusiv-b0a42b2af052.txt | King, pope, Jedi, Superman: Trump’s social media images exclusively target his base and tr | 7199 chars\n",
            "saved [theconversation]: theconversation.com-trump-s-national-guard-deployments-reignite-200-year-old-leg-16f5910d885a.txt | Trump’s National Guard deployments reignite 200-year-old legal debate over state vs. feder | 7315 chars\n",
            "saved [theconversation]: theconversation.com-when-it-comes-to-ukraine-peace-negotiations-it-s-all-over-th-c904f82413ee.txt | When it comes to Ukraine peace negotiations, it’s all over the map | 7608 chars\n",
            "saved [theconversation]: theconversation.com-gender-is-not-an-ideology-but-conservative-groups-know-learn-54af329b3f89.txt | Gender is not an ideology – but conservative groups know learning about it empowers people | 7978 chars\n",
            "saved [theconversation]: theconversation.com-even-before-they-can-read-young-children-are-visualizing-let-485be9558129.txt | Even before they can read, young children are visualizing letters and other objects with t | 5791 chars\n",
            "saved [theconversation]: theconversation.com-many-colorado-homeowners-are-underinsured-here-s-what-to-do--a36c319f207f.txt | Many Colorado homeowners are underinsured − here’s what to do before the next fire | 5593 chars\n",
            "saved [theconversation]: theconversation.com-does-the-full-moon-make-us-sleepless-a-neurologist-explains--4a2a33bca44a.txt | Does the full moon make us sleepless? A neurologist explains the science behind sleep, moo | 6319 chars\n",
            "saved [theconversation]: theconversation.com-trump-s-words-aren-t-stopping-china-brazil-and-many-other-co-c69917843812.txt | Trump’s words aren’t stopping China, Brazil and many other countries from setting higher c | 9539 chars\n",
            "saved [theconversation]: theconversation.com-astronauts-can-get-motion-sick-while-splashing-back-down-to--0591b5c678e8.txt | Astronauts can get motion sick while splashing back down to Earth – virtual reality headse | 7376 chars\n",
            "saved [theconversation]: theconversation.com-rethinking-polygamy-new-research-upends-conventional-thinkin-21e9bd3a1a51.txt | Rethinking polygamy – new research upends conventional thinking about the advantages of mo | 8318 chars\n",
            "saved [theconversation]: theconversation.com-flying-is-safe-thanks-to-data-and-cooperation-here-s-what-th-7e344625faf0.txt | Flying is safe thanks to data and cooperation – here’s what the AI industry could learn fr | 6302 chars\n",
            "saved [theconversation]: theconversation.com-when-coal-smoke-choked-st-louis-residents-fought-back-but-it-295c9b0098eb.txt | When coal smoke choked St. Louis, residents fought back − but it took time and money | 6456 chars\n",
            "saved [theconversation]: theconversation.com-the-erie-canal-how-a-big-ditch-transformed-america-s-economy-f77fb96a99c8.txt | The Erie Canal: How a ‘big ditch’ transformed America’s economy, culture and even religion | 6293 chars\n",
            "saved [theconversation]: theconversation.com-space-exploration-in-the-backyard-on-a-budget-how-nasa-simul-78bc5426d6d2.txt | Space exploration in the backyard, on a budget – how NASA simulates conditions in space wi | 7952 chars\n",
            "saved [theconversation]: theconversation.com-why-are-women-s-shoes-so-pointy-a-fashion-expert-on-impracti-b5a087ccdc47.txt | Why are women’s shoes so pointy? A fashion expert on impractical but stylish footwear | 5791 chars\n",
            "saved [theconversation]: theconversation.com-pharaohs-in-dixieland-how-19th-century-america-reimagined-eg-cae894922bac.txt | Pharaohs in Dixieland – how 19th-century America reimagined Egypt to justify racism and sl | 8172 chars\n",
            "saved [theconversation]: theconversation.com-how-mobsters-own-words-brought-down-philly-s-mafia-a-veteran-68a231be0aad.txt | How mobsters’ own words brought down Philly’s mafia − a veteran crime reporter has the sto | 7792 chars\n",
            "saved [theconversation]: theconversation.com-gunboat-diplomacy-how-classic-naval-coercion-has-evolved-int-6f044f8a346b.txt | Gunboat diplomacy: How classic naval coercion has evolved into hybrid warfare on the water | 5653 chars\n",
            "saved [theconversation]: theconversation.com-why-is-halloween-starting-so-much-earlier-each-year-a-busine-ff082d18e66a.txt | Why is Halloween starting so much earlier each year? A business professor explains | 4067 chars\n",
            "saved [theconversation]: theconversation.com-how-ai-can-improve-storm-surge-forecasts-to-help-save-lives-d57218568b77.txt | How AI can improve storm surge forecasts to help save lives | 5573 chars\n",
            "saved [theconversation]: theconversation.com-openai-slipped-shopping-into-800-million-chatgpt-users-chats-9b8bfc9e09a2.txt | OpenAI slipped shopping into 800 million ChatGPT users’ chats − here’s why that matters | 5787 chars\n",
            "saved [theconversation]: theconversation.com-10-effective-things-citizens-can-do-to-make-change-in-additi-74077f82c9fe.txt | 10 effective things citizens can do to make change in addition to attending a protest | 8527 chars\n",
            "saved [theconversation]: theconversation.com-pennsylvania-s-budget-crisis-drags-on-as-fed-shutdown-adds-t-5c2deffe8eb3.txt | Pennsylvania’s budget crisis drags on as fed shutdown adds to residents’ hardships | 5882 chars\n",
            "saved [theconversation]: theconversation.com-protein-powders-and-shakes-contain-high-amounts-of-lead-new--11e942e03d66.txt | Protein powders and shakes contain high amounts of lead, new report says – a pharmacologis | 6731 chars\n",
            "saved [theconversation]: theconversation.com-how-new-foreign-worker-visa-fees-might-worsen-doctor-shortag-e02561a98fde.txt | How new foreign worker visa fees might worsen doctor shortages in rural America | 6353 chars\n",
            "saved [theconversation]: theconversation.com-antioxidants-help-stave-off-a-host-of-health-problems-but-fi-f614e66e156e.txt | Antioxidants help stave off a host of health problems – but figuring out how much you’re g | 5428 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-3ea4ab918932.txt | play | 4157 chars\n",
            "skip (cached) [aljazeera]: https://www.aljazeera.com/news/2025/10/25/connolly-set-to-be-irelands-next-president-after-rival-concedes-defeat?traffic_source=rss\n",
            "saved [aljazeera]: www.aljazeera.com-play-345f28381aae.txt | play | 370 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-68f7156bc7ff.txt | play | 456 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-0fae0082b67d.txt | play | 3593 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-2f9aaccb9c16.txt | play | 1324 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-e2cec7c337e0.txt | play | 426 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-6c675e150d02.txt | play | 2444 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-d0cf8b073aa9.txt | play | 6783 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-c97e71c5bcaf.txt | play | 4843 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-1ca7fbda1241.txt | play | 708 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-0d98894ff143.txt | play | 8851 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-399454bc8387.txt | play | 4256 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-fef9107621d0.txt | play | 5081 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-63d3d83be7f5.txt | play | 4184 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-b27f0c0e125b.txt | play | 6590 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-a59e96375634.txt | play | 3749 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-abc50bfc26c1.txt | play | 469 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-80fe7cd3e2c4.txt | play | 5696 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-44e9b098b644.txt | play | 779 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-93acc95898f0.txt | play | 3427 chars\n",
            "saved [aljazeera]: www.aljazeera.com-play-3af2f2cf8876.txt | play | 5714 chars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 8 of N - topic embeddings to Chroma\n",
        "\n",
        "Purpose\n",
        "Generate multi topic embeddings per article and upsert into the topic collection. This models what the article is about. Each article may get multiple topic vectors.\n",
        "\n",
        "Why this matters\n",
        "Topical neighbors power the first half of contrastive retrieval.\n",
        "\n",
        "Outputs\n",
        "Vectors upserted into the topic collection with structured metadata."
      ],
      "metadata": {
        "id": "o-xZkiif5ajG"
      },
      "id": "o-xZkiif5ajG"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Setup 8 of N — Topic Embeddings (Anchor + OpenAI Hybrid, merged for Code 1)\n",
        "# ==============================\n",
        "\n",
        "import os, json, time, numpy as np, nltk, torch, warnings\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import chromadb\n",
        "from openai import OpenAI\n",
        "warnings.filterwarnings(\"ignore\", message=\"Token indices sequence length is longer\")\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "RAW_DIR = PROJECT_ROOT / \"raw\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- Config ---\n",
        "topic_model_name = CONFIG[\"embeddings\"][\"topic_model\"]\n",
        "topic_dim = int(CONFIG[\"embeddings\"][\"dim\"])\n",
        "topic_dtype = CONFIG[\"embeddings\"][\"dtype\"]\n",
        "chunk_tokens = int(CONFIG[\"embeddings\"][\"chunk_tokens\"])\n",
        "MAX_TOPICS = CONFIG[\"topics\"].get(\"max_topics_per_article\", 5)\n",
        "TOPIC_THRESHOLD = CONFIG[\"topics\"].get(\"similarity_threshold\", 0.4)\n",
        "\n",
        "# --- OpenAI enrichment toggle ---\n",
        "topic_cfg = CONFIG.get(\"topics\", {})\n",
        "use_openai = topic_cfg.get(\"use_openai_enrichment\", False)\n",
        "openai_model = topic_cfg.get(\"openai_model\", \"gpt-4o-mini\")\n",
        "openai_field = topic_cfg.get(\"openai_field\", \"openai_topic_summary\")\n",
        "openai_temp = float(topic_cfg.get(\"openai_temperature\", 0.4))\n",
        "openai_max = int(topic_cfg.get(\"openai_max_tokens\", 64))\n",
        "openai_prompt = topic_cfg.get(\"openai_prompt\", \"\")\n",
        "client_openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "print(f\"Topic model: {topic_model_name}\")\n",
        "print(f\"OpenAI enrichment: {'ON' if use_openai else 'OFF'}\")\n",
        "\n",
        "# --- NLTK sentence tokenizer ---\n",
        "for pkg in [\"punkt\", \"punkt_tab\"]:\n",
        "    try: nltk.data.find(f\"tokenizers/{pkg}\")\n",
        "    except LookupError: nltk.download(pkg)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(topic_model_name, use_fast=True)\n",
        "tokenizer.model_max_length = 512\n",
        "embedder = SentenceTransformer(topic_model_name, device=device)\n",
        "\n",
        "# --- Load precomputed anchors ---\n",
        "ANCHORS_PATH = PROJECT_ROOT / \"config/topic_anchors.npz\"\n",
        "if not ANCHORS_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Missing {ANCHORS_PATH}\")\n",
        "data = np.load(ANCHORS_PATH, allow_pickle=True)\n",
        "topic_anchors = {k: v for k, v in data.items()}\n",
        "print(f\"Loaded {len(topic_anchors)} topic anchors from disk\")\n",
        "\n",
        "# --- Chroma setup ---\n",
        "client = chromadb.PersistentClient(path=str(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]))\n",
        "topic_coll = client.get_collection(CONFIG[\"chroma_collections\"][\"topic\"])\n",
        "\n",
        "# --- Utilities ---\n",
        "def sent_split(text):\n",
        "    return [s.strip() for s in nltk.sent_tokenize(text) if s.strip()]\n",
        "\n",
        "def encode(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    bs = 4 if torch.cuda.is_available() else 16\n",
        "    vecs = embedder.encode(texts, batch_size=bs, convert_to_numpy=True,\n",
        "                           normalize_embeddings=True, show_progress_bar=False)\n",
        "    return np.array(vecs)\n",
        "\n",
        "def chunk_by_tokens(text, max_tokens=512, overlap=64):\n",
        "    ids = tokenizer(text, add_special_tokens=False, return_attention_mask=False)[\"input_ids\"]\n",
        "    step = max_tokens - overlap\n",
        "    chunks = []\n",
        "    for i in range(0, len(ids), step):\n",
        "        j = min(i + max_tokens, len(ids))\n",
        "        piece = tokenizer.decode(ids[i:j], skip_special_tokens=True)\n",
        "        if piece.strip(): chunks.append(piece)\n",
        "    return chunks\n",
        "\n",
        "def sanitize(meta: dict):\n",
        "    out = {}\n",
        "    for k, v in meta.items():\n",
        "        if isinstance(v, (str, int, float, bool)) or v is None:\n",
        "            out[k] = \"\" if v is None else v\n",
        "        else:\n",
        "            out[k] = str(v)\n",
        "    return out\n",
        "\n",
        "def topic_vecs(text):\n",
        "    sents = sent_split(text)\n",
        "    if not sents: return []\n",
        "    if len(sents) < 2:\n",
        "        chunks = chunk_by_tokens(\" \".join(sents), chunk_tokens, 64)\n",
        "        return [encode(chunks).mean(axis=0)]\n",
        "    emb = encode(sents)\n",
        "    k = min(max(1, len(sents)//8), 8)\n",
        "    labels = AgglomerativeClustering(n_clusters=k).fit_predict(emb)\n",
        "    segs = [\" \".join([s for s, l in zip(sents, labels) if l == lab]) for lab in sorted(set(labels))]\n",
        "    out = []\n",
        "    for seg in segs:\n",
        "        chunks = chunk_by_tokens(seg, chunk_tokens, 64)\n",
        "        if not chunks: continue\n",
        "        pooled = encode(chunks).mean(axis=0)\n",
        "        out.append(pooled)\n",
        "    return out\n",
        "\n",
        "def match_topics(vec):\n",
        "    scores = {label: cosine_similarity([vec], [anchor])[0][0] for label, anchor in topic_anchors.items()}\n",
        "    sorted_topics = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    topics = []\n",
        "    for i, (k, v) in enumerate(sorted_topics[:MAX_TOPICS]):\n",
        "        if i == 0 or v >= TOPIC_THRESHOLD:\n",
        "            topics.append({\"topic_label\": k, \"similarity\": float(v)})\n",
        "    if not topics:\n",
        "        topics = [{\"topic_label\": \"General / Miscellaneous\", \"similarity\": 0.0}]\n",
        "    return topics\n",
        "\n",
        "def upsert_in_chunks(collection, ids, vectors, metadatas, chunk=2048):\n",
        "    for i in range(0, len(ids), chunk):\n",
        "        j = min(i + chunk, len(ids))\n",
        "        collection.upsert(ids=ids[i:j],\n",
        "                          embeddings=vectors[i:j].tolist(),\n",
        "                          metadatas=metadatas[i:j])\n",
        "\n",
        "def generate_openai_topic_sentence(title, text):\n",
        "    msg = f\"{openai_prompt}\\n\\nTitle: {title}\\n\\nExcerpt:\\n{text[:1500]}\"\n",
        "    try:\n",
        "        resp = client_openai.chat.completions.create(\n",
        "            model=openai_model,\n",
        "            messages=[{\"role\": \"user\", \"content\": msg}],\n",
        "            max_tokens=openai_max,\n",
        "            temperature=openai_temp,\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"[OpenAI] topic summary failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Main Loop ---\n",
        "start = time.time()\n",
        "added = processed = 0\n",
        "for txt_path in RAW_DIR.glob(\"*.txt\"):\n",
        "    meta_path = txt_path.with_suffix(\".meta.json\")\n",
        "    if not meta_path.exists(): continue\n",
        "    text = txt_path.read_text(encoding=\"utf-8\").strip()\n",
        "    if not text: continue\n",
        "    meta = json.load(open(meta_path, encoding=\"utf-8\"))\n",
        "\n",
        "    vecs = topic_vecs(text)\n",
        "    if not vecs: continue\n",
        "\n",
        "    if use_openai:\n",
        "        gpt_summary = generate_openai_topic_sentence(meta.get(\"title\", \"\"), text)\n",
        "        if gpt_summary:\n",
        "            gpt_vec = encode(gpt_summary)[0]\n",
        "            vecs.append(gpt_vec)\n",
        "            meta[openai_field] = gpt_summary\n",
        "\n",
        "    ids, metas = [], []\n",
        "    for i, v in enumerate(vecs):\n",
        "        topics_detected = match_topics(v)\n",
        "        topics_json = json.dumps(topics_detected, ensure_ascii=False)\n",
        "        topics_flat = [t[\"topic_label\"] for t in topics_detected]\n",
        "        top_topic = topics_detected[0][\"topic_label\"] if topics_detected else \"\"\n",
        "        topic_source = (\n",
        "            \"openai_summary\"\n",
        "            if use_openai and i == len(vecs) - 1 and openai_field in meta\n",
        "            else \"anchor_cluster\"\n",
        "        )\n",
        "        enriched_meta = sanitize({\n",
        "            **meta,\n",
        "            \"topic_index\": i,\n",
        "            \"topic_model\": topic_model_name,\n",
        "            \"topic_source\": topic_source,\n",
        "            \"topic_labels_json\": topics_json,\n",
        "            \"topics_flat\": \";\".join(topics_flat),\n",
        "            \"top_topic\": top_topic\n",
        "        })\n",
        "        ids.append(f\"{meta['id']}::topic::{i}\")\n",
        "        metas.append(enriched_meta)\n",
        "\n",
        "    upsert_in_chunks(topic_coll, ids, np.vstack(vecs), metas)\n",
        "    added += len(vecs)\n",
        "    processed += 1\n",
        "\n",
        "print(f\"Processed {processed} articles.\")\n",
        "print(f\"Topic upserts: {added} vectors ({'with' if use_openai else 'without'} OpenAI enrichment) \"\n",
        "      f\"in {round(time.time()-start,2)} s.\")\n"
      ],
      "metadata": {
        "id": "pV8CM5ZlnvVl"
      },
      "id": "pV8CM5ZlnvVl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Topic Embeddings Checker (GPT summaries + anchor clusters)\n",
        "# ==============================\n",
        "\n",
        "import numpy as np, json, collections\n",
        "import chromadb\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "client = chromadb.PersistentClient(path=str(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]))\n",
        "topic_coll = client.get_collection(CONFIG[\"chroma_collections\"][\"topic\"])\n",
        "\n",
        "ANCHORS_PATH = PROJECT_ROOT / \"config/topic_anchors.npz\"\n",
        "if ANCHORS_PATH.exists():\n",
        "    data = np.load(ANCHORS_PATH, allow_pickle=True)\n",
        "    print(f\"Loaded {len(data.files)} topic anchors from {ANCHORS_PATH}\")\n",
        "else:\n",
        "    print(\"Warning: topic_anchors.npz not found\")\n",
        "\n",
        "count = topic_coll.count()\n",
        "print(f\"Topic collection contains {count} total vectors\\n\")\n",
        "if count == 0:\n",
        "    print(\"No topic vectors found.\"); raise SystemExit()\n",
        "\n",
        "dump = topic_coll.get(include=[\"metadatas\"], limit=min(5000, count))\n",
        "metas = dump.get(\"metadatas\", [])\n",
        "\n",
        "grouped = collections.defaultdict(lambda: {\n",
        "    \"anchor_cluster\": 0, \"openai_summary\": 0,\n",
        "    \"title\": None, \"source\": None, \"summary_text\": None\n",
        "})\n",
        "for m in metas:\n",
        "    if not isinstance(m, dict): continue\n",
        "    base_id = m.get(\"id\", \"\").split(\"::topic::\")[0]\n",
        "    src = m.get(\"topic_source\", \"anchor_cluster\")\n",
        "    grouped[base_id][src] += 1\n",
        "    grouped[base_id][\"title\"] = m.get(\"title\", \"?\")\n",
        "    grouped[base_id][\"source\"] = m.get(\"source\", \"?\")\n",
        "    if src == \"openai_summary\" and m.get(\"openai_topic_summary\"):\n",
        "        grouped[base_id][\"summary_text\"] = m[\"openai_topic_summary\"]\n",
        "\n",
        "print(\"=== Per-Article Topic Summary (with GPT Output) ===\\n\")\n",
        "for base_id, info in grouped.items():\n",
        "    print(f\"{info['source']} | {info['title']}\")\n",
        "    print(f\"  • anchor_cluster: {info['anchor_cluster']:>3}\")\n",
        "    print(f\"  • openai_summary: {info['openai_summary']:>3}\")\n",
        "    print(f\"  • total_vectors:  {info['anchor_cluster']+info['openai_summary']:>3}\")\n",
        "    if info[\"summary_text\"]:\n",
        "        print(f\"  • OpenAI topic summary:\\n   {info['summary_text']}\\n\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "anchor_total = sum(v[\"anchor_cluster\"] for v in grouped.values())\n",
        "openai_total = sum(v[\"openai_summary\"] for v in grouped.values())\n",
        "print(f\"\\n=== Aggregate Counts ===\")\n",
        "print(f\"Articles processed: {len(grouped)}\")\n",
        "print(f\"Anchor vectors:    {anchor_total}\")\n",
        "print(f\"OpenAI summaries:  {openai_total}\")\n",
        "print(f\"Grand total:      {anchor_total+openai_total}\")\n",
        "print(\"\\n--- Topic Embedding Integrity Check Complete ---\")\n"
      ],
      "metadata": {
        "id": "lkaygTuHuK10"
      },
      "id": "lkaygTuHuK10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 9 of N — Source Bias + Author Tone Alignment (v5.0)\n",
        "\n",
        "### Purpose\n",
        "This step analyzes each scraped article to determine **how the author’s ideological tone aligns or diverges** from the **typical bias of the source outlet**.\n",
        "\n",
        "It adds three new analytical fields to your `stance` collection in Chroma:\n",
        "- `source_bias`: typical ideological family of the outlet (e.g. \"center left\", \"libertarian right\")\n",
        "- `bias_score`: numeric position on a simplified political spectrum (-1.0 = strong left, +1.0 = strong right)\n",
        "- `author_tone_match`: boolean indicating whether the detected author tone aligns with the outlet’s known bias\n",
        "\n",
        "---\n",
        "\n",
        "### Why this matters\n",
        "In modern media ecosystems, an outlet’s *institutional bias* doesn’t always reflect the *tone of individual articles*.  \n",
        "For example:\n",
        "- A **right-leaning outlet** might publish an article with a **centrist or neutral tone**\n",
        "- A **left-leaning outlet** might host a **contrarian** op-ed that diverges from its norm\n",
        "\n",
        "Capturing that divergence lets your system distinguish between:\n",
        "> “A left outlet being left” versus “A left outlet publishing something surprising.”\n",
        "\n",
        "That difference is key to building your anti-echo retrieval logic — you can surface articles that:\n",
        "- Cover **the same topic**\n",
        "- Come from **opposite ideological directions**\n",
        "- And either **reinforce** or **contradict** their outlet’s typical stance\n",
        "\n",
        "---\n",
        "\n",
        "### How `bias_score` works\n",
        "Each outlet in `source_bias.json` has a **bias family** (like `\"center left\"`)  \n",
        "and a **bias score** (float between -1.0 and +1.0).\n",
        "\n",
        "| Range | Meaning | Example Outlets |\n",
        "|--------|----------|----------------|\n",
        "| -1.0 → -0.6 | Progressive / Left | Vox, The Guardian, MSNBC |\n",
        "| -0.6 → -0.2 | Center Left | NPR, BBC, NYT |\n",
        "| -0.2 → +0.2 | Center / Neutral | Reuters, AP |\n",
        "| +0.2 → +0.6 | Center Right | WSJ, The Economist |\n",
        "| +0.6 → +1.0 | Conservative / Right | Fox News, Daily Caller, Breitbart |\n",
        "\n",
        "The article’s **author tone** (detected by GPT-4o-mini) is mapped to the same numeric scale.  \n",
        "If the two scores are close, the author is “in tune” with the source.\n",
        "\n",
        "`author_tone_match = abs(source_bias_score - author_tone_score) <= 0.3`\n",
        "\n",
        "Otherwise, the article is flagged as a **divergent piece** — a sign of internal tension or surprising framing.\n",
        "\n",
        "---\n",
        "\n",
        "### Output Fields (stored in Chroma)\n",
        "| Field | Description |\n",
        "|--------|-------------|\n",
        "| `political_leaning` | Article tone / author ideology |\n",
        "| `source_bias` | Typical outlet bias family |\n",
        "| `bias_score` | Numeric bias of outlet |\n",
        "| `author_tone_match` | Whether article tone aligns with outlet bias |\n",
        "| `implied_stance` | Summary of article’s worldview or policy argument |\n",
        "| `stance_variant` | “label” or “summary” variant |\n",
        "| `stance_summary_text` | One-sentence summary of rhetorical tone |\n",
        "| `stance_embedding` | Vector representation used for retrieval |\n",
        "\n",
        "---\n",
        "\n",
        "### Why this design\n",
        "This allows retrieval experiments such as:\n",
        "- “Show me articles on the same topic, but from **different bias families**.”\n",
        "- “Find articles from outlets whose **authors disagree** with the typical tone.”\n",
        "- “Find the **most contrasting stance** to the one I uploaded.”\n",
        "\n",
        "These new metadata fields make your dense retrieval space **bias-aware** and **author-sensitive**, giving the comparison tool a richer basis for anti-echo matching.\n"
      ],
      "metadata": {
        "id": "7lHNRC8VZ28B"
      },
      "id": "7lHNRC8VZ28B"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Setup 9 of N — Source Bias + Author Tone Alignment (v5 merged for Code 1)\n",
        "# ===============================================\n",
        "\n",
        "import os, json, re, time, torch, chromadb, numpy as np\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rapidfuzz import fuzz\n",
        "from collections import Counter\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "RAW_DIR = PROJECT_ROOT / \"raw\"\n",
        "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
        "\n",
        "SOURCE_BIAS_PATH = CONFIG_DIR / \"source_bias.json\"\n",
        "LEANINGS_PATH = CONFIG_DIR / \"political_leanings.json\"\n",
        "STANCES_PATH = CONFIG_DIR / \"implied_stances.json\"\n",
        "\n",
        "source_bias = json.load(open(SOURCE_BIAS_PATH, encoding=\"utf-8\"))\n",
        "leanings_map = json.load(open(LEANINGS_PATH, encoding=\"utf-8\"))\n",
        "stances_map = json.load(open(STANCES_PATH, encoding=\"utf-8\"))\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "stance_embedder = SentenceTransformer(\"all-mpnet-base-v2\", device=device)\n",
        "\n",
        "client_chroma = chromadb.PersistentClient(path=str(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]))\n",
        "stance_coll = client_chroma.get_or_create_collection(CONFIG[\"chroma_collections\"][\"stance\"])\n",
        "\n",
        "# --- Bias utilities ---\n",
        "def bias_to_score(name: str) -> float:\n",
        "    n = (name or \"\").lower().strip()\n",
        "    if \"progressive\" in n or (\"left\" in n and \"center\" not in n): return -0.8\n",
        "    if \"center left\" in n:  return -0.4\n",
        "    if n == \"center\":       return 0.0\n",
        "    if \"center right\" in n: return 0.4\n",
        "    if \"conservative\" in n or \"right\" in n: return 0.8\n",
        "    if \"libertarian\" in n:  return 0.6\n",
        "    return 0.0\n",
        "\n",
        "def tone_to_score(leaning: str) -> float:\n",
        "    return bias_to_score(leaning)\n",
        "\n",
        "def tone_match(bias_score, tone_score, threshold=0.3) -> bool:\n",
        "    return abs(bias_score - tone_score) <= threshold\n",
        "\n",
        "# --- GPT classification helper ---\n",
        "def classify_article_tone_and_stance(title: str, text: str) -> dict:\n",
        "    prompt = f\"\"\"\n",
        "You are a political analyst.\n",
        "Based on the article below, classify its overall political leaning (tone) and implied stance.\n",
        "\n",
        "Leaning options: {', '.join(leanings_map.keys())}\n",
        "Stance examples: {', '.join([s for cat in stances_map.values() for s in cat['families'].keys()])}\n",
        "\n",
        "Return strict JSON with fields:\n",
        "- political_leaning\n",
        "- implied_stance\n",
        "- summary (one sentence)\n",
        "\n",
        "Article title: {title}\n",
        "Excerpt: {text[:2000]}\n",
        "\"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=256,\n",
        "        temperature=0.4\n",
        "    )\n",
        "    raw = resp.choices[0].message.content.strip()\n",
        "    clean = re.sub(r\"^```(?:json)?|```$\", \"\", raw, flags=re.MULTILINE).strip()\n",
        "\n",
        "    try:\n",
        "        data = json.loads(clean)\n",
        "        if not isinstance(data, dict): raise ValueError\n",
        "    except Exception:\n",
        "        data = {}\n",
        "        for line in clean.splitlines():\n",
        "            m = re.match(r'\"?([^\":]+)\"?\\s*:\\s*\"([^\"]+)\"', line.strip())\n",
        "            if m: data[m.group(1).strip()] = m.group(2).strip()\n",
        "\n",
        "    return {\n",
        "        \"political_leaning\": data.get(\"political_leaning\", \"unknown\").lower().strip(),\n",
        "        \"implied_stance\": data.get(\"implied_stance\", \"unknown\").lower().strip(),\n",
        "        \"summary\": data.get(\"summary\", \"\").strip()\n",
        "    }\n",
        "\n",
        "# --- Metadata sanitizer ---\n",
        "def sanitize_metadata(meta: dict) -> dict:\n",
        "    out = {}\n",
        "    for k, v in meta.items():\n",
        "        if v is None: out[k] = \"\"\n",
        "        elif isinstance(v, (list, dict)): out[k] = json.dumps(v, ensure_ascii=False)\n",
        "        elif isinstance(v, (str, int, float, bool)): out[k] = v\n",
        "        else: out[k] = str(v)\n",
        "    return out\n",
        "\n",
        "# --- Main processing loop ---\n",
        "start = time.time()\n",
        "added = processed = 0\n",
        "results_summary = []\n",
        "\n",
        "for txt_path in RAW_DIR.glob(\"*.txt\"):\n",
        "    meta_path = txt_path.with_suffix(\".meta.json\")\n",
        "    if not meta_path.exists(): continue\n",
        "    meta = json.load(open(meta_path, encoding=\"utf-8\"))\n",
        "    title = meta.get(\"title\") or Path(txt_path).stem\n",
        "    source = (meta.get(\"source\") or \"unknown\").lower()\n",
        "    text = txt_path.read_text(encoding=\"utf-8\").strip()\n",
        "\n",
        "    bias_info = source_bias.get(source, {\"bias_family\": \"unknown\", \"bias_score\": 0.0})\n",
        "    bias_family = bias_info.get(\"bias_family\", \"unknown\")\n",
        "    bias_score = float(bias_info.get(\"bias_score\", 0.0))\n",
        "\n",
        "    data = classify_article_tone_and_stance(title, text)\n",
        "    leaning, stance, summary = data[\"political_leaning\"], data[\"implied_stance\"], data[\"summary\"]\n",
        "\n",
        "    tone_score = tone_to_score(leaning)\n",
        "    author_match = tone_match(bias_score, tone_score)\n",
        "\n",
        "    meta_enriched = {\n",
        "        **meta,\n",
        "        \"political_leaning\": leaning,\n",
        "        \"implied_stance\": stance,\n",
        "        \"source_bias\": bias_family,\n",
        "        \"bias_score\": bias_score,\n",
        "        \"author_tone_match\": bool(author_match),\n",
        "        \"stance_summary_text\": summary\n",
        "    }\n",
        "    meta_enriched = sanitize_metadata(meta_enriched)\n",
        "\n",
        "    embed_text = f\"{leaning}\\n{stance}\\n{summary}\"\n",
        "    vec = stance_embedder.encode(embed_text, normalize_embeddings=True)\n",
        "    stance_coll.upsert(\n",
        "        ids=[f\"{meta.get('id', Path(txt_path).stem)}::stance::summary\"],\n",
        "        embeddings=[vec.tolist()],\n",
        "        metadatas=[meta_enriched]\n",
        "    )\n",
        "\n",
        "    results_summary.append((source, leaning, stance, author_match))\n",
        "    added += 1; processed += 1\n",
        "    print(f\"[{source}] {title[:60]}... → leaning={leaning}, stance={stance}\")\n",
        "\n",
        "print(f\"\\nProcessed {processed} articles, added {added} stance vectors in {round(time.time()-start,1)}s.\")\n"
      ],
      "metadata": {
        "id": "ynftgkBWGo1a"
      },
      "id": "ynftgkBWGo1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Stance / Source Bias Checker (with GPT Stance Summary Output)\n",
        "# ===============================================\n",
        "\n",
        "import chromadb, numpy as np, collections\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "client = chromadb.PersistentClient(path=str(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]))\n",
        "stance_coll = client.get_collection(CONFIG[\"chroma_collections\"][\"stance\"])\n",
        "\n",
        "count = stance_coll.count()\n",
        "print(f\"Stance collection has {count} total records\\n\")\n",
        "if count == 0:\n",
        "    print(\"No stance vectors found.\")\n",
        "    raise SystemExit()\n",
        "\n",
        "dump = stance_coll.get(include=[\"metadatas\"], limit=min(5000, count))\n",
        "metas = dump.get(\"metadatas\", [])\n",
        "\n",
        "# Aggregate stats per source\n",
        "stats = collections.defaultdict(lambda: {\"leanings\": Counter(), \"biases\": Counter(), \"matches\": 0, \"total\": 0})\n",
        "examples = collections.defaultdict(list)\n",
        "\n",
        "for m in metas:\n",
        "    if not isinstance(m, dict):\n",
        "        continue\n",
        "    src = (m.get(\"source\") or \"unknown\").lower()\n",
        "    lean = (m.get(\"political_leaning\") or \"unknown\").lower()\n",
        "    bias = (m.get(\"source_bias\") or \"unknown\").lower()\n",
        "    match = bool(m.get(\"author_tone_match\"))\n",
        "    summary = m.get(\"stance_summary_text\", \"\").strip()\n",
        "    title = m.get(\"title\", \"\").strip()[:120]\n",
        "\n",
        "    stats[src][\"leanings\"][lean] += 1\n",
        "    stats[src][\"biases\"][bias] += 1\n",
        "    stats[src][\"matches\"] += int(match)\n",
        "    stats[src][\"total\"] += 1\n",
        "\n",
        "    # Keep a few representative summaries per source\n",
        "    if summary and len(examples[src]) < 3:\n",
        "        examples[src].append((title, lean, bias, match, summary))\n",
        "\n",
        "print(\"=== Source-level Stance Summary ===\\n\")\n",
        "for src, d in stats.items():\n",
        "    total = d[\"total\"]\n",
        "    match_rate = d[\"matches\"] / total if total else 0\n",
        "    top_lean = d[\"leanings\"].most_common(1)[0] if d[\"leanings\"] else (\"-\", 0)\n",
        "    top_bias = d[\"biases\"].most_common(1)[0] if d[\"biases\"] else (\"-\", 0)\n",
        "\n",
        "    print(f\"{src.upper()}: {total} articles\")\n",
        "    print(f\"  - top leaning: {top_lean[0]} ({top_lean[1]})\")\n",
        "    print(f\"  - top bias:    {top_bias[0]} ({top_bias[1]})\")\n",
        "    print(f\"  - tone match:  {match_rate:.1%}\")\n",
        "\n",
        "    if examples[src]:\n",
        "        print(\"  - Example summaries:\")\n",
        "        for t, lean, bias, match, summ in examples[src]:\n",
        "            match_str = \"match\" if match else \"divergent\"\n",
        "            print(f\"     * {t}\")\n",
        "            print(f\"       leaning={lean}, bias={bias}, {match_str}\")\n",
        "            print(f\"       summary: {summ[:200]}{'...' if len(summ) > 200 else ''}\")\n",
        "        print()\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "total_all = sum(d[\"total\"] for d in stats.values())\n",
        "overall_match = (sum(d[\"matches\"] for d in stats.values()) / total_all) if total_all else 0\n",
        "\n",
        "print(\"=== Overall ===\")\n",
        "print(f\"Sources analyzed: {len(stats)}\")\n",
        "print(f\"Articles total:   {total_all}\")\n",
        "print(f\"Tone alignment:   {overall_match:.1%}\")\n",
        "print(\"\\n--- Stance / Bias Checker Complete ---\")\n"
      ],
      "metadata": {
        "id": "NAI8jWY8Gth7"
      },
      "id": "NAI8jWY8Gth7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 10 of N - persist feed state to HF and GitHub\n",
        "\n",
        "Purpose\n",
        "Snapshot feeds/feeds_state.json and feeds/index.json to HF as timestamped copies and latest pointers, and commit the same to GitHub. This keeps HF as the single source of truth while providing Git history.\n",
        "\n",
        "Why this matters\n",
        "Future runs and collaborators can always restore state. The UI you build later can also read the latest pointers.\n",
        "\n",
        "Outputs\n",
        "Four files on HF and two files in GitHub updated, with a short summary."
      ],
      "metadata": {
        "id": "LSRhQ_EAnuCQ"
      },
      "id": "LSRhQ_EAnuCQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Setup 10 of N — persist feed state to HF and GitHub (config-driven)\n",
        "# ===============================================\n",
        "\n",
        "import os, json, base64\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from huggingface_hub import upload_file\n",
        "import requests\n",
        "from getpass import getpass\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "FEEDS_DIR = PROJECT_ROOT / \"feeds\"\n",
        "STATE_PATH = FEEDS_DIR / \"feeds_state.json\"\n",
        "INDEX_PATH = FEEDS_DIR / \"index.json\"\n",
        "\n",
        "HF_DATASET_ID = CONFIG[\"hf_dataset_id\"]\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\",\"\").strip() or getpass(\"Enter HF token: \")\n",
        "\n",
        "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\",\"\").strip() or getpass(\"Enter GitHub token: \")\n",
        "REPO_OWNER = CONFIG[\"github\"][\"owner\"]\n",
        "REPO_NAME  = CONFIG[\"github\"][\"repo\"]\n",
        "BRANCH     = CONFIG[\"github\"].get(\"branch\", \"main\")\n",
        "\n",
        "ts = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "uploads = [\n",
        "    (STATE_PATH, f\"feeds/feeds_state_{ts}.json\"),\n",
        "    (INDEX_PATH, f\"feeds/feed_index_{ts}.json\"),\n",
        "    (STATE_PATH, \"feeds/feeds_state_latest.json\"),\n",
        "    (INDEX_PATH, \"feeds/feed_index_latest.json\"),\n",
        "]\n",
        "\n",
        "print(\"Uploading feed state to HF...\")\n",
        "for local, remote in uploads:\n",
        "    upload_file(\n",
        "        path_or_fileobj=str(local),\n",
        "        path_in_repo=remote,\n",
        "        repo_id=HF_DATASET_ID,\n",
        "        repo_type=\"dataset\",\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "print(\"HF upload complete\")\n",
        "\n",
        "def gh_put(local_path: Path, repo_path: str, message: str):\n",
        "    url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{repo_path}\"\n",
        "    headers = {\"Authorization\": f\"Bearer {GITHUB_TOKEN}\", \"Accept\": \"application/vnd.github+json\"}\n",
        "    content = local_path.read_bytes()\n",
        "    r = requests.get(url, headers=headers, timeout=20)\n",
        "    sha = r.json().get(\"sha\") if r.status_code == 200 else None\n",
        "    payload = {\"message\": message, \"content\": base64.b64encode(content).decode(), \"branch\": BRANCH}\n",
        "    if sha: payload[\"sha\"] = sha\n",
        "    resp = requests.put(url, headers=headers, json=payload, timeout=30)\n",
        "    if resp.status_code not in (200,201):\n",
        "        raise RuntimeError(f\"GitHub push failed for {repo_path}: {resp.status_code} {resp.text[:200]}\")\n",
        "\n",
        "print(\"Committing feed state to GitHub...\")\n",
        "commit_msg = f\"Update feed state and index {ts}\"\n",
        "for local, repo_path in [\n",
        "    (STATE_PATH, f\"feeds/feeds_state_{ts}.json\"),\n",
        "    (INDEX_PATH, f\"feeds/feed_index_{ts}.json\"),\n",
        "    (STATE_PATH, \"feeds/feeds_state_latest.json\"),\n",
        "    (INDEX_PATH, \"feeds/feed_index_latest.json\"),\n",
        "]:\n",
        "    gh_put(local, repo_path, commit_msg)\n",
        "print(\"GitHub commit complete\")\n"
      ],
      "metadata": {
        "id": "iB3izd-Rv1WV"
      },
      "id": "iB3izd-Rv1WV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup 11 of N - package and push batch to HF, update registry on Git\n",
        "\n",
        "Purpose\n",
        "Package current Chroma collections into batch files, upload to HF under batches/{batch_id}/, then update artifacts/artifacts_registry.json in your GitHub repo. HF is the single source of truth. The registry keeps a chronological ledger for rebuilds.\n",
        "\n",
        "Why this matters\n",
        "Gives you versioned, reconstructable artifacts and a single source of truth for future runs and for a UI.\n",
        "\n",
        "Outputs\n",
        "topic_embeddings.npz, stance_embeddings.npz, metadata.jsonl, manifest.json uploaded to HF and registry updated on GitHub."
      ],
      "metadata": {
        "id": "fieZ0huen5Zg"
      },
      "id": "fieZ0huen5Zg"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Setup 11 of N — package and push batch, update registry (config-driven)\n",
        "# ===============================================\n",
        "\n",
        "import os, json, time, uuid, warnings, logging, requests, base64\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from huggingface_hub import upload_file\n",
        "import chromadb\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "logging.getLogger(\"chromadb\").setLevel(logging.ERROR)\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "BATCH_DIR = PROJECT_ROOT / CONFIG[\"batch\"][\"base_dir\"]\n",
        "HF_DATASET_ID = CONFIG[\"hf_dataset_id\"]\n",
        "\n",
        "REPO_OWNER = CONFIG[\"github\"][\"owner\"]\n",
        "REPO_NAME  = CONFIG[\"github\"][\"repo\"]\n",
        "BRANCH     = CONFIG[\"github\"].get(\"branch\", \"main\")\n",
        "\n",
        "client = chromadb.PersistentClient(path=str(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]))\n",
        "topic_coll  = client.get_collection(CONFIG[\"chroma_collections\"][\"topic\"])\n",
        "stance_coll = client.get_collection(CONFIG[\"chroma_collections\"][\"stance\"])\n",
        "\n",
        "timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "batch_id = f\"batch_{timestamp}_{uuid.uuid4().hex[:8]}\"\n",
        "batch_path = BATCH_DIR / batch_id\n",
        "batch_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "topic_dump = topic_coll.get(include=[\"embeddings\",\"metadatas\"])\n",
        "stance_dump = stance_coll.get(include=[\"embeddings\",\"metadatas\"])\n",
        "topic_vecs = np.array(topic_dump[\"embeddings\"], dtype=np.float16)\n",
        "stance_vecs = np.array(stance_dump[\"embeddings\"], dtype=np.float16)\n",
        "\n",
        "topic_npz   = batch_path / CONFIG[\"batch\"][\"topic_file\"]\n",
        "stance_npz  = batch_path / CONFIG[\"batch\"][\"stance_file\"]\n",
        "meta_topic  = batch_path / \"metadata_topic.jsonl\"\n",
        "meta_stance = batch_path / \"metadata_stance.jsonl\"\n",
        "manifest_path = batch_path / CONFIG[\"batch\"][\"manifest_name\"]\n",
        "\n",
        "def write_meta_jsonl(path, ids, metas):\n",
        "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for rid, m in zip(ids, metas):\n",
        "            rec = dict(m) if isinstance(m, dict) else {}\n",
        "            rec[\"row_id\"] = rid\n",
        "            rec.setdefault(\"id\", rec.get(\"id\",\"\"))\n",
        "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "write_meta_jsonl(meta_topic,  topic_dump[\"ids\"],  topic_dump[\"metadatas\"])\n",
        "write_meta_jsonl(meta_stance, stance_dump[\"ids\"], stance_dump[\"metadatas\"])\n",
        "np.savez_compressed(topic_npz, topic_vecs)\n",
        "np.savez_compressed(stance_npz, stance_vecs)\n",
        "\n",
        "manifest = {\n",
        "    \"schema_version\": 2,\n",
        "    \"batch_id\": batch_id,\n",
        "    \"created_at\": timestamp,\n",
        "    \"models\": CONFIG[\"embeddings\"],\n",
        "    \"counts\": {\"topic\": int(topic_vecs.shape[0]), \"stance\": int(stance_vecs.shape[0])},\n",
        "    \"hf_dataset_id\": HF_DATASET_ID,\n",
        "    \"paths\": {\n",
        "        \"embeddings_topic\": f\"batches/{batch_id}/{topic_npz.name}\",\n",
        "        \"embeddings_stance\": f\"batches/{batch_id}/{stance_npz.name}\",\n",
        "        \"metadata_topic\": f\"batches/{batch_id}/{meta_topic.name}\",\n",
        "        \"metadata_stance\": f\"batches/{batch_id}/{meta_stance.name}\",\n",
        "        \"manifest\": f\"batches/{batch_id}/{manifest_path.name}\",\n",
        "    }\n",
        "}\n",
        "manifest_path.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(\"Uploading batch to HF...\")\n",
        "HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
        "for fpath in [topic_npz, stance_npz, meta_topic, meta_stance, manifest_path]:\n",
        "    upload_file(\n",
        "        path_or_fileobj=str(fpath),\n",
        "        path_in_repo=f\"batches/{batch_id}/{fpath.name}\",\n",
        "        repo_id=HF_DATASET_ID,\n",
        "        repo_type=\"dataset\",\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "print(\"HF batch upload complete\")\n",
        "\n",
        "REGISTRY_URL = f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/artifacts/artifacts_registry.json\"\n",
        "try:\n",
        "    registry = requests.get(REGISTRY_URL, timeout=20).json()\n",
        "except Exception:\n",
        "    registry = {\"version\": 1, \"batches\": []}\n",
        "\n",
        "registry.setdefault(\"batches\", []).append(manifest)\n",
        "registry[\"version\"] = int(registry.get(\"version\", 0)) + 1\n",
        "\n",
        "new_registry_bytes = json.dumps(registry, indent=2).encode(\"utf-8\")\n",
        "url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/artifacts/artifacts_registry.json\"\n",
        "headers = {\"Authorization\": f\"Bearer {os.environ['GITHUB_TOKEN']}\", \"Accept\": \"application/vnd.github+json\"}\n",
        "r = requests.get(url, headers=headers, timeout=20)\n",
        "sha = r.json().get(\"sha\") if r.status_code == 200 else None\n",
        "payload = {\"message\": f\"Update artifacts registry {timestamp}\",\n",
        "           \"content\": base64.b64encode(new_registry_bytes).decode(),\n",
        "           \"branch\": BRANCH}\n",
        "if sha: payload[\"sha\"] = sha\n",
        "resp = requests.put(url, headers=headers, json=payload, timeout=30)\n",
        "if resp.status_code not in (200,201):\n",
        "    raise RuntimeError(f\"GitHub registry push failed: {resp.status_code} {resp.text[:200]}\")\n",
        "print(\"Registry updated on GitHub\")\n"
      ],
      "metadata": {
        "id": "a3bxLgPWn8H2"
      },
      "id": "a3bxLgPWn8H2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4cefcff6fe8141c896582c7729a6f69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_776aea8081ff44998bc5708f6d1c17ad",
              "IPY_MODEL_92bad2f24c2d4dfc9435052b7b4c3599",
              "IPY_MODEL_6c539b044c0e47a28358b916800e58fe"
            ],
            "layout": "IPY_MODEL_02dd7988561c4b5ca50bbe7deab56747"
          }
        },
        "776aea8081ff44998bc5708f6d1c17ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d67c1e3e1d4001a54c9e279484cd20",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e7377e5b994cce9e8c4d5ba4f68c76",
            "value": "feeds_state_latest.json: "
          }
        },
        "92bad2f24c2d4dfc9435052b7b4c3599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808b7979b6e5482c95ee758aca4aa81c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11e02d1f618c4bab89adce6ca354ede0",
            "value": 1
          }
        },
        "6c539b044c0e47a28358b916800e58fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a39f23809b451e9bd4a023f9f19c03",
            "placeholder": "​",
            "style": "IPY_MODEL_06e3db41f8b24ca1bdeeee59044da778",
            "value": " 3.19k/? [00:00&lt;00:00, 326kB/s]"
          }
        },
        "02dd7988561c4b5ca50bbe7deab56747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1d67c1e3e1d4001a54c9e279484cd20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e7377e5b994cce9e8c4d5ba4f68c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808b7979b6e5482c95ee758aca4aa81c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "11e02d1f618c4bab89adce6ca354ede0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1a39f23809b451e9bd4a023f9f19c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e3db41f8b24ca1bdeeee59044da778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96927fcd11474dc4918def91a8887ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55d96a9eca6e4319b4facf6261933faa",
              "IPY_MODEL_ab248dde49e849bfaa2212900b0f55d5",
              "IPY_MODEL_83701da7186349bdbb140db4bebde114"
            ],
            "layout": "IPY_MODEL_cef3a03d71c64c91b7a2599d076c05a5"
          }
        },
        "55d96a9eca6e4319b4facf6261933faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_293bfe57bec0454f9c2a1cc2d6eb5012",
            "placeholder": "​",
            "style": "IPY_MODEL_560d0c8c560a47b89b4077e291d47d64",
            "value": "feed_index_latest.json: "
          }
        },
        "ab248dde49e849bfaa2212900b0f55d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43f0672ff0d94765a956b6abfe466a04",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86136733a5154f01b301f03fd34b6817",
            "value": 1
          }
        },
        "83701da7186349bdbb140db4bebde114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a792bb5b501477593f83ebaed1acda9",
            "placeholder": "​",
            "style": "IPY_MODEL_a0570ba74b994f039d394a3676ac98be",
            "value": " 2.73k/? [00:00&lt;00:00, 314kB/s]"
          }
        },
        "cef3a03d71c64c91b7a2599d076c05a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293bfe57bec0454f9c2a1cc2d6eb5012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560d0c8c560a47b89b4077e291d47d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43f0672ff0d94765a956b6abfe466a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "86136733a5154f01b301f03fd34b6817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a792bb5b501477593f83ebaed1acda9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0570ba74b994f039d394a3676ac98be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e826337f9e2e4f869ab2a08431e4a986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7812102502b44da28fabcf586e9353c1",
              "IPY_MODEL_0eee7bd41bf6427da9a127d9acb8f9a8",
              "IPY_MODEL_25bab004cfc14be28e0e7af141be0f5d"
            ],
            "layout": "IPY_MODEL_5ec18f76661f49bd83dde46325dc270d"
          }
        },
        "7812102502b44da28fabcf586e9353c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_422205c375e648ac9fe20f83fa9e2324",
            "placeholder": "​",
            "style": "IPY_MODEL_a8bf9efa515a47009d683569b73f8758",
            "value": "embeddings_topic.npz: 100%"
          }
        },
        "0eee7bd41bf6427da9a127d9acb8f9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40c15f084d14b64803be9e59dc8577e",
            "max": 89933,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e54a43c203cc4f6bb678a38ffe86dd4a",
            "value": 89933
          }
        },
        "25bab004cfc14be28e0e7af141be0f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_735694a0e3c6445bbe366cb9234f48b0",
            "placeholder": "​",
            "style": "IPY_MODEL_f30c09c041d9459492e83fedcddda3f3",
            "value": " 89.9k/89.9k [00:00&lt;00:00, 1.78MB/s]"
          }
        },
        "5ec18f76661f49bd83dde46325dc270d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422205c375e648ac9fe20f83fa9e2324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8bf9efa515a47009d683569b73f8758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b40c15f084d14b64803be9e59dc8577e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54a43c203cc4f6bb678a38ffe86dd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "735694a0e3c6445bbe366cb9234f48b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f30c09c041d9459492e83fedcddda3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4abcf682e134d3b83e14061b663d7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aadf7ceead704466870600fed076f89e",
              "IPY_MODEL_6811b0b814b640c0afb7d7f0a03faecc",
              "IPY_MODEL_0fa896ad0b6b40818f46540c8dce93ff"
            ],
            "layout": "IPY_MODEL_58f76104372b4f00ac60535a22a50747"
          }
        },
        "aadf7ceead704466870600fed076f89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0bb9ffe6dc14910b480105afa244911",
            "placeholder": "​",
            "style": "IPY_MODEL_d8c31e4dbf944845bb4ac71b4c5e3377",
            "value": "embeddings_stance.npz: 100%"
          }
        },
        "6811b0b814b640c0afb7d7f0a03faecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d29a54c92e45ccb349d79e3f1ffb5f",
            "max": 18725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_717ba9f1a7344eb28ee4f994dc0e735e",
            "value": 18725
          }
        },
        "0fa896ad0b6b40818f46540c8dce93ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691d26fb43e24eccbcd86244ae731fe9",
            "placeholder": "​",
            "style": "IPY_MODEL_654819d5dbdf45d797a9056f88911fb7",
            "value": " 18.7k/18.7k [00:00&lt;00:00, 219kB/s]"
          }
        },
        "58f76104372b4f00ac60535a22a50747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0bb9ffe6dc14910b480105afa244911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c31e4dbf944845bb4ac71b4c5e3377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81d29a54c92e45ccb349d79e3f1ffb5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717ba9f1a7344eb28ee4f994dc0e735e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "691d26fb43e24eccbcd86244ae731fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654819d5dbdf45d797a9056f88911fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa892e72a0104458942234780b8b3f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09fde59c7ea948c6a82cab08cd049a15",
              "IPY_MODEL_d873c534f3e24682818d4ba85d3de950",
              "IPY_MODEL_216d12908b2749c58ebe4596b018a657"
            ],
            "layout": "IPY_MODEL_2c6e48f959e849e493392889afe60fac"
          }
        },
        "09fde59c7ea948c6a82cab08cd049a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d4ee0b31264d0395e8ea130eb46054",
            "placeholder": "​",
            "style": "IPY_MODEL_4789e40b0311460b953e8797aa6bfc82",
            "value": "metadata_topic.jsonl: "
          }
        },
        "d873c534f3e24682818d4ba85d3de950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918f9c3fd194411aa9909c0c74671060",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b8fe85dbaa1415a88439fd95443add4",
            "value": 1
          }
        },
        "216d12908b2749c58ebe4596b018a657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5280c1991d04c2fade3576d664e9c85",
            "placeholder": "​",
            "style": "IPY_MODEL_4ad5535276444ce09bae0ce0783b8c40",
            "value": " 110k/? [00:00&lt;00:00, 11.9MB/s]"
          }
        },
        "2c6e48f959e849e493392889afe60fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d4ee0b31264d0395e8ea130eb46054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4789e40b0311460b953e8797aa6bfc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "918f9c3fd194411aa9909c0c74671060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2b8fe85dbaa1415a88439fd95443add4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5280c1991d04c2fade3576d664e9c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad5535276444ce09bae0ce0783b8c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "191c4366a0b4483ba41047bd1b8e79c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca5178d08cb244978a068bf145273caa",
              "IPY_MODEL_608e07f7a59144cea2fd8c9a1eb46d5f",
              "IPY_MODEL_828a918aedac4dc09194e49fa3f0d94a"
            ],
            "layout": "IPY_MODEL_9583f94abd504c52bf10127cf9c88126"
          }
        },
        "ca5178d08cb244978a068bf145273caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_916018bd8fb64199939c94dc2ba4399e",
            "placeholder": "​",
            "style": "IPY_MODEL_25b7247c7b754fae988bcefb6a280e00",
            "value": "metadata_stance.jsonl: "
          }
        },
        "608e07f7a59144cea2fd8c9a1eb46d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef8c972042494a2f8496524c52354739",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8e43eb21e7e48b9a7a9bc60c8e3f4e9",
            "value": 1
          }
        },
        "828a918aedac4dc09194e49fa3f0d94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa28984302fa48b0b27f17e579387787",
            "placeholder": "​",
            "style": "IPY_MODEL_4a7987d23332432e83b079c7d062df0c",
            "value": " 12.3k/? [00:00&lt;00:00, 1.28MB/s]"
          }
        },
        "9583f94abd504c52bf10127cf9c88126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916018bd8fb64199939c94dc2ba4399e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b7247c7b754fae988bcefb6a280e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef8c972042494a2f8496524c52354739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d8e43eb21e7e48b9a7a9bc60c8e3f4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa28984302fa48b0b27f17e579387787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a7987d23332432e83b079c7d062df0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}